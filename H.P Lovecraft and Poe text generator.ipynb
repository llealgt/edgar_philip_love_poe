{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks for H.P Lovecraft text generation\n",
    "\n",
    "\"The color out of space\" is one of my favorite tales from Lovecraft, i will use it(as well as others as the call of cthulhu) to create a recurrent neural network in tensorflow that learns his style and generates new text in his style\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn) and an example from \"Deep Learning Nanodegree\" on udacity. Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. \n",
    "\n",
    "## General architecture using \"Long short term memory\" units in the recurrent layers\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime ,localtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only the  first time nltk is used to download language\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define conf variables and hyper parameteters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = \"characters\" #characters or words\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 128       # Sequences per batch\n",
    "num_steps = 75         # Number of sequence steps per batch\n",
    "lstm_size = 768         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.00001  # Learning rate\n",
    "keep_prob = 1       # Dropout keep probability\n",
    "\n",
    "resume_from_checkpoint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base text\n",
    "Once trained ,the network can take base text and a sequence size and generate new text using base text as first characters in the sequence. For every element in base text wi will create a list that will store generated text as training goes, to be able to compare results between steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_try = [\"In the first place\",\"the night before\",\"horror\",\"creature\",\"night\",\"dream\",\"thing\",\"That night\",\"mountain\",\"Ammi\",\"Cthulhu\",\"raven\",\"bird\",\"nevermore\",\"dead\",\"The bird\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that separates text into tokens(for whitespace characters, only new line is implemented, missing tabs and others="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'u',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " '!',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'F',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'G',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'l',\n",
       " 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_by_words(text):\n",
    "    text = text.replace(\"\\n\",\" new_line_token \")\n",
    "    tokens = []\n",
    "    splitted =[[word_tokenize(w),' ']for w in text.split()]\n",
    "    splitted = list(itertools.chain(*list(itertools.chain(*splitted))))\n",
    "    \n",
    "    token_list = []\n",
    "    i = 0\n",
    "    while i < len(splitted):\n",
    "        if splitted[i] == \"new_line_token\":\n",
    "            if   token_list[-1]==\" \":\n",
    "                token_list[-1] = splitted[i]\n",
    "            else:\n",
    "                token_list.append(splitted[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            token_list.append(splitted[i])\n",
    "        i+=1\n",
    "    \n",
    "    return token_list\n",
    "\n",
    "def tokenize_by_characters(text):\n",
    "    return list(text)\n",
    "\n",
    "def tokenize_text(text,mode=\"characters\"):\n",
    "    if mode == \"characters\":\n",
    "        return tokenize_by_characters(text)\n",
    "    elif mode == \"words\":\n",
    "        return tokenize_by_words(text)\n",
    "    \n",
    "tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",mode)\n",
    "#tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",\"words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(tokenize_text(text,mode))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a little portion of text for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = tokenize_text(text,mode)\n",
    "encoded_dataset = np.array([vocab_to_int[c] for c in tokenized_text if c in vocab_to_int], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = batch_size * num_steps #create a single baty\n",
    "validation_start_index = len(encoded_dataset) - validation_size\n",
    "\n",
    "encoded = encoded_dataset[:validation_start_index]\n",
    "encoded_val = encoded_dataset[validation_start_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of \n"
     ]
    }
   ],
   "source": [
    "def encoded_to_text(encoded):\n",
    "    return \"\".join([int_to_vocab[number] for number in encoded])\n",
    "\n",
    "print(encoded_to_text(encoded_val[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_text =encoded_to_text(encoded_val)\n",
    "text = encoded_to_text(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first 100 characters of train and validation, make sure everything is peachy.  line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE COLOUR OUT OF SPACE\\n\\nWest of Arkham the hills rise wild, and there are valleys with deep woods t'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the characters encoded as integersin both train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 49, 56, 15, 74, 10, 58, 10, 63, 73, 15, 10, 63, 46, 15, 10, 65,\n",
       "       15, 66, 77, 57, 74, 56, 84, 84, 53, 83, 54, 45, 15, 29,  8, 15, 57,\n",
       "       39, 19, 82, 14, 96, 15, 45, 82, 83, 15, 82, 44,  5,  5, 54, 15, 39,\n",
       "       44, 54, 83, 15, 89, 44,  5, 97, 31, 15, 14, 48, 97, 15, 45, 82, 83,\n",
       "       39, 83, 15, 14, 39, 83, 15, 79, 14,  5,  5, 83, 32, 54, 15, 89, 44,\n",
       "       45, 82, 15, 97, 83, 83, 91, 15, 89, 29, 29, 97, 54, 15, 45], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 15, 38, 83, 48, 83, 39, 14, 15, 29,  8, 15, 21, 39, 83, 14, 45,\n",
       "       86, 39, 83, 54, 15, 14, 39, 83, 15, 38, 83, 39, 96, 44, 48, 14, 45,\n",
       "       83, 97, 76, 15, 35, 35, 15, 45, 82, 83, 15, 54, 91, 29, 48, 45, 14,\n",
       "       48, 83, 29, 86, 54, 15, 38, 83, 39, 96, 44, 48, 14, 45, 44, 29, 48,\n",
       "       31, 15, 93, 15, 54, 14, 32, 31, 15, 29,  8, 15,  8, 44, 79, 83, 15,\n",
       "       79, 14, 54, 45, 15, 82, 29, 39, 97, 83, 54, 15, 29,  8, 15], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is working with individual english tokens, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training mini-batches\n",
    "\n",
    "Here is where we'll make our mini-batches for training. Remember that we want our batches to be multiple sequences of some desired number of sequence steps. Considering a simple example, our batches would look like this:\n",
    "\n",
    "<img src=\"assets/sequence_batching@1x.png\" width=500px>\n",
    "\n",
    "\n",
    "<br>\n",
    "We have our text encoded as integers as one long array in `encoded`. Let's create a function that will give us an iterator for our batches. I like using [generator functions](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/) to do this. Then we can pass `encoded` into this function and get our batch generator.\n",
    "\n",
    "The first thing we need to do is discard some of the text so we only have completely full batches. Each batch contains $N \\times M$ characters, where $N$ is the batch size (the number of sequences) and $M$ is the number of steps. Then, to get the number of batches we can make from some array `arr`, you divide the length of `arr` by the batch size. Once you know the number of batches and the batch size, you can get the total number of characters to keep.\n",
    "\n",
    "After that, we need to split `arr` into $N$ sequences. You can do this using `arr.reshape(size)` where `size` is a tuple containing the dimensions sizes of the reshaped array. We know we want $N$ sequences (`n_seqs` below), let's make that the size of the first dimension. For the second dimension, you can use `-1` as a placeholder in the size, it'll fill up the array with the appropriate data for you. After this, you should have an array that is $N \\times (M * K)$ where $K$ is the number of batches.\n",
    "\n",
    "Now that we have this array, we can iterate through it to get our batches. The idea is each batch is a $N \\times M$ window on the array. For each subsequent batch, the window moves over by `n_steps`. We also want to create both the input and target arrays. Remember that the targets are the inputs shifted over one character. You'll usually see the first input character used as the last target character, so something like this:\n",
    "```python\n",
    "y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "```\n",
    "where `x` is the input batch and `y` is the target batch.\n",
    "\n",
    "The way I like to do this window is use `range` to take steps of size `n_steps` from $0$ to `arr.shape[1]`, the total number of steps in each sequence. That way, the integers you get from `range` always point to the start of a batch, and each window is `n_steps` wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps \n",
    "    n_batches =  len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr =  arr[:n_batches*batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs,-1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros(x.shape)\n",
    "        y[:,:-1],y[:,-1] = x[:,1:] ,x[:,0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[46 49 56 15 74 10 58 10 63 73]\n",
      " [15 54 83 45 15 14 91 91 83 14]\n",
      " [15 21 14 79 83 39 48 29 86 54]\n",
      " [83 97 15  5 29 29 91 82 29  5]\n",
      " [45  5 32 15 45 29 15 14  5  5]\n",
      " [83 14 39  5 32 15 21 14  5 96]\n",
      " [83 54 15 89 83 39 83 15 14 38]\n",
      " [48 15 14 97 79 14 48 21 83 31]\n",
      " [14 21 83 97 15 97 29 89 48 15]\n",
      " [45 14 44 48  2 54 15 69 14 54]]\n",
      "\n",
      "y\n",
      " [[ 49.  56.  15.  74.  10.  58.  10.  63.  73.  15.]\n",
      " [ 54.  83.  45.  15.  14.  91.  91.  83.  14.   5.]\n",
      " [ 21.  14.  79.  83.  39.  48.  29.  86.  54.  15.]\n",
      " [ 97.  15.   5.  29.  29.  91.  82.  29.   5.  83.]\n",
      " [  5.  32.  15.  45.  29.  15.  14.   5.   5.  29.]\n",
      " [ 14.  39.   5.  32.  15.  21.  14.   5.  96.  31.]\n",
      " [ 54.  15.  89.  83.  39.  83.  15.  14.  38.  14.]\n",
      " [ 15.  14.  97.  79.  14.  48.  21.  83.  31.  15.]\n",
      " [ 21.  83.  97.  15.  97.  29.  89.  48.  15.  91.]\n",
      " [ 14.  44.  48.   2.  54.  15.  69.  14.  54.  83.]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Below is where you'll build the network. We'll break it up into parts so it's easier to reason about each bit. Then we can connect them up into the whole network.\n",
    "\n",
    "<img src=\"assets/charRNN.png\" width=500px>\n",
    "\n",
    "\n",
    "### Inputs\n",
    "\n",
    "First off we'll create our input placeholders. As usual we need placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called `keep_prob`. This will be a scalar, that is a 0-D tensor. To make a scalar, you create a placeholder without giving it a size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"inputs\")\n",
    "    targets = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"targets\")\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Cell\n",
    "\n",
    "Here we will create the LSTM cell we'll use in the hidden layer. We'll use this cell as a building block for the RNN. So we aren't actually defining the RNN here, just the type of cell we'll use in the hidden layer.\n",
    "\n",
    "We first create a basic LSTM cell with\n",
    "\n",
    "```python\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "where `num_units` is the number of units in the hidden layers in the cell. Then we can add dropout by wrapping it with \n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "```\n",
    "You pass in a cell and it will automatically add dropout to the inputs or outputs. Finally, we can stack up the LSTM cells into layers with [`tf.contrib.rnn.MultiRNNCell`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/rnn/MultiRNNCell). With this, you pass in a list of cells and it will send the output of one cell into the next cell. For example,\n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.MultiRNNCell([cell]*num_layers)\n",
    "```\n",
    "\n",
    "This might look a little weird if you know Python well because this will create a list of the same `cell` object. However, TensorFlow will create different weight matrices for all `cell` objects. Even though this is actually multiple LSTM cells stacked on each other, you can treat the multiple layers as one cell.\n",
    "\n",
    "We also need to create an initial cell state of all zeros. This can be done like so\n",
    "\n",
    "```python\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    # Add dropout to the cell outputs\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper( tf.contrib.rnn.BasicLSTMCell(lstm_size),output_keep_prob = keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Output\n",
    "\n",
    "Here we'll create the output layer. We need to connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character, so we want this layer to have size $C$, the number of classes/characters we have in our text.\n",
    "\n",
    "If our input has batch size $N$, number of steps $M$, and the hidden layer has $L$ hidden units, then the output is a 3D tensor with size $N \\times M \\times L$. The output of each LSTM cell has size $L$, we have $M$ of them, one for each sequence step, and we have $N$ sequences. So the total size is $N \\times M \\times L$. \n",
    "\n",
    "We are using the same fully connected layer, the same weights, for each of the outputs. Then, to make things easier, we should reshape the outputs into a 2D tensor with shape $(M * N) \\times L$. That is, one row for each sequence and step, where the values of each row are the output from the LSTM cells. We get the LSTM output as a list, `lstm_output`. First we need to concatenate this whole list into one array with [`tf.concat`](https://www.tensorflow.org/api_docs/python/tf/concat). Then, reshape it (with `tf.reshape`) to size $(M * N) \\times L$.\n",
    "\n",
    "One we have the outputs reshaped, we can do the matrix multiplication with the weights. We need to wrap the weight and bias variables in a variable scope with `tf.variable_scope(scope_name)` because there are weights being created in the LSTM cells. TensorFlow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default. To avoid this, we wrap the variables in a variable scope so we can give them unique names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    seq_output = tf.concat(lstm_output,axis=1)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size),stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros([out_size]))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits =  tf.add(tf.matmul(x,softmax_w),softmax_b) \n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits,name =\"out\")\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss\n",
    "\n",
    "Next up is the training loss. We get the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, we're getting them as encoded characters. Then, reshape the one-hot targets so it's a 2D tensor with size $(M*N) \\times C$ where $C$ is the number of classes/characters we have. Remember that we reshaped the LSTM outputs and ran them through a fully connected layer with $C$ units. So our logits will also have size $(M*N) \\times C$.\n",
    "\n",
    "Then we run the logits and targets through `tf.nn.softmax_cross_entropy_with_logits` and find the mean to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped =  tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_reshaped))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Here we build the optimizer. Normal RNNs have have issues gradients exploding and disappearing. LSTMs fix the disappearance problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip,global_step):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        global_step: to control the total number of train steps\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars),global_step)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "\n",
    "Now we can put all the pieces together and build a class for the network. To actually run data through the LSTM cells, we will use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/dynamic_rnn). This function will pass the hidden and cell states across LSTM cells appropriately for us. It returns the outputs for each LSTM cell at each step for each sequence in the mini-batch. It also gives us the final LSTM state. We want to save this state as `final_state` so we can pass it to the first LSTM cell in the the next mini-batch run. For `tf.nn.dynamic_rnn`, we pass in the cell and initial state we get from `build_lstm`, as well as our input sequences. Also, we need to one-hot encode the inputs before going into the RNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.global_step_tensor = tf.Variable(0,trainable=False,name = \"global_step\")\n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size,num_steps)\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,self.keep_prob)\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs,num_classes)\n",
    "        \n",
    "        self.grad_clip  = grad_clip\n",
    "        # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,x_one_hot,initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs,lstm_size,num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss =  build_loss(self.logits,self.targets,lstm_size,num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss,learning_rate,grad_clip,self.global_step_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here are the hyperparameters for the network.\n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.\n",
    "* `lstm_size` - The number of units in the hidden layers.\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy on training the network:. \n",
    "\n",
    "> ## Tips and Tricks\n",
    "\n",
    ">### Monitoring Validation Loss vs. Training Loss\n",
    ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
    "\n",
    "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
    "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "> ### Approximate number of parameters\n",
    "\n",
    "> The two most important parameters that control the model are `lstm_size` and `num_layers`. I would advise that you always use `num_layers` of either 2/3. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    "\n",
    "> - The number of parameters in your model. This is printed when you start training.\n",
    "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
    "\n",
    ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
    "\n",
    "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `lstm_size` larger.\n",
    "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
    "\n",
    "> ### Best models strategy\n",
    "\n",
    ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_of_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        \n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters*=dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters+= variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for training\n",
    "\n",
    "This is typical training code, passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I save a checkpoint.\n",
    "\n",
    "Here I'm saving checkpoints with the format\n",
    "\n",
    "`i{iteration number}_l{# hidden layer units}.ckpt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = {\"train\":[],\"validation\":[]}\n",
    "x_steps = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting at time: 2017-10-26 01:21:29\n",
      "Number of parameters: 7475814 Dataset size: 2563420\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i20025_l768.ckpt\n",
      "Epoch: 1/15...  Training Step: 20026...  Training loss: 0.6202...  Val loss: 2.2321...  0.3430 sec/batch\n",
      "Epoch: 1/15...  Training Step: 20126...  Training loss: 0.5433...  Val loss: 2.2155...  0.2716 sec/batch\n",
      "Epoch: 1/15...  Training Step: 20226...  Training loss: 0.5360...  Val loss: 2.2163...  0.2857 sec/batch\n",
      "Epoch: 2/15...  Training Step: 20326...  Training loss: 0.5281...  Val loss: 2.2310...  0.2838 sec/batch\n",
      "Epoch: 2/15...  Training Step: 20426...  Training loss: 0.5292...  Val loss: 2.2124...  0.2831 sec/batch\n",
      "Epoch: 2/15...  Training Step: 20526...  Training loss: 0.5208...  Val loss: 2.2054...  0.2738 sec/batch\n",
      "Epoch: 3/15...  Training Step: 20626...  Training loss: 0.5367...  Val loss: 2.1973...  0.2916 sec/batch\n",
      "Epoch: 3/15...  Training Step: 20726...  Training loss: 0.5189...  Val loss: 2.2104...  0.2729 sec/batch\n",
      "Epoch: 3/15...  Training Step: 20826...  Training loss: 0.5373...  Val loss: 2.2183...  0.2906 sec/batch\n",
      "Epoch: 4/15...  Training Step: 20926...  Training loss: 0.5263...  Val loss: 2.2228...  0.2871 sec/batch\n",
      "Epoch: 4/15...  Training Step: 21026...  Training loss: 0.5412...  Val loss: 2.2182...  0.2731 sec/batch\n",
      "Epoch: 5/15...  Training Step: 21126...  Training loss: 0.5337...  Val loss: 2.2237...  0.2732 sec/batch\n",
      "Epoch: 5/15...  Training Step: 21226...  Training loss: 0.5202...  Val loss: 2.2410...  0.2870 sec/batch\n",
      "Epoch: 5/15...  Training Step: 21326...  Training loss: 0.5177...  Val loss: 2.2023...  0.2727 sec/batch\n",
      "Epoch: 6/15...  Training Step: 21426...  Training loss: 0.5294...  Val loss: 2.1884...  0.2732 sec/batch\n",
      "Epoch: 6/15...  Training Step: 21526...  Training loss: 0.5325...  Val loss: 2.2254...  0.2731 sec/batch\n",
      "Epoch: 6/15...  Training Step: 21626...  Training loss: 0.5301...  Val loss: 2.2436...  0.2730 sec/batch\n",
      "Epoch: 7/15...  Training Step: 21726...  Training loss: 0.5305...  Val loss: 2.2616...  0.3083 sec/batch\n",
      "Epoch: 7/15...  Training Step: 21826...  Training loss: 0.5051...  Val loss: 2.2279...  0.2730 sec/batch\n",
      "Epoch: 8/15...  Training Step: 21926...  Training loss: 0.5339...  Val loss: 2.2417...  0.2731 sec/batch\n",
      "Epoch: 8/15...  Training Step: 22026...  Training loss: 0.5237...  Val loss: 2.2339...  0.2731 sec/batch\n",
      "Epoch: 8/15...  Training Step: 22126...  Training loss: 0.5235...  Val loss: 2.2347...  0.2737 sec/batch\n",
      "Epoch: 9/15...  Training Step: 22226...  Training loss: 0.5300...  Val loss: 2.2176...  0.2734 sec/batch\n",
      "Epoch: 9/15...  Training Step: 22326...  Training loss: 0.5050...  Val loss: 2.2393...  0.2732 sec/batch\n",
      "Epoch: 9/15...  Training Step: 22426...  Training loss: 0.5090...  Val loss: 2.2463...  0.2733 sec/batch\n",
      "Epoch: 10/15...  Training Step: 22526...  Training loss: 0.5156...  Val loss: 2.2370...  0.2733 sec/batch\n",
      "Epoch: 10/15...  Training Step: 22626...  Training loss: 0.5154...  Val loss: 2.2296...  0.3082 sec/batch\n",
      "Epoch 10/15 time:73.71400189399719...  finished at 2017-10-26 01:33:50\n",
      "Epoch: 11/15...  Training Step: 22726...  Training loss: 0.5303...  Val loss: 2.2325...  0.2728 sec/batch\n",
      "Epoch: 11/15...  Training Step: 22826...  Training loss: 0.5057...  Val loss: 2.2449...  0.2730 sec/batch\n",
      "Epoch: 11/15...  Training Step: 22926...  Training loss: 0.4921...  Val loss: 2.2296...  0.2730 sec/batch\n",
      "Epoch: 12/15...  Training Step: 23026...  Training loss: 0.5354...  Val loss: 2.2278...  0.2729 sec/batch\n",
      "Epoch: 12/15...  Training Step: 23126...  Training loss: 0.5063...  Val loss: 2.2361...  0.2728 sec/batch\n",
      "Epoch: 12/15...  Training Step: 23226...  Training loss: 0.5042...  Val loss: 2.2438...  0.2731 sec/batch\n",
      "Epoch: 13/15...  Training Step: 23326...  Training loss: 0.5251...  Val loss: 2.2327...  0.2735 sec/batch\n",
      "Epoch: 13/15...  Training Step: 23426...  Training loss: 0.5012...  Val loss: 2.2345...  0.2739 sec/batch\n",
      "Epoch: 14/15...  Training Step: 23526...  Training loss: 0.5091...  Val loss: 2.2236...  0.2733 sec/batch\n",
      "Epoch: 14/15...  Training Step: 23626...  Training loss: 0.5006...  Val loss: 2.2593...  0.2735 sec/batch\n",
      "Epoch: 14/15...  Training Step: 23726...  Training loss: 0.5096...  Val loss: 2.2412...  0.2916 sec/batch\n",
      "Epoch: 15/15...  Training Step: 23826...  Training loss: 0.5164...  Val loss: 2.2304...  0.2735 sec/batch\n",
      "Epoch: 15/15...  Training Step: 23926...  Training loss: 0.5104...  Val loss: 2.2514...  0.2846 sec/batch\n",
      "Epoch: 15/15...  Training Step: 24026...  Training loss: 0.5123...  Val loss: 2.2732...  0.2850 sec/batch\n",
      "Training ending at time: 2017-10-26 01:40:02\n",
      "Trainint total time: 1113.7254118919373\n"
     ]
    }
   ],
   "source": [
    "#epochs = 1\n",
    "# Save every N iterations\n",
    "save_every_n = 500\n",
    "print_loss_every_n = 100\n",
    "sample_every = 500\n",
    "print_epoch_time_every = 10\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "    #print(\"after model\")\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "print(\"Training starting at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "train_start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Number of parameters:\",get_number_of_parameters(),\"Dataset size:\",len(encoded))\n",
    "    #print(\"after initializer\")\n",
    "    if resume_from_checkpoint:\n",
    "        latest_checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            \n",
    "            \n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "        \n",
    "            \n",
    "            end = time.time()\n",
    "            if counter%print_loss_every_n == 0:\n",
    "                val_batches = get_batches(encoded_val,int(len(encoded_val)/num_steps),num_steps)\n",
    "                x_val,y_val = next(val_batches)\n",
    "                \n",
    "                val_dict = {model.inputs: x_val,\n",
    "                            model.targets: y_val,\n",
    "                            model.keep_prob: 1,\n",
    "                            model.initial_state: new_state}\n",
    "                \n",
    "                val_loss,prediction = sess.run([model.loss,model.prediction],feed_dict=val_dict)\n",
    "                \n",
    "                losses[\"train\"].append(batch_loss)\n",
    "                losses[\"validation\"].append(val_loss)\n",
    "                \n",
    "                \n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                x_steps.append(global_step)\n",
    "                \n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(global_step),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      'Val loss: {:.4f}... '.format(val_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "                \n",
    "            counter += 1\n",
    "            #learning_rate*=0.75\n",
    "            #model.optimizer = build_optimizer(model.loss,learning_rate,model.grad_clip,model.global_step_tensor)\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "        \n",
    "        \n",
    "        if ((e+1) % print_epoch_time_every== 0):\n",
    "            print('Epoch {}/{} time:{}...'.format(e+1,epochs,epoch_end-epoch_start),\n",
    "                 \" finished at\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "        \n",
    "            \n",
    "    global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "    saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "    \n",
    "print(\"Training ending at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "print(\"Trainint total time:\",time.time()-train_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAH0CAYAAACNesOUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd0ec040ba8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 375
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_steps,losses[\"train\"],label=\"Train loss\")\n",
    "plt.plot(x_steps,losses[\"validation\"],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved checkpoints\n",
    "\n",
    "Read up on saving and loading checkpoints here: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints = tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling final trained model\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \",mode=\"characters\"):\n",
    "    print(mode)\n",
    "    samples = tokenize_text(prime,mode)\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in tokenize_text(prime,mode):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples).replace(\"new_line_token\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/mcharacters_i24030_l768.ckpt'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new text from \"base\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "\n",
    "\n",
    "samples = list()\n",
    "for text in text_to_try:\n",
    "    #print(\"------------------------\",text)\n",
    "    samples.append( sample(checkpoint, 500, lstm_size, len(vocab), prime=text,mode=mode))\n",
    "    #print(samp)\n",
    "    #print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ In the first place\n",
      "In the first place, as reed as much as possible with the whirl of the St. Jocascrer's insteat of the Oce or the Reville from Bullen Moueta, where it is not the surviving. Titting of Meloon, emig to uttlanqt when with and indised and outside which more me think; and it was clut here more than he had been; and it was not a particular would aeoot about menicial for anyther. Watewiy and pleasant infities were those of the other things to himself. I\n",
      "vaviedly collecting a caution from some sort of febrile and feeling at\n",
      "------------------------\n",
      "------------------------ the night before\n",
      "the night before, the desize tremblings of the bushes grow slipped off by a corridor within the course upon the terrible, as it was his own notion under such a being in the property or sicher tway that fancy could this can be blown. At topic only for any odour reached him with a minutely position. And all the waited walls and violet seeker, and traverse to the fantastic, he thought he had seen in the distant age the land, arouse, so that he learned letter, and even here to grasp me to the advance sadd, paterally\n",
      "------------------------\n",
      "------------------------ horror\n",
      "horror three other cats and inhasing the corridor walls reforbed. The thought of this dead silled me from evolve and he heard the angels of artercoining cation. When it did, he seemes found as to preserve the arts, and did nothinged her ascenwary baluscenum of perhaps an empty radiation. Her frightened metmodes of thousand millious scarts are never choreed and calling way by some regions repetition or twist-houses in the long dead with the exception which the most terrific plunge was sheer domed.iT; o\n",
      "------------------------\n",
      "------------------------ creature\n",
      "creature it will be notimed a metory. In the mids of agony I saw therein, that the manner in what I had completel taining our costing or examine. Both Akeley was consisted of two belongings to a second mater as well as from\n",
      "one near the\n",
      "woman; in the linge of foot other was forced to\n",
      "render our fine foresements. A wild sens it in a station of the lower alloyed me, in a contemptible intersection, as if those of action more than in the language of my former planes, if why it had been utterly searched in th\n",
      "------------------------\n",
      "------------------------ night\n",
      "night, or the lips, luckining mary all the primal legend) the shore of buildings and unidoutl through a sort of diabolic thunderough archants and barren; and that she was of all seemed to exist. Once more carving angulous in its mouthful construction ahead in the mutious city; but the former and exects would be under the sense of the old whisters who had come to the top wholly in his owlieg cown sleep. In three sailors, and rowed- that able too greeped the significanc labra of iridges which the fragme\n",
      "------------------------\n",
      "------------------------ dream\n",
      "dreamed; for he knew they caught from the left hyen three feet and fifty to the earth. Shiverage being neither party offers, rouses, and impages of consciousness which by this few parts so coming in, not, from the pass they will be remembered the general series of dark colouredrs. Tseaking nowed the line of old and three innacest and loathing, I saw that the rustling account which we were accomnodage as eternelly and unmistakable for the consumment the mythical progress where men before, if their made\n",
      "------------------------\n",
      "------------------------ thing\n",
      "things being sure to bear.\n",
      "\n",
      "Shall I twone town, I wa amingting to the crates at the left around her own, when we could breathe\n",
      "with as much as this as fer, but my\n",
      "entire point between the mainly filed state of my reference, but there were nevel and some patient life. The burnic gave me no commencement, from any strange delusion.\n",
      "     For many c ptsimps, till at last againing\n",
      "the used to me. I took from my person, too, that the man who had tas everybed rapid the youth, magicive, madinnisite was daily. \n",
      "------------------------\n",
      "------------------------ That night\n",
      "That night were the oncestrure. I felt above those farther sunk of strangeness. This time, had no remain croice and gave a ripling and raising, and the battleftleng Muse Stree rooke that he had begun to habet, with prince his pevil's terror. It if the most right I was able to find any diorible studen. I have before see he steaded his parenth's\n",
      "possess, and so perfectly seen before me, arrever, every ngite of a naugat. He arose furnitures, with these must thinkeed in some wrong-paper ruinancurations;\n",
      "but I \n",
      "------------------------\n",
      "------------------------ mountain\n",
      "mountains sheather upon my present peculity, and several sparen or contrivably wide enotentally as if in answer toit ten from some aperture with all its irmated dense consciousness on the face of the purpose to denthur his companion from a farther personal expedience. What weather, havied wirst imploning a faint like a monstrous moonless sky. It was turn to say that a gloriousness older they had a shock on the ridge. Off our own hour the glass grown sideed people at wait for the first strained. It is tru\n",
      "------------------------\n",
      "------------------------ Ammi\n",
      "Ammi stravelt during the chamber to Carter any great impressions brought to light. The door sometimesplaced in spite of a sensitive memory which for everyone wishes nor had their stumpers formed a certain timenes--top, the first and a prevocule trunk, less than thirdestry this day before, and one ago had ever should have gone, and that they all leaphants with staring eyes them thus tied to the planet. The moonlithent ham wait in the well-remember frombtale on the coast. The heating was, as poising, a\n",
      "------------------------\n",
      "------------------------ Cthulhu\n",
      "Cthulhu she camm natalty in givts for actual vitality. But when there is smitting a diffcent trees as never before had precided him before --and I would indvive some wide exposed brave unnameabound notwary exchening edders w o saw that some distance from the room of mocking, did inceesing a help, and, in an instant, half a mine to the most\n",
      "race overboard. As it was\n",
      "something closely what I had so stirred, thandage and passed over them. The sideway\n",
      "to get home from the immense in whic not all irritabs ab\n",
      "------------------------\n",
      "------------------------ raven\n",
      "raven. Beings soon, she can be put it, but if they deliced the doctor transport. It was the same, say he had once fully resigned to the face of a change of curse; and the words in face, the ghast, still very landed. It is on one of those things I could not doubt what was partly proved. The trail darkness apoin practiced in the other very carefully carved from a confident and enawoman of horror a soft new grass a re---sekely the classical of the boneful grasp. It was very pleast; and, with the fa fragr\n",
      "------------------------\n",
      "------------------------ bird\n",
      "birdyperhaps impassaller. It was   no motiest when his chis severe roundered mitder of an irrelevantly pagentone, glibbering in a struggle again, and the steps leading formerly or desperate attacked by t ress under a fronting memora in a veryol mile that written on the floor.\n",
      "     At last all the torch which these possible seams then sad have once examies everything whose record; here that the apparent worldiss ocational civilisation, and the greater part of the monstrous that hill no trace of waiti\n",
      "------------------------\n",
      "------------------------ nevermore\n",
      "nevermore and the long-look was night.\n",
      "It was firmly proceered, for in the afternoon he detected the other, the most famically harmless to.\n",
      "\n",
      "Willett had ever seensy rising, however, to say, from what seemed to be the lawd fluxt-like suitable piecing out of the wespend's reading, while the party searched our  ascendant to tracks from the black skylight past, and a feeble glimpee in the vague and trailibl Warker, the nature of the bay-grip developmentand contrarces, and dogratudeomy vacutt more non-succes \n",
      "------------------------\n",
      "------------------------ dead\n",
      "dead of fifteen minutes and temped its terrible, beyond the clock down well in this manner was about to be fragments of\n",
      "every respect or surprise. The form had prepared torn to let thes can be numedoatted and alpared conclesions. He recorded the movative beaus as I had sillnest trunched every insect which we had evidently gettered the probable compassion of below enoughI hauge the everhtory of our footfills, thought, and point, but he had not only notice, nor did these sensitions closely alone dark,\n",
      "------------------------\n",
      "------------------------ The bird\n",
      "The birds of Medome on ye--sallow and in mine conversations that the coming demonser, commi taskeround it in\n",
      "the fluin, and ever, another on the sea-bottem, but much risund, she had far ever saved us for\n",
      "his boook; and as she doubted the carconic realm of the directity at the centre of the tunnel with its floating visiborsly bole and she reseeded, arrividetcy on the house-he saw it whose steed long and lower leaving, ragged or dreamed or salling and screame, were many times of times winder in their brill\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_to_try)):\n",
    "    text = text_to_try[i]\n",
    "    generated = samples[i]\n",
    "    print(\"------------------------\",text)\n",
    "    print(generated)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/mcharacters_i24030_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i22526_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i23026_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i23526_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i24026_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i24030_l768.ckpt\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "The old folk have gone away, and we not could be determined to decline them i control. I now looked at theter for those thanks. He was,esser--\n",
      " \"Phan the cheerly -- and dy nothing is to catch a mying\" shrudderly and absolutely, expected upon the spot. Nor par by the lumber to attracted the lumber --the matter. Tode nowe, too, what of a long time in a very troulle suggestion -- avery curious beings not take occal.\n",
      "     An the subject of the month seads, I could not hermit, have been rendered forward of a yall, as now reached me in our fever. We must finign in my engire\n",
      "to restict a thing line at the house. In strange portions to bo love, and with them, he usually continue as had been or opened to our\n",
      "suspect, grotesque, and irretucally at the innucifice of the lungs.\n",
      "     West, dunkest principall, he said, even offen that it was not always fasting, in storm, had at least checked there among its wroughts, they defined upon him, we genuendly feared at the sound I scroped, aside paused deabling, and so fastoning\n",
      "through a trail boly of a mone effective natural in sight of the sense of mind-territus design, and the paragraps still others, but evingnce, that the sashes of this narrange in the narrow love of\n",
      "the room, which had been within his armstairs, as\n",
      "ifor the much through which had our\n",
      "reason be heard what he said, \"I was not wonder, thus I had been seen in greater despite the supposing curiousity, that I was total except that it seemed to me the stonewife. Of course not so much which may be\n",
      "no ordinary oblet even doning he had been to this part of the size on three who had known h described dizzy\n",
      "slight vague, like winds; and entering the frantical hue not found in the world of man that his mouth and she could, to me mutt have exceeded everytophed since off, alrations, and muscled at this room, and as far as they then from about her, he admirated anythingly upon a passage through the right floor above him. We had finished his voice in the colonias deadly places, and sure that twenty-four exagerald the frightful literals were cadven into the abyss. It was the slant-eyed insacestry of those four file forested. Certain Dessetts anew in rambling things, indeed were better thing and so far as theyseave resounded. As Towars had venomitating the limits of the event was now abnormally perfect,d aperating for any other minute flapping entra pantage of elsewhere. He slained in a huge horror and all hours it would be familiar to enter into the disorder. From which many hand spent most flamps of a dark study throse carefully for thousands accomplish. It was never surely sickeningly around only with some size behend any ofdern mamored to them. Again I considered statemedt that the crowned statues he ceased to strokes in the glob and the temples bengaumed. Of course seemed vividly that the alienists shot offered his entire excess between the ruiners beheld.\n",
      "\n",
      "    It was somewhat residence, but as to these thic faery who, I could not help thinking of the dust, to lay throubh the desert on the park of\n",
      "my hands, allhowed vained, the arrangement of look and the flung of my dreams.\n",
      "\n",
      "And then human eyeland liminurable elder breeged the sandy --but the ship I was that on that a mannem I leaped by one of years ago tog. In a right angle of mislacho entertained, or their things; a while throat was replaced, I at sealch without attimis to represent the normal matter. The brig was getting throughout the pleasure of his bohing; and it was difficulty in a long time that had purposely expected it, and, that were then,\n",
      "as I speak, into the student which a manked willed each off a trope to with no exusing himself, if indees the wide matter is that on the inside exaginition of you; according to the consciou of all the fat such whisperists as rustless wiace. The weather was great\n",
      "lash as hurt unter their mode ages of machines, and in sight of the punernal stage of our lines of either photogrophs, and only\n",
      "the course\n",
      "by tall with the shadow-captains, we came at last; and thought he did not like to speak of the precipice, thinking at this period, no second to human beings from out of shore. It was  that they had indeed lived an eye in the daemon-like and. It was, I can do fuss to deep in my situation, and everyone several perverse in incoccutting its perception. The gruff voy on the middle was\n",
      "over. The more than reaching them is still alive. His adventure was resigned with the shadows and apprehension of matters, in which\n",
      "we stood our condition or might have drownedus, even an opportunity of any interval when\n",
      "he said, was one of those unhalley,and, the weathering worsed oves the fragmentary\n",
      "disrifihing under fur halt a trembling white pursued in the intermed and furtive regularis; and something in the largest one about a field all as one surge. He saw of the head bentation no doubt upon the subject; and endeavoes to the\n",
      "feetch, horror move, mims and camer were of how to admit, his advanced fortabits, for this shouted and\n",
      "dragoim, admitting right leaning to the cast, \n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The old folk have gone away\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i24030_l768.ckpt\n",
      "The thing that should not be; for course it is fortaback; as indestrusing tnowes, had been lying at all; since in all that had an add floor world of the burboos as a pleasant. The body was the least and unexplaced marshinatic officularity in streams, and were display, and numerous, in the intention that the vivic field to be wished to sea him for all. The loose said he sat that much of the centre dwellings in the same damp asparent lander of the steer fore, and before my attention in red clothing of some odour property. We saw several of the inner thereors; and that the rubs hwice hastened us in such succession, such as away, despite the thought of the purpose of refrescmest. To\n",
      "the nature of the passionate and ard was point to me, by much were out security. Therenaft of\n",
      "Augustus, whom\n",
      "we saw that there were the mind of some fat of\n",
      "the former experiment, might in not after his\n",
      "own condition.\n",
      "\n",
      "    It was on the evening of July 14th in Akeleys city, we were to uncre kind, however, taken their accomplishments and abominable, manners, and the sides of the old slight thickeent, and the man and the creaking mnthological sightest them. Highwap, placed on his temporalea a faint, but now I could not attempt tell then youn on conceivably clain. No infamous reasons bad shering of directic force that wend in what lashed surviving melting offandous trips fol only by his party whine sculptured all is a vestige of position in the midst. It was nothing whitefer, to cry if, and wiel not perceive that: \n",
      "\n",
      "In thele islanes, I even shriek any proceed, for the sloper parts that fell through its accession there of naturally peril offerding them in by matter.\n",
      "\n",
      "    From the pictures, however, the girvet executed conditions, the numb ones ender to later years off, and did not coincime a few green itself with a cautious horror and thinking that occasioned me over their profound signing. Then came without notion, and this was there were chanting- to be asserted in consequence. Mr. Juckeraral had heart the powders party, and all the madness of the bulkering entitely of the desert and passing of the terrible kindred ways. Peters cannot bot over be presentation in them even in the inner species of sort, and the waking worse strangh Cyclopean spot had one tack and carefully passed without truntic experience.\n",
      "\n",
      "    One day Clarks traims the senting Bulknes, resumed his close dreams and facities. If they were trosped the witch their three feelings on earthward earth.\n",
      "     Around the fear would get home as they had become a group of homortholess like a glory of dreaded cuttings coating on the former on the hinting of some of the lore of gods that had occurred.\n",
      "     I threw in the running tool at a time, something of the bride, the creatures came down at near rage of the ancient titteness and instruments. Sold and magnificens and distarped dreams were talked on rough lonelyss. There was no small going when thatless depends made more encinesction indeed. It was persistently, to prevent the excrising reports of all thisses which are undermeded in a great sculpture; thlowing to his foreforw before the floor all the cave near the boats they hung abones in, and embeaured that his grandfather had become himself in the hold. It was a study of wailing the shadowy before the race a parphtrad taske, bus believed nerta io. How he could not, have been ability that we would shew hegry steep by expecian conestaling fibriction toward which the fa farmers month was diverse.\n",
      "     Off off the forgotten legs lettered in with these housetal, tentied the light of the hills week at it, and afterward between the increasingly unhollingly resembling the high-poinced paws which the old slant-eyed man's feelings would proce, that newer great stone date wasing that the document would be little tried my spirit. I knew like the castar. It was  that hints were found to get up and the enty on thi wing all leaning party at the bottom of the surprise. There was a great steph and papered, and were made conscion of the fastenings. We achoged my assurr empers willing to me after the present demand. At first interruption slowed me in the cabin into the heart, and the throats of fridar property, and\n",
      "were clothed there are from\n",
      "something which I had thrown his hends for him to believe that any other species cannesses that had come down from her mombit to black acquirement on theirs of modious ned the shape of the scattered picts and that entity he was surround up by those  trainight, while inhalined ofar, subject ty an ancient pallid head wnought in hands; and for almost the authorthing must stuel or lying, and with every corneration. Hat I dou must be kescene with the space of a highly tone or force. The date was unmistakable, though one but nocroples they were to bed; becade mystery of determine in as much to a great incalculable diseasonic point as that of man who had been ritually not even me to exert the cat at the time of our making the words like and thrown down to the villages and a revillability c\n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The thing that should not be\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
