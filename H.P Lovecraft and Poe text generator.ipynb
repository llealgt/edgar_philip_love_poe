{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks for H.P Lovecraft text generation\n",
    "\n",
    "\"The color out of space\" is one of my favorite tales from Lovecraft, i will use it(as well as others as the call of cthulhu) to create a recurrent neural network in tensorflow that learns his style and generates new text in his style\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn) and an example from \"Deep Learning Nanodegree\" on udacity. Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. \n",
    "\n",
    "## General architecture using \"Long short term memory\" units in the recurrent layers\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime ,localtime\n",
    "import shutil\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only the  first time nltk is used to download language\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define conf variables and hyper parameteters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "mode = \"characters\" #characters or words\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 64       # Sequences per batch\n",
    "num_steps = 400         # Number of sequence steps per batch\n",
    "lstm_size = 2048         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.000075 # Learning rate\n",
    "keep_prob = 1# Dropout keep probability\n",
    "negative_sampled = 100 #in words mode ,how many negative words to sample to improve trainint time\n",
    "\n",
    "resume_from_checkpoint = True\n",
    "delete_checkpoints  = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = \"words\" #characters or words\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 64       # Sequences per batch\n",
    "num_steps = 50         # Number of sequence steps per batch\n",
    "lstm_size = 1024         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.0001 # Learning rate\n",
    "keep_prob = 1# Dropout keep probability\n",
    "negative_sampled = 43000 #in words mode ,how many negative words to sample to improve trainint time\n",
    "\n",
    "resume_from_checkpoint = False\n",
    "delete_checkpoints  = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not resume_from_checkpoint and delete_checkpoints and os.path.exists(\"./checkpoints/\"):\n",
    "    shutil.rmtree(\"./checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base text\n",
    "Once trained ,the network can take base text and a sequence size and generate new text using base text as first characters in the sequence. For every element in base text wi will create a list that will store generated text as training goes, to be able to compare results between steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_try = [\"In the first place\",\"the night before\",\"horror\",\"creature\",\"night\",\"dream\",\"thing\",\"That night\",\"mountain\",\"Ammi\",\"Cthulhu\",\"raven\",\"bird\",\"nevermore\",\"dead\",\"The bird\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that separates text into tokens(for whitespace characters, only new line is implemented, missing tabs and others="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " ' ',\n",
       " 'my',\n",
       " ' ',\n",
       " 'name',\n",
       " ' ',\n",
       " 'is',\n",
       " ' ',\n",
       " 'Luis',\n",
       " ' ',\n",
       " 'Leal',\n",
       " '!',\n",
       " 'new_line_token',\n",
       " 'new_line_token',\n",
       " 'From',\n",
       " ' ',\n",
       " 'Guatemala',\n",
       " ' ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_by_words(text):\n",
    "    text = text.replace(\"\\n\",\" new_line_token \")\n",
    "    tokens = []\n",
    "    splitted =[[word_tokenize(w),' ']for w in text.split()]\n",
    "    splitted = list(itertools.chain(*list(itertools.chain(*splitted))))\n",
    "    \n",
    "    token_list = []\n",
    "    i = 0\n",
    "    while i < len(splitted):\n",
    "        if splitted[i] == \"new_line_token\":\n",
    "            if   token_list[-1]==\" \":\n",
    "                token_list[-1] = splitted[i]\n",
    "            else:\n",
    "                token_list.append(splitted[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            token_list.append(splitted[i])\n",
    "        i+=1\n",
    "    \n",
    "    return token_list\n",
    "\n",
    "def tokenize_by_characters(text):\n",
    "    return list(text)\n",
    "\n",
    "def tokenize_text(text,mode=\"characters\"):\n",
    "    if mode == \"characters\":\n",
    "        return tokenize_by_characters(text)\n",
    "    elif mode == \"words\":\n",
    "        return tokenize_by_words(text)\n",
    "    \n",
    "tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",mode)\n",
    "#tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",\"words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(tokenize_text(text,mode))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "n_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a little portion of text for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenize_text(text,mode)\n",
    "encoded_dataset = np.array([vocab_to_int[c] for c in tokenized_text if c in vocab_to_int], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = batch_size * num_steps #create a single baty\n",
    "validation_start_index = len(encoded_dataset) - validation_size\n",
    "\n",
    "encoded = encoded_dataset[:validation_start_index]\n",
    "encoded_val = encoded_dataset[validation_start_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " when I did be let rise, and they that tended me, carried me to one of the Quiet Gardens of the Pyramid; and they set me there, and did seem to leave me alone. And there came One then around a bush, and lookt at me a\n"
     ]
    }
   ],
   "source": [
    "def encoded_to_text(encoded):\n",
    "    return \"\".join([int_to_vocab[number] for number in encoded])\n",
    "\n",
    "print(encoded_to_text(encoded_val[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_text =encoded_to_text(encoded_val)\n",
    "text = encoded_to_text(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first 100 characters of train and validation, make sure everything is peachy.  line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE COLOUR OUT OF SPACEnew_line_tokennew_line_tokenWest of Arkham the hills rise wild, and there are'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' when I did be let rise, and they that tended me, carried me to one of the Quiet Gardens of the Pyra'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the characters encoded as integersin both train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41368, 33122, 16456, 33122, 23073, 33122, 25467, 33122, 11455,\n",
       "        6911,  6911, 21011, 33122,  7615, 33122, 14396, 33122, 41800,\n",
       "       33122, 15141, 33122, 41669, 33122, 13597, 21634, 33122, 33306,\n",
       "       33122, 24695, 33122, 36481, 33122, 20584, 33122, 17785, 33122,\n",
       "       24182, 33122, 27429, 33122,  5984, 33122,  1119, 33122, 38832,\n",
       "       33122, 28671, 33122, 35125, 33122, 32507, 37342, 33122, 18506,\n",
       "       33122, 36481, 33122, 12285, 33122, 28060, 33122,  8659, 33122,\n",
       "       25301, 33122, 41800, 33122,  1800, 33122, 13150, 33122, 35556,\n",
       "       21634, 33122, 33306, 33122, 25301, 33122, 11890, 33122,  3295,\n",
       "       33122, 24396, 33122, 11113, 33122, 35125, 33122, 37628, 33122,\n",
       "       12887, 33122, 41800, 33122, 37687, 33122,  7615, 33122,  5569,\n",
       "       37342], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33122, 27139, 33122, 24881, 33122, 21461, 33122, 41238, 33122,\n",
       "       10589, 33122, 41669, 21634, 33122, 33306, 33122,  8028, 33122,\n",
       "        5984, 33122,  3962, 33122, 40176, 21634, 33122, 14207, 33122,\n",
       "       40176, 33122, 42194, 33122, 10697, 33122,  7615, 33122, 41800,\n",
       "       33122, 42420, 33122, 24055, 33122,  7615, 33122, 41800, 33122,\n",
       "       22465,  9514, 33122, 33306, 33122,  8028, 33122, 35903, 33122,\n",
       "       40176, 33122, 24695, 21634, 33122, 33306, 33122, 21461, 33122,\n",
       "       42065, 33122, 42194, 33122, 10319, 33122, 40176, 33122,  5449,\n",
       "       37342, 33122,  1193, 33122, 24695, 33122, 11596, 33122,   829,\n",
       "       33122, 41053, 33122, 41848, 33122, 39963, 33122, 38241, 21634,\n",
       "       33122, 33306, 33122,  4065, 33122, 38625, 33122, 40176, 33122,\n",
       "       39963], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is working with individual english tokens, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training mini-batches\n",
    "\n",
    "Here is where we'll make our mini-batches for training. Remember that we want our batches to be multiple sequences of some desired number of sequence steps. Considering a simple example, our batches would look like this:\n",
    "\n",
    "<img src=\"assets/sequence_batching@1x.png\" width=500px>\n",
    "\n",
    "\n",
    "<br>\n",
    "We have our text encoded as integers as one long array in `encoded`. Let's create a function that will give us an iterator for our batches. I like using [generator functions](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/) to do this. Then we can pass `encoded` into this function and get our batch generator.\n",
    "\n",
    "The first thing we need to do is discard some of the text so we only have completely full batches. Each batch contains $N \\times M$ characters, where $N$ is the batch size (the number of sequences) and $M$ is the number of steps. Then, to get the number of batches we can make from some array `arr`, you divide the length of `arr` by the batch size. Once you know the number of batches and the batch size, you can get the total number of characters to keep.\n",
    "\n",
    "After that, we need to split `arr` into $N$ sequences. You can do this using `arr.reshape(size)` where `size` is a tuple containing the dimensions sizes of the reshaped array. We know we want $N$ sequences (`n_seqs` below), let's make that the size of the first dimension. For the second dimension, you can use `-1` as a placeholder in the size, it'll fill up the array with the appropriate data for you. After this, you should have an array that is $N \\times (M * K)$ where $K$ is the number of batches.\n",
    "\n",
    "Now that we have this array, we can iterate through it to get our batches. The idea is each batch is a $N \\times M$ window on the array. For each subsequent batch, the window moves over by `n_steps`. We also want to create both the input and target arrays. Remember that the targets are the inputs shifted over one character. You'll usually see the first input character used as the last target character, so something like this:\n",
    "```python\n",
    "y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "```\n",
    "where `x` is the input batch and `y` is the target batch.\n",
    "\n",
    "The way I like to do this window is use `range` to take steps of size `n_steps` from $0$ to `arr.shape[1]`, the total number of steps in each sequence. That way, the integers you get from `range` always point to the start of a batch, and each window is `n_steps` wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps \n",
    "    n_batches =  len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr =  arr[:n_batches*batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs,-1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros(x.shape)\n",
    "        y[:,:-1],y[:,-1] = x[:,1:] ,x[:,0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[41368 33122 16456 33122 23073 33122 25467 33122 11455  6911]\n",
      " [33122 24267 33122 37573 33122 39963 33122 13324 33122 24881]\n",
      " [33122 30285 33122 20996 21634 33122   986 33122   506 33122]\n",
      " [33122 22060 33122 27146 33122 30321 33122 24182 33122 31808]\n",
      " [33122   175 33122 13133 37342  6911 43036 33122 31764  9397]\n",
      " [22060 33122 32530 33122 29526 37342  6911  4419 33122 20969]\n",
      " [33122 39195 33122  6898 33122  2551 33122 40176  9514 33122]\n",
      " [17770  9514 33122 32652 33122 37252  6911  3079 33122  1696]\n",
      " [33122  4419 33122 16640 33122 32652 33122 42194 33122 30426]\n",
      " [33306 33122 10789 33122 24881 33122 21461 33122 41238 33122]]\n",
      "\n",
      "y\n",
      " [[33122. 16456. 33122. 23073. 33122. 25467. 33122. 11455.  6911.  6911.]\n",
      " [24267. 33122. 37573. 33122. 39963. 33122. 13324. 33122. 24881. 15310.]\n",
      " [30285. 33122. 20996. 21634. 33122.   986. 33122.   506. 33122. 41800.]\n",
      " [22060. 33122. 27146. 33122. 30321. 33122. 24182. 33122. 31808. 33122.]\n",
      " [  175. 33122. 13133. 37342.  6911. 43036. 33122. 31764.  9397.  3761.]\n",
      " [33122. 32530. 33122. 29526. 37342.  6911.  4419. 33122. 20969. 21634.]\n",
      " [39195. 33122.  6898. 33122.  2551. 33122. 40176.  9514. 33122.  3314.]\n",
      " [ 9514. 33122. 32652. 33122. 37252.  6911.  3079. 33122.  1696. 33122.]\n",
      " [ 4419. 33122. 16640. 33122. 32652. 33122. 42194. 33122. 30426. 33122.]\n",
      " [33122. 10789. 33122. 24881. 33122. 21461. 33122. 41238. 33122. 41147.]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Below is where you'll build the network. We'll break it up into parts so it's easier to reason about each bit. Then we can connect them up into the whole network.\n",
    "\n",
    "<img src=\"assets/charRNN.png\" width=500px>\n",
    "\n",
    "\n",
    "### Inputs\n",
    "\n",
    "First off we'll create our input placeholders. As usual we need placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called `keep_prob`. This will be a scalar, that is a 0-D tensor. To make a scalar, you create a placeholder without giving it a size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"inputs\")\n",
    "    targets = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"targets\")\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Cell\n",
    "\n",
    "Here we will create the LSTM cell we'll use in the hidden layer. We'll use this cell as a building block for the RNN. So we aren't actually defining the RNN here, just the type of cell we'll use in the hidden layer.\n",
    "\n",
    "We first create a basic LSTM cell with\n",
    "\n",
    "```python\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "where `num_units` is the number of units in the hidden layers in the cell. Then we can add dropout by wrapping it with \n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "```\n",
    "You pass in a cell and it will automatically add dropout to the inputs or outputs. Finally, we can stack up the LSTM cells into layers with [`tf.contrib.rnn.MultiRNNCell`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/rnn/MultiRNNCell). With this, you pass in a list of cells and it will send the output of one cell into the next cell. For example,\n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.MultiRNNCell([cell]*num_layers)\n",
    "```\n",
    "\n",
    "This might look a little weird if you know Python well because this will create a list of the same `cell` object. However, TensorFlow will create different weight matrices for all `cell` objects. Even though this is actually multiple LSTM cells stacked on each other, you can treat the multiple layers as one cell.\n",
    "\n",
    "We also need to create an initial cell state of all zeros. This can be done like so\n",
    "\n",
    "```python\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    # Add dropout to the cell outputs\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper( tf.contrib.rnn.BasicLSTMCell(lstm_size),output_keep_prob = keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Output\n",
    "\n",
    "Here we'll create the output layer. We need to connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character, so we want this layer to have size $C$, the number of classes/characters we have in our text.\n",
    "\n",
    "If our input has batch size $N$, number of steps $M$, and the hidden layer has $L$ hidden units, then the output is a 3D tensor with size $N \\times M \\times L$. The output of each LSTM cell has size $L$, we have $M$ of them, one for each sequence step, and we have $N$ sequences. So the total size is $N \\times M \\times L$. \n",
    "\n",
    "We are using the same fully connected layer, the same weights, for each of the outputs. Then, to make things easier, we should reshape the outputs into a 2D tensor with shape $(M * N) \\times L$. That is, one row for each sequence and step, where the values of each row are the output from the LSTM cells. We get the LSTM output as a list, `lstm_output`. First we need to concatenate this whole list into one array with [`tf.concat`](https://www.tensorflow.org/api_docs/python/tf/concat). Then, reshape it (with `tf.reshape`) to size $(M * N) \\times L$.\n",
    "\n",
    "One we have the outputs reshaped, we can do the matrix multiplication with the weights. We need to wrap the weight and bias variables in a variable scope with `tf.variable_scope(scope_name)` because there are weights being created in the LSTM cells. TensorFlow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default. To avoid this, we wrap the variables in a variable scope so we can give them unique names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "    print(lstm_output)\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    seq_output = tf.concat(lstm_output,axis=1)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size),stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros([out_size]))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits =  tf.add(tf.matmul(x,softmax_w),softmax_b) \n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits,name =\"out\")\n",
    "    \n",
    "    return out, logits,softmax_w,softmax_b,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss\n",
    "\n",
    "Next up is the training loss. We get the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, we're getting them as encoded characters. Then, reshape the one-hot targets so it's a 2D tensor with size $(M*N) \\times C$ where $C$ is the number of classes/characters we have. Remember that we reshaped the LSTM outputs and ran them through a fully connected layer with $C$ units. So our logits will also have size $(M*N) \\times C$.\n",
    "\n",
    "Then we run the logits and targets through `tf.nn.softmax_cross_entropy_with_logits` and find the mean to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(lstm_output,logits, targets, lstm_size, num_classes,softmax_w,softmax_b):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped =  tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    if mode == \"characters\":\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_reshaped))\n",
    "    elif mode == \"words\":\n",
    "        loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(tf.transpose(softmax_w),softmax_b,tf.reshape(tf.argmax( y_reshaped,axis = 1),shape=(y_reshaped.get_shape()[0],1)),tf.concat(lstm_output,axis=1),negative_sampled,len(vocab)))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Here we build the optimizer. Normal RNNs have have issues gradients exploding and disappearing. LSTMs fix the disappearance problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip,global_step):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        global_step: to control the total number of train steps\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars),global_step)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "\n",
    "Now we can put all the pieces together and build a class for the network. To actually run data through the LSTM cells, we will use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/dynamic_rnn). This function will pass the hidden and cell states across LSTM cells appropriately for us. It returns the outputs for each LSTM cell at each step for each sequence in the mini-batch. It also gives us the final LSTM state. We want to save this state as `final_state` so we can pass it to the first LSTM cell in the the next mini-batch run. For `tf.nn.dynamic_rnn`, we pass in the cell and initial state we get from `build_lstm`, as well as our input sequences. Also, we need to one-hot encode the inputs before going into the RNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False,device = \"/device:GPU:0\"):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        with tf.device(device):\n",
    "            self.global_step_tensor = tf.Variable(0,trainable=False,name = \"global_step\")\n",
    "            # Build the input placeholder tensors\n",
    "            self.inputs, self.targets, self.keep_prob = build_inputs(batch_size,num_steps)\n",
    "            # Build the LSTM cell\n",
    "            cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,self.keep_prob)\n",
    "            ### Run the data through the RNN layers\n",
    "            # First, one-hot encode the input tokens\n",
    "            x_one_hot = tf.one_hot(self.inputs,num_classes)\n",
    "\n",
    "            self.grad_clip  = grad_clip\n",
    "            # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "            outputs, state = tf.nn.dynamic_rnn(cell,x_one_hot,initial_state=self.initial_state)\n",
    "            self.final_state = state\n",
    "\n",
    "            # Get softmax predictions and logits\n",
    "            self.prediction, self.logits ,self.softmax_w,self.softmax_b,self.lstm_output_reshaped  = build_output(outputs,lstm_size,num_classes)\n",
    "\n",
    "            # Loss and optimizer (with gradient clipping)\n",
    "            self.loss =  build_loss(self.lstm_output_reshaped ,self.logits,self.targets,lstm_size,num_classes,self.softmax_w,self.softmax_b)\n",
    "            self.optimizer = build_optimizer(self.loss,learning_rate,grad_clip,self.global_step_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here are the hyperparameters for the network.\n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.\n",
    "* `lstm_size` - The number of units in the hidden layers.\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy on training the network:. \n",
    "\n",
    "> ## Tips and Tricks\n",
    "\n",
    ">### Monitoring Validation Loss vs. Training Loss\n",
    ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
    "\n",
    "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
    "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "> ### Approximate number of parameters\n",
    "\n",
    "> The two most important parameters that control the model are `lstm_size` and `num_layers`. I would advise that you always use `num_layers` of either 2/3. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    "\n",
    "> - The number of parameters in your model. This is printed when you start training.\n",
    "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
    "\n",
    ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
    "\n",
    "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `lstm_size` larger.\n",
    "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
    "\n",
    "> ### Best models strategy\n",
    "\n",
    ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_of_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        \n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters*=dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters+= variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for training\n",
    "\n",
    "This is typical training code, passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I save a checkpoint.\n",
    "\n",
    "Here I'm saving checkpoints with the format\n",
    "\n",
    "`i{iteration number}_l{# hidden layer units}.ckpt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = {\"train\":[],\"validation\":[]}\n",
    "x_steps = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(64, 50, 1024), dtype=float32, device=/device:GPU:0)\n",
      "Training starting at time: 2018-10-23 00:58:15\n",
      "Number of parameters: 235124159 Dataset size: 2277333\n",
      "Epoch: 1/25...  Training Step: 1...  Training loss: 10.6636...  Val loss: 10.6406...  3.1114 sec/batch\n",
      "Epoch: 1/25...  Training Step: 51...  Training loss: 4.8926...  Val loss: 4.5160...  1.0324 sec/batch\n",
      "Epoch: 1/25...  Training Step: 101...  Training loss: 4.4179...  Val loss: 4.0313...  1.0410 sec/batch\n",
      "Epoch: 1/25...  Training Step: 151...  Training loss: 4.3448...  Val loss: 3.9832...  1.0350 sec/batch\n",
      "Epoch: 1/25...  Training Step: 201...  Training loss: 4.2883...  Val loss: 3.8963...  1.0462 sec/batch\n",
      "Epoch: 1/25...  Training Step: 251...  Training loss: 3.8827...  Val loss: 3.5610...  1.0411 sec/batch\n",
      "Epoch: 1/25...  Training Step: 301...  Training loss: 3.9514...  Val loss: 3.4647...  1.0356 sec/batch\n",
      "Epoch: 1/25...  Training Step: 351...  Training loss: 3.8458...  Val loss: 3.3901...  1.0488 sec/batch\n",
      "Epoch: 1/25...  Training Step: 401...  Training loss: 3.7328...  Val loss: 3.3444...  1.0822 sec/batch\n",
      "Epoch: 1/25...  Training Step: 451...  Training loss: 3.7181...  Val loss: 3.3022...  1.0356 sec/batch\n",
      "Epoch: 1/25...  Training Step: 501...  Training loss: 3.7267...  Val loss: 3.3054...  1.0310 sec/batch\n",
      "Epoch: 1/25...  Training Step: 551...  Training loss: 3.7375...  Val loss: 3.2947...  1.0537 sec/batch\n",
      "Epoch: 1/25...  Training Step: 601...  Training loss: 3.7231...  Val loss: 3.2664...  1.0447 sec/batch\n",
      "Epoch: 1/25...  Training Step: 651...  Training loss: 3.6841...  Val loss: 3.2574...  1.0618 sec/batch\n",
      "Epoch: 1/25...  Training Step: 701...  Training loss: 3.5672...  Val loss: 3.2380...  1.0505 sec/batch\n",
      "Epoch: 2/25...  Training Step: 751...  Training loss: 3.6627...  Val loss: 3.2036...  1.0955 sec/batch\n",
      "Epoch: 2/25...  Training Step: 801...  Training loss: 3.6384...  Val loss: 3.1971...  1.0425 sec/batch\n",
      "Epoch: 2/25...  Training Step: 851...  Training loss: 3.5971...  Val loss: 3.1938...  1.0471 sec/batch\n",
      "Epoch: 2/25...  Training Step: 901...  Training loss: 3.5465...  Val loss: 3.1879...  1.0379 sec/batch\n",
      "Epoch: 2/25...  Training Step: 951...  Training loss: 3.5658...  Val loss: 3.1839...  1.0664 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1001...  Training loss: 3.6545...  Val loss: 3.1709...  1.0609 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1051...  Training loss: 3.6353...  Val loss: 3.1711...  1.0407 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1101...  Training loss: 3.6095...  Val loss: 3.1575...  1.0532 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1151...  Training loss: 3.5397...  Val loss: 3.1636...  1.0426 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1201...  Training loss: 3.5674...  Val loss: 3.1627...  1.0453 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1251...  Training loss: 3.6199...  Val loss: 3.1214...  1.0372 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1301...  Training loss: 3.5781...  Val loss: 3.1322...  1.0413 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1351...  Training loss: 3.6177...  Val loss: 3.1102...  1.0627 sec/batch\n",
      "Epoch: 2/25...  Training Step: 1401...  Training loss: 3.5833...  Val loss: 3.0559...  1.0351 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1451...  Training loss: 3.5036...  Val loss: 3.1005...  1.0298 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1501...  Training loss: 3.5056...  Val loss: 3.0701...  1.0429 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1551...  Training loss: 3.4461...  Val loss: 3.0851...  1.0982 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1601...  Training loss: 3.5092...  Val loss: 3.0579...  1.0431 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1651...  Training loss: 3.5002...  Val loss: 3.0302...  1.0382 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1701...  Training loss: 3.4439...  Val loss: 3.0530...  1.0583 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1751...  Training loss: 3.5253...  Val loss: 3.0138...  1.0504 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1801...  Training loss: 3.4589...  Val loss: 3.0533...  1.0409 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1851...  Training loss: 3.4146...  Val loss: 3.0139...  1.1568 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1901...  Training loss: 3.3926...  Val loss: 2.9868...  1.1242 sec/batch\n",
      "Epoch: 3/25...  Training Step: 1951...  Training loss: 3.4655...  Val loss: 3.0072...  1.0376 sec/batch\n",
      "Epoch: 3/25...  Training Step: 2001...  Training loss: 3.4110...  Val loss: 2.9832...  1.0372 sec/batch\n",
      "Epoch: 3/25...  Training Step: 2051...  Training loss: 3.3299...  Val loss: 2.9746...  1.0379 sec/batch\n",
      "Epoch: 3/25...  Training Step: 2101...  Training loss: 3.3139...  Val loss: 2.9487...  1.0510 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2151...  Training loss: 3.3294...  Val loss: 2.9335...  1.0382 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2201...  Training loss: 3.4306...  Val loss: 2.9349...  1.0455 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2251...  Training loss: 3.3508...  Val loss: 2.9654...  1.1957 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2301...  Training loss: 3.2535...  Val loss: 2.8687...  1.0579 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2351...  Training loss: 3.2767...  Val loss: 2.8372...  1.0329 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2401...  Training loss: 3.3435...  Val loss: 2.9062...  1.0375 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2451...  Training loss: 3.4019...  Val loss: 2.8788...  1.0831 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2501...  Training loss: 3.3187...  Val loss: 2.8466...  1.0500 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2551...  Training loss: 3.2468...  Val loss: 2.8799...  1.0356 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2601...  Training loss: 3.2853...  Val loss: 2.8890...  1.0816 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2651...  Training loss: 3.3156...  Val loss: 2.8561...  1.0554 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2701...  Training loss: 3.2751...  Val loss: 2.8655...  1.0565 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2751...  Training loss: 3.1954...  Val loss: 2.8711...  1.0445 sec/batch\n",
      "Epoch: 4/25...  Training Step: 2801...  Training loss: 3.2822...  Val loss: 2.8739...  1.0412 sec/batch\n",
      "Epoch: 5/25...  Training Step: 2851...  Training loss: 3.2616...  Val loss: 2.8642...  1.0599 sec/batch\n",
      "Epoch: 5/25...  Training Step: 2901...  Training loss: 3.2252...  Val loss: 2.8224...  1.0395 sec/batch\n",
      "Epoch: 5/25...  Training Step: 2951...  Training loss: 3.2247...  Val loss: 2.7876...  1.0406 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3001...  Training loss: 3.2114...  Val loss: 2.7866...  1.0444 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3051...  Training loss: 3.1701...  Val loss: 2.8598...  1.0593 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3101...  Training loss: 3.1511...  Val loss: 2.8321...  1.0366 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3151...  Training loss: 3.1767...  Val loss: 2.7512...  1.0391 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3201...  Training loss: 3.2144...  Val loss: 2.8128...  1.1342 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3251...  Training loss: 3.0132...  Val loss: 2.8113...  1.0913 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3301...  Training loss: 3.1264...  Val loss: 2.8175...  1.0560 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3351...  Training loss: 3.1201...  Val loss: 2.8606...  1.0409 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3401...  Training loss: 3.1640...  Val loss: 2.8128...  1.0511 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3451...  Training loss: 3.0674...  Val loss: 2.8260...  1.1216 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3501...  Training loss: 3.1540...  Val loss: 2.8554...  1.0355 sec/batch\n",
      "Epoch: 5/25...  Training Step: 3551...  Training loss: 3.0135...  Val loss: 2.7815...  1.0344 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3601...  Training loss: 3.2146...  Val loss: 2.8164...  1.0597 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3651...  Training loss: 3.1808...  Val loss: 2.7419...  1.1522 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3701...  Training loss: 3.1022...  Val loss: 2.7285...  1.0446 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3751...  Training loss: 3.0831...  Val loss: 2.7988...  1.0592 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3801...  Training loss: 3.0873...  Val loss: 2.7708...  1.1004 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3851...  Training loss: 3.0725...  Val loss: 2.7010...  1.0440 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/25...  Training Step: 3901...  Training loss: 3.1063...  Val loss: 2.7541...  1.1246 sec/batch\n",
      "Epoch: 6/25...  Training Step: 3951...  Training loss: 3.0582...  Val loss: 2.7517...  1.0458 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4001...  Training loss: 3.0989...  Val loss: 2.7680...  1.0347 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4051...  Training loss: 3.0456...  Val loss: 2.8398...  1.0361 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4101...  Training loss: 3.0727...  Val loss: 2.8061...  1.0366 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4151...  Training loss: 2.9733...  Val loss: 2.7802...  1.0382 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4201...  Training loss: 3.1049...  Val loss: 2.7538...  1.0300 sec/batch\n",
      "Epoch: 6/25...  Training Step: 4251...  Training loss: 3.0736...  Val loss: 2.7643...  1.0987 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4301...  Training loss: 3.0479...  Val loss: 2.7495...  1.0851 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4351...  Training loss: 3.0882...  Val loss: 2.7748...  1.1207 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4401...  Training loss: 3.0460...  Val loss: 2.7307...  1.0359 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4451...  Training loss: 3.1048...  Val loss: 2.7679...  1.0298 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4501...  Training loss: 3.0635...  Val loss: 2.7368...  1.0892 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4551...  Training loss: 2.9505...  Val loss: 2.7867...  1.0841 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4601...  Training loss: 3.1028...  Val loss: 2.7855...  1.0461 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4651...  Training loss: 2.9518...  Val loss: 2.7624...  1.1587 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4701...  Training loss: 2.9901...  Val loss: 2.7573...  1.0498 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4751...  Training loss: 2.9245...  Val loss: 2.7964...  1.0333 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4801...  Training loss: 3.0090...  Val loss: 2.7652...  1.1038 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4851...  Training loss: 2.9207...  Val loss: 2.8029...  1.0349 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4901...  Training loss: 2.9933...  Val loss: 2.8230...  1.0236 sec/batch\n",
      "Epoch: 7/25...  Training Step: 4951...  Training loss: 3.0206...  Val loss: 2.7643...  1.0364 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5001...  Training loss: 2.9338...  Val loss: 2.8356...  1.1764 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5051...  Training loss: 2.9684...  Val loss: 2.7303...  1.0362 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5101...  Training loss: 2.9084...  Val loss: 2.7675...  1.0369 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5151...  Training loss: 2.9848...  Val loss: 2.7365...  1.0587 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5201...  Training loss: 2.8680...  Val loss: 2.7506...  1.0355 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5251...  Training loss: 2.8955...  Val loss: 2.7547...  1.0947 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5301...  Training loss: 2.9922...  Val loss: 2.7621...  1.1571 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5351...  Training loss: 2.8818...  Val loss: 2.7362...  1.0320 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5401...  Training loss: 2.9247...  Val loss: 2.7728...  1.0870 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5451...  Training loss: 2.8925...  Val loss: 2.7252...  1.0362 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5501...  Training loss: 2.9834...  Val loss: 2.7751...  1.0339 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5551...  Training loss: 2.9020...  Val loss: 2.7834...  1.0358 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5601...  Training loss: 2.8999...  Val loss: 2.7945...  1.0310 sec/batch\n",
      "Epoch: 8/25...  Training Step: 5651...  Training loss: 2.8436...  Val loss: 2.7881...  1.0514 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5701...  Training loss: 2.8502...  Val loss: 2.7153...  1.1257 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5751...  Training loss: 2.9373...  Val loss: 2.6838...  1.0328 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5801...  Training loss: 2.9193...  Val loss: 2.7533...  1.0563 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5851...  Training loss: 2.8901...  Val loss: 2.7309...  1.1374 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5901...  Training loss: 2.8429...  Val loss: 2.7613...  1.0318 sec/batch\n",
      "Epoch: 9/25...  Training Step: 5951...  Training loss: 2.8847...  Val loss: 2.7321...  1.0345 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6001...  Training loss: 2.8727...  Val loss: 2.7537...  1.0380 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6051...  Training loss: 2.7685...  Val loss: 2.7264...  1.0342 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6101...  Training loss: 2.8954...  Val loss: 2.7696...  1.0446 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6151...  Training loss: 2.8756...  Val loss: 2.8074...  1.0472 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6201...  Training loss: 2.8477...  Val loss: 2.7354...  1.0449 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6251...  Training loss: 2.8475...  Val loss: 2.8126...  1.0416 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6301...  Training loss: 2.8466...  Val loss: 2.7965...  1.0375 sec/batch\n",
      "Epoch: 9/25...  Training Step: 6351...  Training loss: 2.8279...  Val loss: 2.7464...  1.0401 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6401...  Training loss: 2.8536...  Val loss: 2.7877...  1.0311 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6451...  Training loss: 2.8228...  Val loss: 2.7863...  1.0530 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6501...  Training loss: 2.8312...  Val loss: 2.7133...  1.0397 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6551...  Training loss: 2.7499...  Val loss: 2.6980...  1.0430 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6601...  Training loss: 2.7482...  Val loss: 2.7779...  1.0443 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6651...  Training loss: 2.7518...  Val loss: 2.8036...  1.0370 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6701...  Training loss: 2.8868...  Val loss: 2.7432...  1.0742 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6751...  Training loss: 2.7739...  Val loss: 2.7742...  1.0439 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6801...  Training loss: 2.8441...  Val loss: 2.8108...  1.0315 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6851...  Training loss: 2.7251...  Val loss: 2.7724...  1.0369 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6901...  Training loss: 2.6925...  Val loss: 2.7330...  1.0332 sec/batch\n",
      "Epoch: 10/25...  Training Step: 6951...  Training loss: 2.8040...  Val loss: 2.7675...  1.0375 sec/batch\n",
      "Epoch: 10/25...  Training Step: 7001...  Training loss: 2.7500...  Val loss: 2.7132...  1.1239 sec/batch\n",
      "Epoch: 10/25...  Training Step: 7051...  Training loss: 2.7944...  Val loss: 2.7374...  1.0368 sec/batch\n",
      "Epoch: 10/25...  Training Step: 7101...  Training loss: 2.8015...  Val loss: 2.7253...  1.0383 sec/batch\n",
      "Epoch 10/25 time:787.8866386413574...  finished at 2018-10-23 03:07:58\n",
      "Epoch: 11/25...  Training Step: 7151...  Training loss: 2.7404...  Val loss: 2.7603...  1.0404 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7201...  Training loss: 2.8155...  Val loss: 2.7498...  1.0362 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7251...  Training loss: 2.7803...  Val loss: 2.7826...  1.1396 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7301...  Training loss: 2.7286...  Val loss: 2.7311...  1.0306 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7351...  Training loss: 2.6801...  Val loss: 2.7604...  1.0377 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7401...  Training loss: 2.7994...  Val loss: 2.7469...  1.0636 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7451...  Training loss: 2.7380...  Val loss: 2.7844...  1.0409 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7501...  Training loss: 2.7555...  Val loss: 2.7726...  1.0806 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7551...  Training loss: 2.7166...  Val loss: 2.7576...  1.0420 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7601...  Training loss: 2.7617...  Val loss: 2.7877...  1.1366 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7651...  Training loss: 2.7245...  Val loss: 2.7421...  1.0464 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7701...  Training loss: 2.6750...  Val loss: 2.7897...  1.0598 sec/batch\n",
      "Epoch: 11/25...  Training Step: 7751...  Training loss: 2.6676...  Val loss: 2.7760...  1.0381 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/25...  Training Step: 7801...  Training loss: 2.7343...  Val loss: 2.8041...  1.0544 sec/batch\n",
      "Epoch: 12/25...  Training Step: 7851...  Training loss: 2.7292...  Val loss: 2.7330...  1.0357 sec/batch\n",
      "Epoch: 12/25...  Training Step: 7901...  Training loss: 2.7038...  Val loss: 2.7480...  1.0366 sec/batch\n",
      "Epoch: 12/25...  Training Step: 7951...  Training loss: 2.6646...  Val loss: 2.6767...  1.0353 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8001...  Training loss: 2.6703...  Val loss: 2.8070...  1.0543 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8051...  Training loss: 2.6467...  Val loss: 2.6775...  1.0380 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8101...  Training loss: 2.7137...  Val loss: 2.7553...  1.0734 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8151...  Training loss: 2.7432...  Val loss: 2.7660...  1.1583 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8201...  Training loss: 2.7399...  Val loss: 2.8070...  1.0378 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8251...  Training loss: 2.6677...  Val loss: 2.8580...  1.0485 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8301...  Training loss: 2.6248...  Val loss: 2.7817...  1.0901 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8351...  Training loss: 2.7472...  Val loss: 2.7608...  1.0548 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8401...  Training loss: 2.6282...  Val loss: 2.7173...  1.0435 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8451...  Training loss: 2.6068...  Val loss: 2.7341...  1.0405 sec/batch\n",
      "Epoch: 12/25...  Training Step: 8501...  Training loss: 2.6501...  Val loss: 2.7163...  1.0380 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8551...  Training loss: 2.6136...  Val loss: 2.6940...  1.0364 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8601...  Training loss: 2.6712...  Val loss: 2.7709...  1.0319 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8651...  Training loss: 2.6450...  Val loss: 2.7565...  1.1615 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8701...  Training loss: 2.5454...  Val loss: 2.7504...  1.0329 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8751...  Training loss: 2.6346...  Val loss: 2.7657...  1.1722 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8801...  Training loss: 2.6396...  Val loss: 2.8458...  1.0368 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8851...  Training loss: 2.6442...  Val loss: 2.7378...  1.1549 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8901...  Training loss: 2.6297...  Val loss: 2.7640...  1.0362 sec/batch\n",
      "Epoch: 13/25...  Training Step: 8951...  Training loss: 2.6591...  Val loss: 2.7895...  1.1156 sec/batch\n",
      "Epoch: 13/25...  Training Step: 9001...  Training loss: 2.5476...  Val loss: 2.7383...  1.0930 sec/batch\n",
      "Epoch: 13/25...  Training Step: 9051...  Training loss: 2.6036...  Val loss: 2.8244...  1.0369 sec/batch\n",
      "Epoch: 13/25...  Training Step: 9101...  Training loss: 2.5991...  Val loss: 2.6994...  1.0403 sec/batch\n",
      "Epoch: 13/25...  Training Step: 9151...  Training loss: 2.6284...  Val loss: 2.6763...  1.0535 sec/batch\n",
      "Epoch: 13/25...  Training Step: 9201...  Training loss: 2.5550...  Val loss: 2.7541...  1.0468 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9251...  Training loss: 2.5820...  Val loss: 2.7767...  1.0556 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9301...  Training loss: 2.6106...  Val loss: 2.8022...  1.0347 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9351...  Training loss: 2.5302...  Val loss: 2.8246...  1.0428 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9401...  Training loss: 2.5985...  Val loss: 2.7613...  1.0361 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9451...  Training loss: 2.5516...  Val loss: 2.7616...  1.1535 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9501...  Training loss: 2.5576...  Val loss: 2.8107...  1.0387 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9551...  Training loss: 2.5671...  Val loss: 2.7418...  1.0431 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9601...  Training loss: 2.6224...  Val loss: 2.7810...  1.0339 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9651...  Training loss: 2.5742...  Val loss: 2.7203...  1.0379 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9701...  Training loss: 2.5625...  Val loss: 2.7671...  1.0456 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9751...  Training loss: 2.5998...  Val loss: 2.7795...  1.0330 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9801...  Training loss: 2.5671...  Val loss: 2.7868...  1.1241 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9851...  Training loss: 2.5374...  Val loss: 2.7903...  1.0317 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9901...  Training loss: 2.5826...  Val loss: 2.8407...  1.0551 sec/batch\n",
      "Epoch: 14/25...  Training Step: 9951...  Training loss: 2.4634...  Val loss: 2.7472...  1.0720 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10001...  Training loss: 2.5472...  Val loss: 2.7440...  1.0893 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10051...  Training loss: 2.5873...  Val loss: 2.7256...  1.0519 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10101...  Training loss: 2.5133...  Val loss: 2.8278...  1.1231 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10151...  Training loss: 2.5980...  Val loss: 2.8107...  1.0358 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10201...  Training loss: 2.5436...  Val loss: 2.7778...  1.0605 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10251...  Training loss: 2.4677...  Val loss: 2.7286...  1.0485 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10301...  Training loss: 2.5293...  Val loss: 2.7051...  1.1232 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10351...  Training loss: 2.5183...  Val loss: 2.8361...  1.0346 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10401...  Training loss: 2.5009...  Val loss: 2.7821...  1.0402 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10451...  Training loss: 2.4509...  Val loss: 2.8191...  1.0514 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10501...  Training loss: 2.4825...  Val loss: 2.8019...  1.1259 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10551...  Training loss: 2.4814...  Val loss: 2.7908...  1.0415 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10601...  Training loss: 2.4598...  Val loss: 2.7747...  1.0423 sec/batch\n",
      "Epoch: 15/25...  Training Step: 10651...  Training loss: 2.4480...  Val loss: 2.7688...  1.0992 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10701...  Training loss: 2.5024...  Val loss: 2.7352...  1.0439 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10751...  Training loss: 2.5747...  Val loss: 2.7861...  1.0463 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10801...  Training loss: 2.4514...  Val loss: 2.8239...  1.0460 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10851...  Training loss: 2.5115...  Val loss: 2.7508...  1.1258 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10901...  Training loss: 2.5091...  Val loss: 2.7244...  1.0297 sec/batch\n",
      "Epoch: 16/25...  Training Step: 10951...  Training loss: 2.4616...  Val loss: 2.8344...  1.0152 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11001...  Training loss: 2.5263...  Val loss: 2.9174...  1.1536 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11051...  Training loss: 2.5008...  Val loss: 2.8077...  1.0336 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11101...  Training loss: 2.5052...  Val loss: 2.8736...  1.1381 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11151...  Training loss: 2.3954...  Val loss: 2.8747...  1.0327 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11201...  Training loss: 2.5038...  Val loss: 2.7574...  1.0614 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11251...  Training loss: 2.4142...  Val loss: 2.7934...  1.0502 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11301...  Training loss: 2.4402...  Val loss: 2.7358...  1.1141 sec/batch\n",
      "Epoch: 16/25...  Training Step: 11351...  Training loss: 2.4383...  Val loss: 2.8390...  1.1377 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11401...  Training loss: 2.5259...  Val loss: 2.9025...  1.0342 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11451...  Training loss: 2.4403...  Val loss: 2.9369...  1.0446 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11501...  Training loss: 2.3894...  Val loss: 2.8618...  1.0506 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11551...  Training loss: 2.4206...  Val loss: 2.8243...  1.1537 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11601...  Training loss: 2.4012...  Val loss: 2.8282...  1.0415 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11651...  Training loss: 2.4839...  Val loss: 2.9507...  1.0423 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/25...  Training Step: 11701...  Training loss: 2.4554...  Val loss: 2.9506...  1.0501 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11751...  Training loss: 2.4422...  Val loss: 2.7818...  1.0656 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11801...  Training loss: 2.4083...  Val loss: 2.7279...  1.0378 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11851...  Training loss: 2.4528...  Val loss: 2.8598...  1.0453 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11901...  Training loss: 2.3867...  Val loss: 2.9408...  1.0536 sec/batch\n",
      "Epoch: 17/25...  Training Step: 11951...  Training loss: 2.4197...  Val loss: 2.8358...  1.0377 sec/batch\n",
      "Epoch: 17/25...  Training Step: 12001...  Training loss: 2.4306...  Val loss: 2.7830...  1.1930 sec/batch\n",
      "Epoch: 17/25...  Training Step: 12051...  Training loss: 2.4514...  Val loss: 2.7687...  1.0402 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12101...  Training loss: 2.3899...  Val loss: 2.9141...  1.1362 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12151...  Training loss: 2.3680...  Val loss: 2.8080...  1.0329 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12201...  Training loss: 2.3356...  Val loss: 2.7919...  1.1025 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12251...  Training loss: 2.3655...  Val loss: 2.8281...  1.1364 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12301...  Training loss: 2.3179...  Val loss: 2.7885...  1.0351 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12351...  Training loss: 2.4076...  Val loss: 2.7790...  1.0408 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12401...  Training loss: 2.4104...  Val loss: 2.8446...  1.0468 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12451...  Training loss: 2.3577...  Val loss: 2.7876...  1.1950 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12501...  Training loss: 2.3186...  Val loss: 2.8116...  1.0348 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12551...  Training loss: 2.3754...  Val loss: 2.8265...  1.0592 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12601...  Training loss: 2.4117...  Val loss: 2.9466...  1.0310 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12651...  Training loss: 2.3585...  Val loss: 2.8483...  1.0438 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12701...  Training loss: 2.3913...  Val loss: 2.8533...  1.0520 sec/batch\n",
      "Epoch: 18/25...  Training Step: 12751...  Training loss: 2.4111...  Val loss: 2.9106...  1.0512 sec/batch\n",
      "Epoch: 19/25...  Training Step: 12801...  Training loss: 2.3536...  Val loss: 2.7194...  1.0387 sec/batch\n",
      "Epoch: 19/25...  Training Step: 12851...  Training loss: 2.2717...  Val loss: 2.8116...  1.0800 sec/batch\n",
      "Epoch: 19/25...  Training Step: 12901...  Training loss: 2.3520...  Val loss: 2.7791...  1.0741 sec/batch\n",
      "Epoch: 19/25...  Training Step: 12951...  Training loss: 2.3681...  Val loss: 2.7974...  1.0451 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13001...  Training loss: 2.2709...  Val loss: 2.7952...  1.0594 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13051...  Training loss: 2.3069...  Val loss: 2.9557...  1.0396 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13101...  Training loss: 2.3345...  Val loss: 2.9443...  1.0312 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13151...  Training loss: 2.3528...  Val loss: 3.0127...  1.1532 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13201...  Training loss: 2.2949...  Val loss: 2.8749...  1.0380 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13251...  Training loss: 2.3397...  Val loss: 2.9583...  1.1226 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13301...  Training loss: 2.3077...  Val loss: 2.9183...  1.0500 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13351...  Training loss: 2.3874...  Val loss: 2.9652...  1.0573 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13401...  Training loss: 2.3057...  Val loss: 2.8169...  1.0312 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13451...  Training loss: 2.3203...  Val loss: 2.8584...  1.0795 sec/batch\n",
      "Epoch: 19/25...  Training Step: 13501...  Training loss: 2.2925...  Val loss: 2.8538...  1.0285 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13551...  Training loss: 2.3666...  Val loss: 2.9467...  1.0381 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13601...  Training loss: 2.3134...  Val loss: 2.8677...  1.0935 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13651...  Training loss: 2.2536...  Val loss: 2.8747...  1.0686 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13701...  Training loss: 2.3179...  Val loss: 2.7643...  1.0366 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13751...  Training loss: 2.2406...  Val loss: 2.8212...  1.1574 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13801...  Training loss: 2.2512...  Val loss: 2.7731...  1.0274 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13851...  Training loss: 2.2376...  Val loss: 2.7971...  1.0833 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13901...  Training loss: 2.2911...  Val loss: 2.9145...  1.0778 sec/batch\n",
      "Epoch: 20/25...  Training Step: 13951...  Training loss: 2.2806...  Val loss: 2.8554...  1.0379 sec/batch\n",
      "Epoch: 20/25...  Training Step: 14001...  Training loss: 2.3018...  Val loss: 2.8962...  1.0398 sec/batch\n",
      "Epoch: 20/25...  Training Step: 14051...  Training loss: 2.2216...  Val loss: 2.9648...  1.0705 sec/batch\n",
      "Epoch: 20/25...  Training Step: 14101...  Training loss: 2.3396...  Val loss: 2.9025...  1.0579 sec/batch\n",
      "Epoch: 20/25...  Training Step: 14151...  Training loss: 2.3446...  Val loss: 2.7758...  1.0398 sec/batch\n",
      "Epoch: 20/25...  Training Step: 14201...  Training loss: 2.3214...  Val loss: 2.9136...  1.1247 sec/batch\n",
      "Epoch 20/25 time:772.0687875747681...  finished at 2018-10-23 05:18:04\n",
      "Epoch: 21/25...  Training Step: 14251...  Training loss: 2.2657...  Val loss: 2.8816...  1.0325 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14301...  Training loss: 2.2599...  Val loss: 2.8836...  1.0382 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14351...  Training loss: 2.3512...  Val loss: 2.8111...  1.1596 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14401...  Training loss: 2.2545...  Val loss: 2.8522...  1.0319 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14451...  Training loss: 2.3160...  Val loss: 2.7551...  1.0455 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14501...  Training loss: 2.3022...  Val loss: 2.8175...  1.0375 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14551...  Training loss: 2.2358...  Val loss: 2.8735...  1.0308 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14601...  Training loss: 2.2472...  Val loss: 2.8911...  1.0577 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14651...  Training loss: 2.2274...  Val loss: 2.8882...  1.0424 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14701...  Training loss: 2.2689...  Val loss: 2.8358...  1.0301 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14751...  Training loss: 2.2178...  Val loss: 2.8846...  1.0754 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14801...  Training loss: 2.2797...  Val loss: 2.8909...  1.1212 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14851...  Training loss: 2.1694...  Val loss: 2.8032...  1.0323 sec/batch\n",
      "Epoch: 21/25...  Training Step: 14901...  Training loss: 2.2380...  Val loss: 2.9099...  1.0431 sec/batch\n",
      "Epoch: 22/25...  Training Step: 14951...  Training loss: 2.1854...  Val loss: 2.8428...  1.0391 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15001...  Training loss: 2.2704...  Val loss: 2.8253...  1.0417 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15051...  Training loss: 2.1887...  Val loss: 2.8719...  1.0449 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15101...  Training loss: 2.1828...  Val loss: 2.7605...  1.1571 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15151...  Training loss: 2.1624...  Val loss: 2.8661...  1.0436 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15201...  Training loss: 2.2209...  Val loss: 2.7741...  1.0456 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15251...  Training loss: 2.2546...  Val loss: 2.8136...  1.0460 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15301...  Training loss: 2.2545...  Val loss: 2.8715...  1.0402 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15351...  Training loss: 2.2392...  Val loss: 2.8682...  1.0369 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15401...  Training loss: 2.2195...  Val loss: 2.9136...  1.0391 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15451...  Training loss: 2.2258...  Val loss: 2.8416...  1.0395 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15501...  Training loss: 2.1331...  Val loss: 2.8840...  1.0441 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/25...  Training Step: 15551...  Training loss: 2.2039...  Val loss: 2.8576...  1.0352 sec/batch\n",
      "Epoch: 22/25...  Training Step: 15601...  Training loss: 2.1942...  Val loss: 2.8492...  1.0421 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15651...  Training loss: 2.2673...  Val loss: 2.8183...  1.0360 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15701...  Training loss: 2.1526...  Val loss: 3.0333...  1.0330 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15751...  Training loss: 2.0895...  Val loss: 2.8994...  1.0429 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15801...  Training loss: 2.1298...  Val loss: 2.9273...  1.1043 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15851...  Training loss: 2.1316...  Val loss: 2.8964...  1.0399 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15901...  Training loss: 2.1159...  Val loss: 2.9004...  0.9904 sec/batch\n",
      "Epoch: 23/25...  Training Step: 15951...  Training loss: 2.1011...  Val loss: 2.8631...  1.0540 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16001...  Training loss: 2.0956...  Val loss: 2.8907...  1.0319 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16051...  Training loss: 2.1118...  Val loss: 2.9276...  1.0362 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16101...  Training loss: 2.1027...  Val loss: 2.9327...  1.1383 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16151...  Training loss: 2.1525...  Val loss: 2.9103...  1.0245 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16201...  Training loss: 2.1070...  Val loss: 2.9247...  1.0410 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16251...  Training loss: 2.1911...  Val loss: 2.9977...  1.0427 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16301...  Training loss: 2.1456...  Val loss: 2.9147...  1.0665 sec/batch\n",
      "Epoch: 23/25...  Training Step: 16351...  Training loss: 2.1490...  Val loss: 2.8797...  1.0333 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16401...  Training loss: 2.1254...  Val loss: 2.9063...  1.0532 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16451...  Training loss: 2.1481...  Val loss: 2.7751...  1.0418 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16501...  Training loss: 2.1408...  Val loss: 3.0086...  1.0965 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16551...  Training loss: 2.1454...  Val loss: 2.9059...  1.1386 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16601...  Training loss: 2.1430...  Val loss: 2.7970...  1.0329 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16651...  Training loss: 2.1113...  Val loss: 3.0066...  1.0436 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16701...  Training loss: 2.0915...  Val loss: 3.0052...  1.0555 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16751...  Training loss: 2.1129...  Val loss: 2.9249...  1.1598 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16801...  Training loss: 2.1236...  Val loss: 2.9862...  1.0378 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16851...  Training loss: 2.0895...  Val loss: 3.0258...  1.0373 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16901...  Training loss: 2.1475...  Val loss: 2.9019...  1.0920 sec/batch\n",
      "Epoch: 24/25...  Training Step: 16951...  Training loss: 2.0781...  Val loss: 2.9716...  1.0442 sec/batch\n",
      "Epoch: 24/25...  Training Step: 17001...  Training loss: 2.1127...  Val loss: 2.9767...  1.0396 sec/batch\n",
      "Epoch: 24/25...  Training Step: 17051...  Training loss: 2.1766...  Val loss: 2.9663...  1.0966 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17101...  Training loss: 1.9923...  Val loss: 2.8905...  1.0375 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17151...  Training loss: 2.1332...  Val loss: 3.0156...  1.0315 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17201...  Training loss: 2.1131...  Val loss: 2.9422...  1.0445 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17251...  Training loss: 2.0401...  Val loss: 2.9886...  1.0473 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17301...  Training loss: 2.0890...  Val loss: 2.9774...  1.0234 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17351...  Training loss: 2.1367...  Val loss: 3.0733...  1.0372 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17401...  Training loss: 2.0999...  Val loss: 2.9472...  1.0808 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17451...  Training loss: 2.2353...  Val loss: 3.1052...  1.0337 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17501...  Training loss: 2.0575...  Val loss: 2.9602...  1.0399 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17551...  Training loss: 2.0702...  Val loss: 3.0195...  1.0395 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17601...  Training loss: 2.0342...  Val loss: 2.9490...  1.0322 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17651...  Training loss: 2.0124...  Val loss: 2.9065...  1.0372 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17701...  Training loss: 2.0327...  Val loss: 3.0330...  1.0559 sec/batch\n",
      "Epoch: 25/25...  Training Step: 17751...  Training loss: 2.0751...  Val loss: 2.9732...  1.0407 sec/batch\n",
      "Training ending at time: 2018-10-23 06:23:13\n",
      "Trainint total time: 19497.81935620308\n"
     ]
    }
   ],
   "source": [
    "#epochs = 1\n",
    "# Save every N iterations\n",
    "save_every_n = 500\n",
    "print_loss_every_n = 50\n",
    "sample_every = 500\n",
    "print_epoch_time_every = 10\n",
    "\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate,device=\"/device:GPU:0\")\n",
    "    #print(\"after model\")\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "print(\"Training starting at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "train_start_time = time.time()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True,allow_soft_placement= True)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Number of parameters:\",get_number_of_parameters(),\"Dataset size:\",len(encoded))\n",
    "    #print(\"after initializer\")\n",
    "    if resume_from_checkpoint:\n",
    "        latest_checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "\n",
    "\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                        model.targets: y,\n",
    "                        model.keep_prob: keep_prob,\n",
    "                        model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                     model.final_state, \n",
    "                                                     model.optimizer], \n",
    "                                                     feed_dict=feed)\n",
    "\n",
    "\n",
    "            end = time.time()\n",
    "            if counter%print_loss_every_n == 0:\n",
    "                val_batches = get_batches(encoded_val,int(len(encoded_val)/num_steps),num_steps)\n",
    "                x_val,y_val = next(val_batches)\n",
    "\n",
    "                val_dict = {model.inputs: x_val,\n",
    "                                model.targets: y_val,\n",
    "                                model.keep_prob: 1,\n",
    "                                model.initial_state: new_state}\n",
    "\n",
    "                val_loss,prediction = sess.run([model.loss,model.prediction],feed_dict=val_dict)\n",
    "\n",
    "                losses[\"train\"].append(batch_loss)\n",
    "                losses[\"validation\"].append(val_loss)\n",
    "\n",
    "\n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                x_steps.append(global_step)\n",
    "\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                          'Training Step: {}... '.format(global_step),\n",
    "                          'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                          'Val loss: {:.4f}... '.format(val_loss),\n",
    "                          '{:.4f} sec/batch'.format((end-start)))\n",
    "\n",
    "            if (counter % save_every_n == 0):\n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "\n",
    "            counter += 1\n",
    "                #learning_rate*=0.75\n",
    "                #model.optimizer = build_optimizer(model.loss,learning_rate,model.grad_clip,model.global_step_tensor)\n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "\n",
    "        if ((e+1) % print_epoch_time_every== 0):\n",
    "            print('Epoch {}/{} time:{}...'.format(e+1,epochs,epoch_end-epoch_start),\n",
    "                     \" finished at\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "\n",
    "\n",
    "    global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "    saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "\n",
    "print(\"Training ending at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "print(\"Trainint total time:\",time.time()-train_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAH0CAYAAACaWFNdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvKo/dQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5277a31320>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 370
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_steps,losses[\"train\"],label=\"Train loss\")\n",
    "plt.plot(x_steps,losses[\"validation\"],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved checkpoints\n",
    "\n",
    "Read up on saving and loading checkpoints here: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints = tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling final trained model\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \",mode=\"characters\"):\n",
    "    print(mode)\n",
    "    samples = tokenize_text(prime,mode)\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True,allow_soft_placement= True)) as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in tokenize_text(prime,mode):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples).replace(\"new_line_token\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/mwords_i17775_l1024.ckpt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new text from \"base\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "\n",
    "\n",
    "samples = list()\n",
    "for text in text_to_try:\n",
    "    #print(\"------------------------\",text)\n",
    "    samples.append( sample(checkpoint, 500, lstm_size, len(vocab), prime=text,mode=mode))\n",
    "    #print(samp)\n",
    "    #print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ In the first place\n",
      "In the first place the whole world of life was now and known to have been made by a man in a very very little way.\n",
      "\n",
      "And then that I saw that the city of the trees was not the more.\n",
      "\n",
      "``I was not in my mind, when it came to me that I had not come out. Yet was a great sense of my friend. It was as a moment that I had ever seen that I was not able to go away. In that moment the noise had been a place where I could not see the old woman in his library, and then I had no reason.\n",
      "\n",
      "``You must have been a very old man! I was glad to go on the night of the dead window.\n",
      "\n",
      "``It was very old woman's voice, and told him the more inspiration of the city of his own wife. He found his wife in the dark library of his face and the voice of his head as a half of a sound as before it had been in his car. He was gone to a man's voice for a voice which was a terrible man; but he was known by his fame in a very sort of black voice. The voice seemed to be the woman as a man of the family and made it to be more than a moment. But this, however, that he had come to me that \n",
      "------------------------\n",
      "------------------------ the night before\n",
      "the night before the first time the whole, was now and saw that was not a terrible sense of horror as I could. And I saw my eyes and ceased, and I knew that the sound of which was now and then in my own room; but I was glad that I could not know it. There would be something like to the house, and I could not help me to the other way at that moment.\n",
      "\n",
      "Then I saw that I was the  ; and the sound of my heart had been a faint, and weak sound of my heart; and the Maid had been a great weak  ; and the Diskos did not be in the dark and mighty of the light of a great distance, so that in mine armour did be no weak and dreadful thing; so that I was surely not in my spirit to know that I had no power of the more; for I was not to have a power of my heart with me; for I was a glad of the light of the hollow, and made my head to the back of my heart.\n",
      "\n",
      "And I made no more for my strength that was so that I did be so glad as you do.\n",
      "\n",
      "And I came presently that I should be a place for the time and to go back.\n",
      "\n",
      "And when that we did be, I to have the Maid to\n",
      "------------------------\n",
      "------------------------ horror\n",
      "horror of the first time it seemed.\n",
      "\n",
      "``It was in that last time I had seen a little old woman! I now saw the old man had been found a little house in his sleep; for I could not think the sound as a moment I had ever heard before him. He was very low, and at last he knew his voice.\n",
      "I thought he was a thing of a kind of wind that had built, but it seemed to be the old man. He had made it to be done in the night, and that I had not been able to tell me; but I was afraid to go back for my sleep. Then I saw that the city of the trees, and made the way of the lantern, and the trees came out from that bed. Then the moon came out upon the floor and turned the door to the door. The door was turned by his head and went out into the street. He was now and then. And, for the man was a man of a chair; for the sound of his eyes began to  ; and his eyes grew quickly to his face, and his voice turned to a mans face.\n",
      "\n",
      "Then he sat on the table. He looked into a man to get his back into\n",
      "a corner of the room by the table, he reached the, and one of\n",
      "\n",
      "------------------------\n",
      "------------------------ creature\n",
      "creature the thing made no more than a time and more and offensive wonder that might be like that I know. It was in the same night, but that I could not help to be able to tell me that. I knew, I must have to go back again in that room, and only a faint and sound of my heart and a faint and sound; for I saw that I saw; for, as I do not know that the thing was gone over by my spirit to be of the heart and a thing of my spirit in my heart; for there was not a sound unto me,  . And so as it went, as you came back. And I was the broth to the Maid, and she to see her head into a little while, so that she had her head. And the Master Monstruwacan to be very quiet for the little moment; and afterward, I lookt very quiet and little, and to go back again to the edge of the rock to the breast of the rock that made of the Maid, and I did be a little, and afterward the Diskos; for the Maid was very quiet, and to be in a moment. Yet, I was that I should be come upon my hand, and I to be gone unto me; but I to be very weak and to be in that moment; and\n",
      "------------------------\n",
      "------------------------ night\n",
      "night that we had come to go back along the great sea to be found to find a distance of a very mile to  . The head of the hollow, as I could see no man. Then I heard the sound, and the trees, and the fire to the right side. The eyes of the whole door, and looked out at me, and I knew that it had been so that a moment for my breath. And then, when I had seen that I had been a long while before.\n",
      "\n",
      "``And I was in the darkness to the Maid, I saw that I could see it a place for a moment for an hour.\n",
      "\n",
      "And I saw that the Maid was gone over to the edge of the rock, and did go very swift; but yet asit I did think, I made no more to my power to be gone; and so I to know how that she had been in a great and bitter  . And I to go back to the Maid's very quiet, and so that the Maid to be gone from my head; and so, as I to think her very sweet and dainty and gentle unto my face.\n",
      "\n",
      "And presently, she made to the Maid; and she to be very husht, and to the more of her face; so that I had beenher in the same moment. And she had\n",
      "------------------------\n",
      "------------------------ dream\n",
      "dream the man did not be done. And now the wind grew very white,and and the sound and burst off from the right side. Then I heard a faint, shaking light from the great corridor and a black glow with a black dome of the hollow, and the moon of a very light from the door. And the light was very silent, and I saw that the city was a great and dreadful sound; so that I knew the more of my heart; and the Maid had no more more than I did. And I went back upon the Maid, and the Diskos to my breast, and as that I did be so utter a great while that was all in the night. And by that I did come upon the great Rock; and, indeed, as it did seem, and the sound came upon a little light of the hollow. And there did be no light in the hollow, and the Diskos did come from the edge of the rock, and made the sound of a very little way; and did be in that moment, and to be very glad to be in a moment; yet did it not like that she should be a little thing unto my heart; and the more to come upward into the far part of the Gorge. And, truly, in a moment I to come to the Maid; and so I \n",
      "------------------------\n",
      "------------------------ thing\n",
      "thing the thing I saw that the place.\n",
      "\n",
      "And the sun had risen into the sky, and the moon was still in a vast, and burning sound with a strange shriek like a very plain one of a thousand and silent as he had seen to his own son and his father had a little to take his hand in his pocket a mirror as a man. It was very clear that he could not see it. He had not been too much of the ship to keep out from my pocket pocket and; for my heart was always to come back!\n",
      "\n",
      "``I knew, that, with all of my mind, that the sound of my heart had been a good and proper place; for I had been that I did go upon her head into a instant of that place and her head. And I to be the Maid that I did be of a little; yet yet with that she had her in mine arms, and she to have her  ; but that I was very weak in her instant; and she then to have the cloak about me, as I do not; but I to have been in my heart for a little of my spirit. And truly I did come upon my heart; and I to have been so that it should be a wondrous and place; and I to have no more of this thing, \n",
      "------------------------\n",
      "------------------------ That night\n",
      "That night was no one thing ever, since he was seen by a sort of beam through desolation into the road and a low sound of the road, a great distance of the air; and it was still like that he would come out of the  . I saw a small, and lean cry and torn out of the street. There were a great light down over and above the great moon of a black white stone door and laid out of the road, and turned out over the dark road and looked upon the great lane which had lain through the city of rock, and the head of the great slope  .  , then and then a little way of low corridor into that dark valley, and still over the city. Then he found a curious glow over the road that had a great black black stone with the black stone door that was not the right to be a great and  . And he looked at the time I saw that the city of the bog had not seen it had come upon it, and that I had come to the place of the world that did not even like to do. And I went to the edge of a great and dreadful dreadful of the Rock, where was the great glare of the Rock; and the Ten-thousand did come upward to the edge, and the great noise made off the rock\n",
      "------------------------\n",
      "------------------------ mountain\n",
      "mountain I saw he had been mad, it was very very old man; but his voice was still a man of his father, and he told me that his head he knew he had his father in a moment.\n",
      "\n",
      "``You don't but he was a very old--man, as it was as he could see it. The sound of the old man had begun to stop for the house. It was now that he could not wish to make him a little man, and I knew that I could hear no more than any thing. And then, for a moment I could not know what he might have been so far as I might do so much like to keep it? -- not I have been heard of the strange horror of the city, and I knew that the very  . I saw the old man's and turned off from the door and the doctor; but when he turned, he found his hands and laughed. It was too well for the last he could go. And I had seen it in a place that she had come to the place where I might be in it. It was very old -- that I had a little one in the street and turned away over the door, and turned to find him at the door and turned back. Then his head was to the sound, and the noise of his\n",
      "------------------------\n",
      "------------------------ Ammi\n",
      "Ammi the thought I have been made up my own friend and the city and the city of my friend. I now saw that I could not be the more of any kind of the old and terrible house. Then when he had been heard a little, so far as he had left to the old man with his eyes that had a new and dreaded to take his face. Then he saw a sound of light and turned out of the road to the north window; and the trees that the moon was not so that I could not hear. I had heard the old woman and the door, but was not to find it in his face. And he would have come to the old man with a great and dreadful park, and that he would come out for a moment, and looked upon the face and saw the face that the voice was not to be the moon and as of the far-off night of a strange and horrible thing. The old woman's face had left me for an hour before, when I felt the door of my friend --the old horror that had come to me in all the scene.\n",
      "I saw that she had not been heard of my mind from the house. I felt that I must have had been a mad and wholly free of terror. Then he saw that the city were very far out \n",
      "------------------------\n",
      "------------------------ Cthulhu\n",
      "Cthulhu of the time no place of it.\n",
      "\n",
      "The next morning I saw that the city of the old house and a little figure in the road. The light was very low, and there was no one of any of the house as a very thick and rush of his own eye.\n",
      "\n",
      "``The man was in a very pause, and then that he saw his voice to his eyes that he was to his eyes and a faint and shriek of a strange and terrible thing. He was in the end, and a few moments in a few seconds I looked upon it at the base of a vast velocity of a vast distance of the black floor.  of all black trees on the floor of the road; and the moon was a faint and sound that came out upon the rock that a little black glowing into the sky. And I was glad of that strange and dreadful thing that was so utter a little and wonderful that the beginnings of that Redoubt did come upon my heart.\n",
      "\n",
      "And I, as you to think of the great Redoubt that lay in the night and the Diskos. And I to see how the light did, and as it did seem.\n",
      "\n",
      "And presently to the right of the rock that was, and the Maid to the right and did be very quick; for the Maid had been gone upon the far \n",
      "------------------------\n",
      "------------------------ raven\n",
      "raven , I thought it had been able to do.\n",
      "\n",
      "So the day he had made me to a lantern for a moment for a time. And then, with his eyes, that there was a vague sound like the air of  ; and there was a few of the light of  . Then came out upon the door of the room I had been heard of a long house on his head; and when he had found a great stone door with a candle, he saw that the house was still a candle and a few feet of the old woman and the tower and faint low  ; and then the moon was still like a faint and sound as that a single moon. And when I came, I knew of that I must not have done before my soul with my heart. I did not see that I had done before. I had heard a little while in the midst of my heart and saw that I was in a moment that was still of his heart.\n",
      "\n",
      "But when that I was in a moment, I found my mind and held me in a certain degree of horror that which had been lost in a very measure of the most hideous man. There was a very curious old woman in that city of the black sky. And I grew in that dark and terrible wave of my heart. Then the old\n",
      "------------------------\n",
      "------------------------ bird\n",
      "bird and he saw the first time for him as they might see.\n",
      "But I was in my own way. I was glad that he had come to me. I\n",
      "knew that the old womans voice was very afraid; though I had no kind, and heard the entire sense of a strange woman, but not even so familiar; though he was not to be a mans  . It was a small, hollow very dark and thick trees, but was like a certain thing that I could not see. I was not heard, but when he did not like the thing at the door. It was not for a moment. I thought it would; but I could not see what he wished it. Itss and the old man had never been seen and seen by the old houses dark of the dark room. There was a very light and like it. Then he saw it would be a very little thing for it's a bit of a terrible place as far. Then he thought that I was afraid to be about for a few hours. I couldnot however, that he had begun to do the old man. I had not seen it in the old house, and I could see that the pounding was a faint, but a sound and faint laughter of the voice. The room came out of the door and looked \n",
      "------------------------\n",
      "------------------------ nevermore\n",
      "nevermore . It is no doubt that the whole thing was too well. There is no one of those who are seen and like that I know what was in the same time. I saw that the old man and never turned away, nor knew he would be able to get a chance to be done when he had left to me, and I could not see that I would not be for it in the first time.\n",
      "\n",
      "``The great silence of that night I had been seen by the old man in his house; but the sound of his voice grew close to the sound. He was very close to the house in a very distance for the sound; and when I had found that the faint man was not come to the earth as a mad and touch of a terrible and terrible thing. There was something like to be a  . I knew that the city had a place of the city. I had not seen that I had ever, but had come back into the room, but as he had come to the old farm and in the library of a little room. The light of a very plain place, and the whole thing had been heard that I had seen before before. Then the last the servant had made it heard, and found that the old house had a place and removed it had not been like \n",
      "------------------------\n",
      "------------------------ dead\n",
      "dead that I am no more mortal than you have seen it was not like that I had been in an effort to make a way from me. I was a very old man to place that he would be like to do me, but I knew that he had come out upon me as a man and thought of a terrible and hideous thing, but which I thought I knew of a old woman in that I was lost. But in that moment he did make a sound of the sound; and I saw that the sound did seem as to be all in the dark.\n",
      "\n",
      "And the hours went back into mine armour and pouch; so that she did be so weak and so that I did not come to her, and she to be very weak; and yet with that a man that did be so weak and to make me in mine. And when I had eat and drunk, I made a little to my back, and to the Maid, and to have a new and loving gladness; and yet to have no knowledge that I be so glad. And truly, I to have her power of her dear heart, even as she did think that I had her so dear. And she to kiss me very dainty and tender.\n",
      "\n",
      "And I to have the Maid that I to be so to my strength, for a little\n",
      "------------------------\n",
      "------------------------ The bird\n",
      "The bird was no longer go to be done. The ship had been drawn off from the ground to the village of the tower. And I saw that the old old cat began to be silent and a little and more to catch my own friend. I knew that I would be a time to be able to do with a certain degree of terror and my heart to a pitiful idea. I have said that I had a place of a kind and wonderful, and that I had not known of the long days; yet I could not feel that I was a mad. Then, I thought of the cold thing and the door to be a very little shriek of my head. But a moment I saw that he was a very black and heavy eye of a great cloud of light. I had not been for a moment to be found in my mind, that I could not see what I had been seen in that I had come; so that the tumult of a  , had made the name of a great hollow. Yet, as I could not see. And now. I saw that the rock was not the place to be in the night; and the Maid had gone into the water, and the Diskos did come down into the Rock, and so that I was the Maid in that moment. And surely I was gone over \n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_to_try)):\n",
    "    text = text_to_try[i]\n",
    "    generated = samples[i]\n",
    "    print(\"------------------------\",text)\n",
    "    print(generated)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/mwords_i17775_l1024.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mwords_i16001_l1024.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mwords_i16501_l1024.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mwords_i17001_l1024.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mwords_i17501_l1024.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mwords_i17775_l1024.ckpt\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "The old folk have gone away through the great channel of the world to be seen. But when I had looked for the sound, and looked at the last time.\n",
      "For the hour was not a great place for it was not to be done, and by a very curious sound of the black world of the world of the world.\n",
      "\n",
      "And I went back to my mind, and I knew that I was not to go for a great time; for I had no power to make to go forward, and with a very weak and weak voice, as it did seem to make;  , there were come. \n",
      "And in this end the hour of this great and the Rock, I saw that there were a great distance off from the far of the Rock; and so to have no more of strength, and I to have no power to come upon me; but I to be so that I was not to my heart for a little; for it had not been so that I should come upon her and little of my soul.\n",
      "\n",
      "Now, presently I did be a while to be silent, and the Diskos to come back from my hand, and so that it might come.\n",
      "\n",
      "And lo! I did be in a moment, and made a little to tremble as I did go to my back upon the rock.\n",
      "\n",
      "And surely I went back again to the Maid, and so to have her so that my heart did be so that I had no power to come upon her; and I to feel very weak, as that I had been to come upon her, and to be utter so that I was come. And I to have a little while my body, as that she had come to a little while; and so that I could see her to be very sure. And I lookt upon the Maid, and I saw the Maid to the right; and she did be very husht, because of her sweet dear.\n",
      "\n",
      "And when she had been gone to me; and I gat to the end, and did be very quiet; and she to have no knowledge of the thing that I did be as it as I have done; and I to have set her feet very quick unto my feet, and made to the Diskos that I to lie for her hands; yet yet I should be, and to have no more to think upon; and so that I did think that I should be like to have a little while. And I to have a little while that, for her did be in her dear heart and utter dainty and dainty, and so that she did be very weak; yet in that moment, I to be so that it might be a little; for I did not to have been so far as I did.\n",
      "\n",
      "And I went forward with the great rock into the rock; and the Maid to   from the Maid; so that she to be in a moment, and the Maid to  . And I lookt upon her; and I to  , the Humpt Men and drank; but she to be very husht; for I to be that I was come in a little way; for I did be so utter in her heart, so that I might not have her thought that I had so utter as you, even as I did think; for I had not a little of the great and mighty thing that lay upon the trees, and did run as a little way off in the far part, that did seem to be the Maid to be a little thing, and that I had come to her from the Maid that she had no power to come to my slumber, and so that she did be so that I did be in a moment of my heart that did be so that I did go upon her; for she did make a little way upon me, so that I should be a little; and so did I have no; and to be so strong as that I have been; and I not to be able to have been so utter as I did go upon that place where the Maid did be all of her feet, as that she did be; yet that I did be so utter all that she was but to be; yet yet I not so utter, for I to have no power to be seen to her strength. And truly I did be very glad that she did be. And she to be a little while, and made her hands very dainty; and afterward, I put her hand. And the Maid to be so strong as I did think, and to have the more ready to my back. But the Maid to go very swift, as that they were come unto her, so that, as she had no power to go forward into the dark way of the great place for the fire-hole. And, presently, I saw the  , that I did go very swift to the rock for a great and brutish place where the trees did be like to a place; for it did seem to the end of the great and the Diskos, and the Capsule, and was the small while the great man had come down into the night.\n",
      "And lo! I made a little while to go forward again across, the little while the Man did be come from me, and to be a great and dreadful sound that did be in a moment, as that she had come in a moment, and to have no power of the more than I. And surely it was a little while that I did see in the moment, and made it to be a little while to go; for I to be very sure that I was not a more to be so strong with the Diskos, as it. And I lookt about her, and to the Maid that I should go to her, because that I did not to her slumber; yet she with me, as I did think that she was not in the heart; and she to be very dear and dainty unto her; and she to kiss me, and to have no more. And I to have the Maid very  ; so that she had not been to come from her, and to make her to have a little, and so to have a great fear of my heart, that I should be to come upon her again.\n",
      "\n",
      "And I made a little of the rock, and the pouch very  , and made the Diskos and so that I did be very glad that I should come to the end of the Rock, and did be so close for the hollow; for, in a moment that I had the Maid to go back to her feet very quiet. And so that we had come into the rock that did be nigh to a place; for there was a great and dreadful light for the trees and dreadful of that did. Yet I was   that I was come nigh, and of that time; and had a little while that I had gone; and I to have no time for it in the night, and made a little way to my feet, and the Maid to be very strong; so that we had come to the Maid that I did go; and she to be a little to go with her; and she to be in that moment she did be utter dainty and to her face.\n",
      "\n",
      "And I went up that I should be; and to the Maid to make my hand, as that I did be in her heart; but trulyI was the more of her strength; for I knew that I should go very swift and to the Maid that I did be in mine arms, and to have the Maid very quiet, because of that I should be so to be a little thing, and to be so glad to go for her; yet to have a little while her to be of a little man, as that I had been so that I should be in that moment; for truly she was so weak, and as she to know her  ; but yet not she to know her how to her naughtiness; and that she to be like to have a little thing, and to be very strong in the heart; for a little time to her face.\n",
      "\n",
      "And surely, as I do say to her that I did think, and she to have no more than that I did be.\n",
      "\n",
      "And I to be that the Maid did be in mine, and to be in her arms; and yet to be in her dear and natural, that she to be so to her as she to be of her, and to kiss me and loving and tender and to the pillow and to her; for she to be very quiet, and to her face that she be so that I was so that I had no heed of her; but that I did be so weak, and that I should have no heed. And I lookt very well, and to be, as that I have been in this thing, and that I have no heed that she did be so well as that I did be in that moment. And she to be utter weak and loving; and so that I was very little in her; and I to be very glad.\n",
      "\n",
      "And I went very quiet into my hands, and to the scrip and the pouch where I did go; and so to have a time, and the Humpt Men and the little while that I was gone very nigh unto her, so that I did be very eager to be; and she to be a little while, and she, and that I did be her in her face.\n",
      "\n",
      "And she took me very quiet, as that she did be so dainty upon my heart. And she made to me a little while that she was gone upon me; but truly I did be so well; for I did be as that she was so far as I did think; and truly I did be very quiet; and the Maid to have no more than her, and she to have her to be in her, and she to kiss me very gentle and loving; and so to be her dear and naughty; so that I did mean in the moment that she did be so that she had her to be so utter a while.\n",
      "\n",
      "And I went to a little place for her, and to be very quiet; and the Maid to have no more than my; and she to make her, as that she did not be in her arms.\n",
      "\n",
      "And I to know how that she had come her to my breast and a dainty as that she did make me; for she to be a little more; and I to have no word; but that there came a little while, because that I would have no power of her, so that I did be so utter a sweet and joyous gladness that of   of the heart that I should not so to be in the same time. And surely I to have a little while that we should be so utter and to have gone to the Maid for the Maid, and so to go forward into her armour.\n",
      "\n",
      "And the Maid to have no heed of her sweet pretty thing. And I came her to be that she should come from her hand; and she to kiss me very quiet. And I did be so that I should go very swift to the Maid; for truly there,did I be that she should be so utter a little and to go upon me; for that I was very quiet and loving; and she to kiss me. But I was very content; for her head very  ; but that I was her in mine arms, so that I had no more of her. And the Maid did be so that she did go from the cloak; so that it had been her in the heart and to have her so that she to know that I should be so utter as I did love, and so to a constant while that she had come, and I to be so glad that I had not so.\n",
      "\n",
      "And when the Maid did come upon me very swift, and made to her sleep; but I to be in the end, I did be very glad that she be so to have a little of my heart; and she was not that she to be a little way; and she lookt very quiet and loving, and made a little upon her, and did be her utter dainty; and she then that she had her belt-knife from my face, and so with a little while her, and she did nestle very unto me, and she did be very quiet, so that I might be her. And she to have her dear love that she be her, because that she had been so utter and so that she might have her to be gone from her pretty pretty; but truly I was her so that I did be her dear and loving and loving unto her dear and loving.\n",
      "\n",
      "And so we that she had no more to the more of her dear head. And I to be the more of the Humpt Men; and yet in my heart to be a little of mine arms, that I to have a little while, so that, she had no power to come upon her feet into the hollow, so.\n",
      "\n",
      "And I saw that she had been very weak, and lookt at the timeand and she did be so husht, as that she had told her to my strength, and so that she did be a \n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The old folk have gone away\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n",
      "The thing that should not be a chance of my own.\n",
      "\n",
      "And now, as I did tell, I was not to go for the little while that was come in a little while, I was come in a moment, and to have a sound of my spirit, and that was very small and steadfast of the Diskos; and the Maid did be so strong; for it was so that I did come unto it from her; and I was very sure, that there was a little thing that did go; yet was not to come unto me; for truly I did not be that of the Maid that did be in mine arms as that she might be all. And because that I wasthe\n",
      "\n",
      "And I lookt about her, and was very strong, and afterward to be very weak; and she to be that I should go forward again to her, and to be that I have the Maid that she to be very dear; and so to be a wondrous while as she might be that I did have her strength. But I to be a little time, and to be very strong as I did think that she did be very strong and loving in her face with me. And I to be very weak that she should be so that I did be in the same.\n",
      "\n",
      "And the Maid that made me with the Maid; but she to   that I did be, as that I have been so shaken as, that I should be come upon her hand, and so to have been gone by a little way, so that she did be in mine arms; and she to have no more than a natural way and that didbecome in a moment, and to make my hand upon her, so that it did be as I did go; and I to be in a little moment, as that I was come; and surely, I saw that I should be very glad to be for a moment; and she to make her to be in the same moment; and so to that a moment, in a little moment, and to have no heed of her, and did be that she had no power to her to me that I did be so that she was not in mine arms; for she did be very strong, because that she had been a love to her with her face and gentle upon mine.\n",
      "\n",
      "And she then that she did carry her, and so that I did be her utter gentle and loving and loving, as that she had her hands and to her dear face; and she to be very dainty and so to the dainty that moment, that she to be like a dainty, and to be so that I had no more of Mine Own.\n",
      "\n",
      "And the Maid did be very weak and to the raft, and so  ; so that the Maid had been her to her; for she to have been her in mine arms with a dainty, and to make me her to my hand. And, in verity, that she was very quiet, and so utter and so to have her so dainty as I might think. And she to be very husht; and so to have no; and yet to have her, because that she did be so utter a dainty upon the heart.\n",
      "\n",
      "But this was a sudden and dreadful strength of her being, that had no power to come unto her; and she to be very glad to her face, and did be so wondrous that I did so utter a little thing, so that she to be in the heart; and so to be that I did be so utter a little and proper to the heart; for, truly, she had no power to  , so that I should have no more to be able to be in a little fashion.\n",
      "\n",
      "And I went forward, with a little while to the Maid; but yet did I be in a great and a little while that I did go very quick, and to be a very while for a great while that did be like to her. And she did be a little and loving upon my heart, that was a small and loving and loving, and that she  and she then to have a little more of me, as that it was a little, and she to be very weak and in. But, indeed, I knew, that she had not been so utter, so that it was as that it had been gone unto me, and she did be utter quiet in a moment for her sleep.\n",
      "\n",
      "And when that the Maid did be very quiet, and to the Maid to be a little and then to my breast, and I to have a little of that part, where that the Humpt Men had been in the Maid, and to go very dainty upon me.\n",
      "\n",
      "And when that I was come from the Humpt Men, and I to have no knowledge that she had done in a moment, and did be then that I did be so that we had no strength in my life.\n",
      "\n",
      "And when that I was come to the Maid, and to   that she be gone from mine, and so utter a little, as that she had her head and a little while her, she did seem to be that I had her to be.\n",
      "\n",
      "And I made her to the Maid; for she to make her hands into her face; and afterward I to be very quiet; but yet with her sweet dear love as that she did make all her; and I to need that she did go with me very quiet. And when that I was come, I came  .  And I saw  , that she did be a great and cry upon my head that I was so utter and I was so that I did come from the raft.\n",
      "\n",
      "And I went forward at the feet again; so that I was come very swift unto my feet, and so that I should eat and drink, and so  ; and she did be very; and that she put the cloak about her head, and kist me, and to be the more of my spirit, and to have been her to be in her arms; and she to be very dainty in mine arms with my love, and I to be in her dear heart; and I to kiss her very dainty upon her lips, and that I had no more of her dear feet that hedidbe indeed, she did kiss me very strong and loving; for, truly, I did mean that I have her thought, and she to be a little of that she be in her heart. And, in verity, she was her dear and loving, and so that I did be so dainty in the moment, and that I did have no more to be able to sleep in; and truly I did be very glad that she did be so dainty.\n",
      "\n",
      "Now I saw that I was not come to the Maid where she had no strength; and so that we had eat and drunk, I to think, because that she did be a little way of my heart; for, indeed that she had been a little while; but did I put her hand into the water; for she had no power of mine feet very strong; so that I was not to be the broth of her dear and a little to my heart, and the cloak and very gentle and so, as I did be in her instant to her; and I to  , and with a little gladness as a great, as that I did come in her head very quick. And she lookt very swift and gentle; and she had to be the more of her pretty feet, and did seem to that she had come into her head and to the right, and to be utter so that it was very wondrous and proper for her to be that she did be so dainty and a loving unto my heart, and all with the little of the heart; and I to be very strong, because that I was come to a great and tremble upon that part where the   did be so  . I saw that she did be a little way off upon her, as she might have been, she to have her head in her head; but she to be in the end of her dear, that did be in the heart of the heart.\n",
      "\n",
      "And I to be in a moment, and to be so utter and the more to her head; and I to be that the Diskos in my heart.\n",
      "\n",
      "And I went forward to the Maid, and to be a little and tender to the right to her hand.\n",
      "\n",
      "And she to have a while that she did be a while to be a little thing. And I to be very glad of my heart, that she might be all that I have her thought that her heart was her to have a little, and she to kiss me and to; so that she did seem so that I did not so to be for her in a moment.\n",
      "\n",
      "Then, in a time, and the Maid to   to me, and she had not to have been so far as we might have been gone.\n",
      "\n",
      "And I went downward into the Gorge, and did come upon her, and did be utter husht, that we should have no knowledge of  ; but she had not; and to have a great joy of her dear and dainty, as that she  and that she to have her head to her toes that was her dear gentle and dainty; yet she to make her that I had her in the heart that she; and she to have to be so dainty, as she did be so dainty unto me.\n",
      "\n",
      "And I saw that she had no heed of her strength; but, truly,\n",
      "that she did be a little time, as you shall mind; and to be so; because that she did not be in her own dear dear and gentle.\n",
      "\n",
      "And she put her belt-knife into her, so that I was not to have her, and she to be very; but did be a little and dainty; and to be a lovely and tender dainty; and so to be that I have to eat and a little while; but that the Maid did go very sudden upon her.\n",
      "\n",
      "And the Maid to have a little while; so that I was not come in a little; and I to have no more of this thing. And I to have no knowledge; but I to have no knowledge of her being to be all of that she be of love to be all all that in all the heart of the heart; and the Maid to be both to her; for I to have no knowing of her pretty heart, that she had been in her heart with a dainty while that she had her.\n",
      "\n",
      "And she, in a moment, I to know that she had her; and she to make me very dainty. And, in verity, I had a little time, as she did be; and she to be like to have her dear dear and loving naughtiness, as that I she kist her in a little while; for she did be a little while, and I to know with her sweet and naughty and dainty that she be in a dear and loving maid, as thather in her heart.\n",
      "\n",
      "And she to be that I had so that I should be the little; and I lookt at her; and she to have been utter tender and loving and loving. And I lookt at her, and I to have her her dear and dainty with a quick cry and the Maid to her hand; and yet to make her very loving; and so to seem as that she was in mine heart. And truly I did make her her head of my heart, as you did perceive; and she to kiss me with her dear hands and gentle and loving, and so that I did go so that I did be so utter her. And truly, she had no little that she had her pretty dear and loving upon her face that she kist me.\n",
      "\n",
      "And I took her, because that she did be so utter her, and to have her love that she did not be her. And, indeed, when she she to have her head of her dear, that she did be so dainty; and she to make no need that I be so utter a little of mine anger that she to be so dainty as I to have her to be so that I to have the power of her dear. And she to be that she had not a little thing; and that I was very quiet; and the Maid did be very husht, and to make her to the heart that she to be very sweet in me, and to make her dear heart, that she to be her; and yet to have a little while that she had her thought that she did be so dainty; but she to be in her heart that she did love that she did not her naughtiness to be so dainty. And so that she had her belt-knife to me so that her, and she did be very dainty; but yet with that she did be her; and I to be that she be in a moment, that she did be her pretty dear with her eyes, as thather I did not so well; and she to be very quiet and dainty, as that I did be a little of her love, and so to her dear.\n",
      "\n",
      "And when that I did go down upon, she to be a little while; but yet to be so weak, and so, as I have said, that I did be a great and proper to have her courage.\n",
      "\n",
      "And when, as I was there in the place of her  ; for the Maid did put her, and she to have her head very tender; and she to have been so that I did be a little while.\n",
      "\n",
      "And she came up to her face with me; and she to be very quiet, and as she to be in a moment, and. And she to be in a moment, so that I to have her strength and to be in her, that she to be in a moment to her; so that, she to know that I was her; for her heart did be as that I should be in her heart that I have no more to her own body, and to have her to love me; and that I have no more to her pretty. But yet, with a little to the Maid.\n",
      "\n",
      "And when she had gone, I to go again, she to be a great while that we had eat and drink; and she to kiss me from her, and she to have no word, as she to know; but I knew that the Maid was so utter, so that I did go to my back to her, that she did be her in a little moment; and she to be very dear and tender, and I did be so utter as. And she to be the more  . \n",
      "And the Maid came to me, and the Maid to  ; and I to be that the Diskos very warm and dainty upon my head that she should be so weak as to have done before. And she to be the little man very strong; and so that I should have no knowing that I did be so well as you shall have done her with her love and to her, because that she was not to be of her dear; and to kiss me again that he did go; so that I should be very dainty in the end, so that it did be so far. And she to be a great and dreadful dainty of the Humpt Men; and yet, in that I did be so weak; but I to have no more of her dear and love; and to this to be a dear man in my heart, that I did be so that it did be like the heart of the heart of all that did be in mine heart, as you to think; and she to be very dainty, because of the little moment that she did be so weak in her arms with a little man, that she had no little to her, as that she had her to love with her, so that I had her so to be a dainty and tender, and to kiss me. And I to be very quiet, and to her face to be very dainty, as that I should be in a little fashion that did be in her arms, that I have her thought; but yet to have a love that she did make a little way unto me; for, truly I, I knew that I had not come from her, and to have her to be the sweetness of her own dear heart that I did mean. But she to be, as you shall understand.\n",
      "\n",
      "And I went forward to a little while, and made to the Maid again to her, as I do; and I to be that she had a little while; and afterward I lookt; and she to be very husht, as she to the man of mine own heart, and that I did come from her; and surely I did be that I should her, as that I should have no heed; for she was not to have a little thing; for she did be very quiet; and she to be in her, and did not be of her love; and I did run with her hair very dainty, as I to have no heed of her dear that I had no heed that she had not so that, she to be so utter a little thing as that she should be so weak unto her naughtiness; and yet to be that there did be no more than a little; and she to be in a little while, because of the little time and did be so utter as she might be in a moment. And she to make her a little; and she to refuse to me, very quiet and sweet and loving, so that she had her so gentle to me; and truly, I to kiss her and gentle very tender, and to be a dainty and loving upon the cloak; and the hair came upon the cloak of my hand, so that I did go up to the earth. And the Maid had made me to the scrip; and I kist her to my feet, and she to be very quiet for a little while; and so to come very sudden, as that she did be very quiet; and so that it did be as I have told her that she did be very dainty, and so that she did be very lovely; and so that I should have a little way to her, as you shall think. And I to have her dear strength and loving and loving, as that she did come from a little moment; and, as she did be so weak as I did, and to be a little of her heart. And she did be a sudden way; and she then to refuse, and I to have a little while, as I did be so utter; and yet to be a little while in the moment, that she to have been so that I did think of the heart of her love.\n",
      "\n",
      "And the Master did be then, she put her head very loving, and so to my face that I did be so that, and I to have the Maid,  , that I had her to her, and that she did kiss her dear head; and the Maid did be a little of her dear; and she to kiss me very very dainty; for the Maid that I kiss her, and she to have no more for her; for she to be so dear as I might.\n",
      "\n",
      "And she to be that she to be in her arms; and so I did be so; for, indeed, she to have been her pretty to be her; and she to be kist the cloak very loving for her; for, in a little moment, and to be in mine own heart; so that she did be so dear; and she to be very quiet and dainty; for her whiles that she be not in mine heart; but yet with my love that did be in her dear and gentle. And she to be very little in me; and she to be in her heart with me; for she had been a little of the heart with her dear dear and love to. And she did be very strong and dainty in mine; and she to have her belt-knife to, and kist me again. But I did not to have her, and she to be in her dear and love that she did be so dainty, as that she might be all in mine arms with the heart, and she to be a little way off.\n",
      "\n",
      "And I took her to her, as I did her, and to be very quiet with the little of the cloak, as that she might be so dainty, and the more of my strength and her head; for the little man did come her into mine armour.\n",
      "\n",
      "And I to have no power of her pretty pretty; but she to be that the Maid had come very sudden, and to make her pretty dear; and surely she did be a little thing, as that she might; but she to be like that she be in a moment to the Maid; and yet I did be so that it be a little thing unto her.\n",
      "\n",
      "And she did be very husht; and yet to have a little thing.\n",
      "\n",
      "And she went back again, so that she had come to her feet in the hollow; so that I should come to the Maid upon her, and to be a little and then of that moment.\n",
      "\n",
      "And she to be very husht, and to be very husht and to go; so that I did be so that I should come to her hand upon me; and she to be very glad that she be so that I should be like to a natural fear; for I.\n",
      "\n",
      "And I went forward into the great and part of the Humpt Men, which she had been nigh to me, and she to have her head to be in my love, and so utter a little while and her head of the little moment that she to be in her dear face, and to make a dainty gladness, and to be so.\n",
      "\n",
      "Yet, I to be in the Maid to the raft; and I to kiss her, and took her hand, as I did think; but she came to a little while that she was come, and she to be in that moment, that she had her hands to me.\n",
      "\n",
      "And presently, the Maid had her to the Maid; and she to be that she put her head about her pretty shoulders, and; for I was very weak and gentle, and that I should be a little while that she had come into her dear face.\n",
      "\n",
      "And I made the Maid, and I to kiss her very quiet, and she to be so that I should be a child; and she to have been that I be able to have to her dear dear and dainty. And truly she was not so that; but she was very quiet in my heart, because that she had her so sweet and gentle, because that I was not so utter a little. And the Maid, that did be so utter as that I should go to her. And I to have her; and surely, she very very dainty; but yet to make a little thing; and I to be that I have her to love for her.\n",
      "\n",
      "And she did be a little while that she was come from the raft, and made the Maid; and she to kiss me again, and I to look for her, and did nestle very sudden and to kiss me; and I did feel that, I did think to be the little thing; and that she be in the heart of the Humpt Men, and the Maid did go very close upon the rock; and, truly, as I, I, to have her so dear as that I should have no more more than that I should come to sleep. And surely I had no more than a man for her; but did she to be very quiet and loving as that she did know. But I did be so utter as that I did come to her, and she to be that she had her belt-knife and she to obey her for she then to be a little of my spirit that she was so utter a little.\n",
      "\n",
      "And she to be a little while that I kist her; and she to have no need of her dear naughtiness.\n",
      "\n",
      "And I did be that I to be very husht and gentle and loving, and she to have her dear dear woman; and I to be the more of her pretty pretty, and she to kiss me very dainty; and the Maid to have her to her hand from her to me, so that I to kiss her dear and naughty loving; for I, as that I had been; and she to be like the way of her dear and dainty unto me; and the Maid had not her head, as you that I have her to have her to her, and to have no more than her. And she did be, that she did be very dainty and tender; and she to have been gone from me, as she did have her love to me, so that she was her to be her dear, and she to kiss me with her dear head. And I to be a quiet and loving and dainty upon her; and she to have a dear man as that she did love her and loving with love that she had her; so that she did be so weak and dainty.\n",
      "\n",
      "And presently, she had no more of mine arms, and the Maid to make her hand very gentle and loving and gentle with her head and gentle with a little gladness and her. And so to be that she to be gone very quiet;and indeed, she to be so dear and loving and dainty, and the Maid to make her to me, that I to think that I was a little way off; but yet did be as that she should make her pretty pretty loving and, because that I did be so utter as I might, and she to be in the end. And I to have the Maid with me, and to make her to my back, and to her belt-knife and she  ; and she to be very quiet and loving and pretty gentle as that I did be the more of my heart. And the Maid to be the cloak, because that she had come from a little while; yet that I should have no more; but only a little way; and so that I should be in a little place of the rock. And she then to be the more and tender. And so that I lookt upon her; and I did be in a little, that I did be in that instant; but I kist her with a little while that Ihad and kist her very quick and tender; and I kist her and gentle garments, and I did be a little of the heart, and that she had her head to her hand, and she to know how that she was not so to my love; for the Maid that I did be in her dear dear and loving tears that, and her pretty feet very upon her with mine, and kist me with the little love and that she did be her dainty; and I to be a little that her love; and that she did be so dainty as I to be so that I might be like to be the broth of her heart that she did not to be her, and to have her dear dear dear and loving and loving; and she to kiss me very gentle and gentle. And, indeed that I was so utter in my.\n",
      "\n",
      "And so that we did be; and I to have a little while that she did come, and so; and she to have her to her garments; and that she did be in her arms and loving and gentle to me very gentle, that, in a moment, I to have her  ; and she did not be a little thing that she had no power to be done, because she was come.\n",
      "\n",
      "And I to be very quiet; for I was very husht, and to have the Diskos, because it was very well; and I had no heed to the Maid; for I to be in the same moment; but she to be very strong, as it did be so that she had her head to me in mine arms; and truly, as she to be done in a moment that she did be her dear dear and loving; and she to kiss me; and she to make me to my spirit, and she to be so utter as I do; but that, she to be like a little of the man that doth be in that moment she to be in a little moment.\n",
      " And when I did be a little, I to have no heed for Mine Own; but she to have no more in her; and she to refuse that she did be very dainty in mine armour.\n",
      "\n",
      "And I to be that I should come to my hand; and I to be in that I have no more than a great thing, and did be in that time.\n",
      "\n",
      "And when she came to the right hand, and the Maid did be; and, truly, I made no heed to her, and to make her pretty dear and dainty, that she be so dainty and loving.\n",
      "\n",
      "And she to be very husht as to be so that she did kiss her; and she to be her, and with her face and dainty with the cloak that her hand and kist me in mine lips; and I to go very quiet, and to have her love that she did be in her own face; so, as she do mind. And, truly, I did be a little way, and that I should not be in the same moment; and so that I did be in the same moment, because that I had been in a while that the Maid came  ; and she to have no knowing; for she did be in the same moment; for I to be in the same moment, and made to a sweetness and dear; and she to know that I had no heed in the matter; for she was gone very close; but she to be that there did be her dear heart. And I to say that she was her to her dear face and dear dear dear, and I to be her with the dainty of her, and she to be in a moment, because that she did be her.\n",
      "\n",
      "And I came her with her arms, that we to have her belt-knife very dainty upon her; but she to be that she be very quiet, and she to have a little way from her, and she to make a love with me, so that she had her so dainty a little, and she to be in that moment.\n",
      "\n",
      "And surely she did be so that it did be so that she might make her a little; and she did be so that I should be very strong; but yet with her dear dear dear, and that I did know that she should be so utter and in my heart for her sweet and naughtiness.\n",
      "\n",
      "And surely I to go again to her; but she to be very quiet and gentle to the Maid.\n",
      "\n",
      "And surely we went forward again, and the Diskos to my hand; and she to have the Maid that she be in her arms with me, and she to kiss me very dainty, as that she did be, and I to be very glad to  ; for I was come to her with a little gladness and to be that she did be in her face; and so to be a little while her to be in that moment that she to be in her face and, that of her dear heart; and I to be so utter in a. And as she to be in mine arms, as that I have her love to be all that she did be; but I to have her dear and dainty; and so, as that I was very quiet in her arms; for she had been so that I had her power to come to her; yet she to have no power to  ; but I to be in the same moment. But the Maid to be so that I did be her to be a little; for her she did be in a little moment; for she was that her face was not to her. And she to be very strong. And, she to be in the same moment, and so that she did be in the end of my spirit; but I to be like that I should be a little thing; and I to be like the Maid that I did be her to be that she to kiss me. And I to have no more to my task; but yet to be a little thing with her; and she to know that she did be in her instant; and she to be very dainty and gentle and dainty and tender, so that I did be in the same moment, that she did be very dainty; for the little thing; and so did I be kist her in the heart; and truly, as it did be so wondrous as I to say that she was not to be so that I should not to have been stirred for her in mine arms.\n",
      "\n",
      "And I to have no power of the Humpt Men; for yet I to be so that I did be so that she was her; and afterward, I to have a raft, so that she to have no need; for she had no more to be in all; but yet I was not to know that she was so to have been so weak as that I did be in her own love. And I to have no need of her dear dear pain.\n",
      "\n",
      "And when I had eat and of the Maid for her  ; and she to kiss and very gentle, and she kist; and the Maid to be very quiet and loving for a sweet and love of me that she did lie in me with me, and she to kiss her head very gentle, and I to be her in her, and to be a little thing to be her pretty lovethat as I to know her that she did be in her.\n",
      "\n",
      "And so that she did be so gentle and dainty unto the cloak where she did be very dainty. And I then to have her pretty gentle, because that her heart was her dear and dainty; and she to be a little thing that; for, truly, I to have been the little way with her; and she to be very quiet with the little while; and she to be very little. And she to be very dainty, and so to have her naughtiness that I have her, and to make her a little while; and she did be a while in a little moment that, and her hair to be very tender; for she to be a little while to her; and I to have no heed to her, as that she did be her dear dear woman and loving and dainty, and that did be very sweet unto her own dear and dainty. And when, she made her belt-knife and I lookt upon her; and she to kiss me, as I did be a little; but she to refuse to kiss me; and she to have no dear; but truly she did seem that I did be all the Maid.\n",
      "\n",
      "And I lookt very quiet and gentle from the mouth of her head; and the Maid to have her belt-knife in her heart; so that she was very glad of the Maid very tender and loving. And she to be the cloak of her lips; and I to be that she did be her dear dear; and I to be her dear dear; and so I to be that I should be her to be all that I have so to have the Maid, and she to kiss me very dear, and to kiss her dear pretty daintythat and to be that she kist me; so that I did be so well.\n",
      "\n",
      "\n",
      "And when that I had come from her, and I to kiss her Maid, she kist me, and I to be very quiet and dainty; and she to be that I had come from her pretty head that she had so a little to my, as that I had no power to be in mine armour. And, indeed, I did be very quiet and dainty, and the Maid to be her; so, indeed I to know that I did be so glad as I have told.\n",
      "\n",
      "And when she was come to her hand, as I have told that she should be gone, and she to be very strong with her and dainty, so that she did be all her. And, indeed, she to have her belt-knife to me; for the while to be a little while that she had no power to be so strong as that, as I have done, she to be in her heart that she did be in her arms; and she to be very dear and loving, and she to be very dainty, as I to think that she be a little way off from her, and that she to have her head to her dear dear and loving naughtiness that she had me; and she to be very dainty, because of the dear love and love; and she to have her, so that, as you do know with her, that she did not be a little while her; and she to be that she be her in mine eyes.\n",
      "\n",
      "And I to be then that her heart very gentle; but she to be\n",
      "utter weak and dainty with a little cry; and she to make that it did seem to me, and to be a little to be in her dear dear and love. And she to be utter quiet and tender unto me, that I have her to be so dear in the heart. And so that I to be in her heart, that she to be in her heart; and truly, I to have no more of my heart.\n",
      "\n",
      "And I lookt at her, and she to be very quiet and gentle; and that I should be very weak and loving, and that she did be her, in a moment.\n",
      "\n",
      "And presently, I did go, and to be a little while, and afterward I to be very quiet and loving with a little while, and she to make her hand with her, and to be very quiet, and she to have her belt-knife that she be so in mine arms; and to her dear body of her sweet tears.\n",
      "\n",
      "And I took her to her head, and I to have her her dear love; and I then to have that she to be so dainty; but yet to seem that I should not have to be so utter a natural, and to her to be of love unto me, and she to know that I to be like to a child in a very dainty upon my heart; for a little thing and to have no fear for her; for I had been a great and loving; but yet she to be utter dear, as she to say, and that she had not so that a thing doth be a wondrous maid.\n",
      "\n",
      "And, presently, she said that the Maid very very dainty and gentle, and that she did be in her face with her pretty loving; but I did run up into the hollow with the hollow; so that it did be very quiet; and she did be so glad that she be gone from her; for she did be so dainty as I did go with her; but she to be that she did be very dainty and joyous; and that she to be in her dear heart that she did love, so that she had been so utter a sweet and dainty as that I had her. And surely, she to be a little while to her head that she to be a dear and loving; and I lookt very quiet, and with a little care that she; but,she in a little moment, very quiet, as I did go; so that I was not in my heart; and so to have been a little while that she had come to her feet. And she to the Maid that she had not her to her, as I do her with her dear heart and dear; and she to make her belt-knife to her pretty hair, that I put her her hand. And afterward, I to go forward again into mine arms; and I then to be in a while that I should be a little to have a little of my heart.\n",
      "\n",
      "And when that she had made a pause, as she to be in mine hand very gentle and tender; yet I to have no power to come from the same time that doth be so that I did not be stirred in all that of the heart that I should have come to her hand upon her head, and so that I did mean that she be so dear as I do think; and she to be a little of my heart, as I to say, and I to have no knowledge of her; but yet to be as she did be in her arms with a little while, and that she did be in a moment, as that I might be so utter as I did know. But she to be very quiet for her, as, and the cloak very gentle and dainty upon her, and so that she to be in the little man that she did be in her dear and loving and tender of her pretty dear; and I to have that she to be a little while, and that she to have a dear joy and dainty, as you shall think that I be to be; and she to have no more of her dear dear pain. And she to have her to love that I did shake the little man to kiss her with mine eyes. But she had a sudden love to me in the hollow of my spirit that I had her to her feet in the heart, and she to be very quiet and gentle with a little while that, and so utter as I to think.\n",
      "\n",
      "And presently I to be very husht and to the raft where I did be so; and the Maid to  ; for her  , as I have told; but I to be in the end of her dear; and she did make that she be in her arms.  ; her that I did be so utter her, and to be very dear and loving her pretty loving;and for she to be that I have no heed to be as of her; and I to be that I have no power of love; and yet with her dear love, and her pretty dainty and loving, and kist her with her shoulders in my heart, that was her so gentle and loving, and she then to know that I did be her pretty dear, that I did be so that I had so utter her, and so that I did be all her and loving for her dear, and that she did be in mine arms; and she then to have her dear and gentle and loving; and then she to be kist me; for I to be very dainty; so that I should be, in that moment she did be in a little while, as that I had been in a dear while that she was come from her pretty.\n",
      "\n",
      "And she took her a little while from my hand, and made a little way of her, and had her belt-knife that, she had the little time, and she had no more.\n",
      "And she then to have her head that she did go up upon me, and she to refuse that I, to be very quiet, and to be very dainty and dainty, and so that I should have been her to be a little of the man; for her she had not her to be gone upon her with her dear face as that she had her in love of her face that she did be in that; and she did be so weak in her own heart that her love did be so that I should not have so love that I did be in her; for she to be a little while; and she to be so dainty as I might have to her naughtiness, and to have her love that I be her to her dear and gentle. And, indeed, she did not to be her dear pretty gentle and loving, and that she to be her utter and tender, as that I do mind that she be in love of her dear dear and love. And I then that she kist me, and she kist me from the scrip and her, and so that I might have her her love with her pretty loving for her. And she then her head very quick. And she did have to her face that I be her to be her; for she was very dainty, because that she did be her to be so utter as I did love; and so that I did be like that I should come from her. And she to be a little while that she should be in a moment to be that I should have her; and to be a little while in her.\n",
      "\n",
      "And she to  , as I to go forward again; and truly I to be in the heart of the Maid; for I had not to be so that I did think her, because that she did be a little while; and she to have gone her, and she to be a child in her own face; and that she did be a little way, and she did be in her arms, because I to have no need of my strength and love; and so that I should think; and she to have a little while that she had her head to her face. But she had her belt-knife very and gentle upon her lips. And she to be very quiet, and she to have no need of her, because that she did be so utter as that she had been, in a moment. But she was very quiet in a little time; and, indeed, as I should have been, and made a little while to be in a little while that of the Humpt Men. Yet, in the moment I did be so close; for she didbe as I have told; but she to be very husht and dainty.\n",
      "\n",
      "And in a moment I saw that she was so strong, and I to  ; and I to have a great while, and the Maid very quiet and to the Maid, so thatI I to have no power to be so that I might think; for that I did be so utter her; and I to be very weak and with her pretty love, and to her very sweet and dear; and so that I did be in her dear face of her pretty; for, indeed, she made her sweet head of mine armour and gentle and loving; for she very  ; and the Maid to be very strong, and her to have her love of her dear naughtiness, and to be so dear in her; so that she to know that I did be in the heart that she be in mine arms.\n",
      "\n",
      "And she took her hands and loving, and to have her belt-knife and her face very tender upon, and I to be that she be gone from her, and to kiss me; and she put her head; and to my face with mine armour; and she to be in that moment, and I to need that I should be so utter to my heart.\n",
      "\n",
      "And when, I to be the more and more to have her, and to make the broth very tender; but yet to be so to be in her heart; for she to have no knowing that I to be so, that she did be in her face. And so that I did not be in her own love that I did be so utter; yet, as I to think, she to be in the heart that she did be in her face, and to her face that she be in mine arms.\n",
      "\n",
      "And I to have her dear dear and loving and gentle and loving, so that I did kiss her; and she kist her and very dainty from my hand, that I did be so that I did be so dainty; for I to be in her dear heart, and to kiss her head and to be in her face; and I to need that she did be in all the man of a love; and the Maid to be so that she be not so to be all, and I to be very glad to be in the same moment, as that she did be so strong, because that her naughtiness did be so to her. And she did be her utter dainty and loving, and to be her very dainty. And so to that I had so a little to have her to her naughtiness.\n",
      "\n",
      "And I was her gentle with her; and she to make her to mine arms, and I did be so that I did be her, and to her very dear and dear; and I then to kiss, and to be very husht and tender; and so to have a lovely and tender gladness that, and to be so to have  , so that I should come to her to have her, because that I do not to know, and I to have a power to come from her; and she to be kist, because that her head did be so dainty; so, indeed, she to have a little while; but she to have her dear gentle with me upon the face, and she to kiss me that I be very weak and to have her love; but thatIshe to have no fear of her strength with her heart, and that she be very weak; and she to be that I should kiss her with her dear dear and gentle loving and dainty, and the cloak and her hand, and to have her to love, and I to have her love that she did not be a dear woman, and so to her naughtiness to her dear dear and dainty, and so that her heart had no more of love; so that I did be so utter a sweet and loving and dainty; and so utter that I did mean to be a little of my heart; for, in verity, as you to have her, and she to be very dainty in her; and so to have a little way in mine arms, that she to have her dear love and all that she did be all in that I be all that she be in, and to have no more more than that I did think. And she to have been a dear and dainty maid; and that I be very weak; but only that she to be in mine heart with all of love.\n",
      "\n",
      "Now when I to be a little while to my hand, that I to have a little, so that I was come in her. But I did mean that the Maid had her and strength that I should have her to be gone, because that shedid and so a great while in a little while; and did be very quiet and gentle, and so that she had so a little while that she did be nigh upon me. And, surely, she to be a little while in her arms, and I to refuse me that I be in her. And she to refuse to her very dearthat because that I had her so dainty; for her to be all that she did beher as she had her; and, indeed to be that I should think she to be a natural way; and I to have no more of the Maid, and to have her dear dear, because that I did be her in mine arms, and to have her to her naughtiness; and yet to be that she to be a lovely and joyous as her.\n",
      "\n",
      "And I to kiss her Maid very gentle,and with the cloak, and the Maid to have her head with my heart as that she did be so dainty; and so that we to have no need that be come unto her feet and dainty, as that her spirit did make me to her face; but yet to be very strong, as she had come upon me from her pretty shoulders of her dear spirit that she had no love; but she had been that she had come to her; so that, she to be in her dear dear dear and loving tears, and her face very little with a sweet and dainty gladness to her and love; and so that I she to have her to love her with me that she to be in the same instant, because of the armour that she made her to mine arms, and that I should be in her hand and so that I should have her to her feet; and she did be that she did be so that she had her to love me, as she did be her pretty loving; but yet I not her mind to my heart. Yet she was not a dear man; and she to kiss me that she to be very dainty. And she then to have her to kiss; for I to have no power to come, but to be in that same thing that she had her thought, because that she did be so that I should not.\n",
      "\n",
      "And surely, I did go upward into the great; but yet to make her a very little; but yet did I go with her head; and she to have no fear of mine arms for a. And I did be so utter and to be her dear pretty loving and pretty, so that I to have no need to be that her own way and to be all that I did be like to be the little man of her pretty heart.\n",
      "\n",
      "And she came then to the raft; and so that she did be so that I should; but she to come her again; and she to be in the cloak, as that she might be in mine arms, and so that I to be in mine. And I kist her with a great and gentle, and that I to make her to be a little of the Maid; for she did be in that moment; and I to kiss me.\n",
      "\n",
      "Now I took her Maid; for she had been so that she had gone her feet in a moment; and I had no more in her feet into the rock, as I had told that, in the same moment, and she did go very strong with the Diskos, and she had come to me. And she to be very quiet in mine arms; and I made no little; but I to have no more of her love.\n",
      "\n",
      "And presently, the Maid to go forward to the cloak, and put her hand into my lips, and to go back to the Maid; and I to go forward, and the Maid to have her belt-knife and; so that I had been gone to the little of Mine Own; but she then to make her; and afterward I to go; and she to be a little of the mouth and the more that she did be very dainty upon her, with her head. And she did be very strong in a moment, as that she had been her to run away; so that she had her belt-knife to her head of the cloak upon her; so that she had been in her arms, that did be very dainty; but I to be that she to be in a moment, and to kiss, and to be in a little moment; so that I was her in my heart; and truly I had no need that I should be so glad as I did be in the same moment, so that it did be so that she did be.\n",
      "\n",
      "And she to be very husht, and to have a little time.\n",
      "\n",
      "And surely we to come again upon the Maid; for I to be the more and joyous to her back; and she to kiss me very gentle with mine feet very quick; and so that I was in a little while a little, as that she did be very weak and to sit with her dear face and dear and gentle. And she to be very quiet and gentle and loving.\n",
      "\n",
      "And when the sixth and the twelfth hour did come from her, that I lookt her feet upon me, and she to look again upon her. And, indeed, as I did think, and to have no knowing, that she should be in mine arms, and she to be very dainty and loving, as that I might think; and she to be; so that I had her and a little while to my feet; and she to have no heed of her naughtiness that did be so that, and her to be a little and loving her pretty loving and dainty.\n",
      "\n",
      "And when that I did be the broth, she came up from the trees of the pouch, as she did have her head to be upon her head. And I to have no heed of the thing; but did she to have her dear strength; and I to be very strong with her in her face with my face, and to have a little while, that I did be so; that I should be so glad that I did be so that I should, and so that she did be very strong, and to be so.\n",
      "\n",
      "And she to be very dear and to be somewise of her dear dear and gentle unto me, and to have her dear and gentle dear dear dear and love of me, and she to make a little upon her arms; and I to be a little to be in mine armour; and so to have no heed that she to be in that moment.\n",
      "\n",
      "And she to have no; and she to be so utter that her love; and I to have herher in that I be her with me; and she to have no more than her as that I had her power to have her dear love and all her; and she to refuse that she be in a moment. And truly, I to be that her; and I to be that I should be a little thing in her; and yet to be that I have her so that I did be like her in a while, and she to be her to mine eyes, and so to that I did be very. And she to be in mine arms; and she to be that she to be so dear and loving, and to make a little to tremble in me, as that I had come to her hand.\n",
      "\n",
      "And I lookt very quiet, and so to be a little while that she did carry my hand; yet, inher I to be that I should go forward again.\n",
      "\n",
      "And she to be very quiet and quiet, and so to make my spirit very tender; so that I have no power to be the thought of my body to her Maid; and yet, I made her a little to be; and I lookt very quiet, and to be the Diskos to her hand; and I to know that she did be a little while her; and I kist; and she did be very weak; and yet with her heart that she was not so that I should not be able to know her, that I did be in her own heart; for truly I knew that she did be in her naughtiness that, and so that I had come so to a dainty and dainty upon her; and so that we were very husht,  , all the Diskos, and to be a little of the heart that did be in a little time, as that I have no more of my strength. And she did be that I put her hand into the heart that she was so to her face; and she to have no. And surely she had her head to her feet very dainty; so that it was that her Own had been her to be in her heart with a dainty naughtiness upon her; and she to kiss me; and she to make me to me that her love; and to kiss her pretty very dainty, and very tender and dainty; and so I to have to her dear love that she did be all her; and she to be very quiet, and so to a very natural and dainty, so that she to be a little of my body, as that she did be very dainty; and truly, as I do mind; and the Maid did run her head into mine arms as that she did go very quiet unto mine. And she did seem to me that she had me a little while, that she was very, and did be her very little.\n",
      "\n",
      "And she then she to kiss me; and she to be the cloak off off from me, and I to be in mine hand. And I to go again again upon the Maid; and afterward I to have her, and to kiss her with the cloak, and she to be very dainty and loving. And she to have her to be in, and to be a little to be in the heart that she had no more of her dear love that I did be so that I have her to be for her dear and gentle unto her naughtiness, and so to her dear naughtinessthat as that she she to have her to love me; so that she did be a little thing that I was so glad, and she to be like that I have her love that she not; but yet to have her love; so that I did be so that I be so to have her to be in her dear heart; so that I did be very glad that she to be in a dear and love of love, and the dear and maid; and so to be a very wondrous tender. Yet, because that she was not to be so that she did be all in her face and dear and naughty to me; and she then to make her hand with me to my face; and so that I did be very dainty in the hollow; for the Maid to be in her heart; and so Ito have to be a dear and natural that which I have told her to be of her love. And, truly, I was not that I should have a power of her to have the heart that I did be so; and that I did not be so that I should be in mine heart for me in mine.\n",
      "\n",
      "And when that I was the Maid very strongand I lookt at the sixth while that she should be very quiet, so that I did be the broth, and she then then that I should have a little while, and the Maid to be her, and she; for, indeed, she did be so that she had her to be in her arms, and she to kiss her. And she to be kist me, and she to be her, and to be very quiet; and she to have her to be her dear dear and dear dear and dainty and gentle that her heart that her love and to have her love that she had her love and to love her; for she she to have no more.  I did be in mine arms. And she to make me very dear; but yet, as you, I said; and she had been very strong with me; yet she to be so utter as that she had gone from her to her breast; and truly, in a moment she to be in her, that, she to be very dainty unto her, that was her sweet naughtiness.\n",
      "\n",
      "And in the first moment she did be very dainty; and she to make that she kiss me; and she then to be in her dear face of mine armour, and the Maid to be in mine arms; and she to be very dear and tender; yet that I was so that I to be very glad to be in her own love; but that she to kiss my head to be in a strange fashion; and then to have no more more than I did; but she to be in a little moment; yet she to be in a little hand, so that I was not to be a natural thing, because that I should have a power to go from her feet, and did be like to have her  . And she did be in her instant to the raft; for she did be very quiet; and she made no more than I did be so that I did be in the first; and so to come a little while that she did be so utter and a little of the Humpt Man.\n",
      "\n",
      "And I lookt upon her; for she to be very quiet in her, and to make that she kist me, very very dainty; so that we to be in the same moment, as that she had come from her hands to me, and to make her to have her dear love; and I to have no more to her; for, in that moment, she to have her to be a sweet and loving and dainty, and that I be all that she did be in the heart that she did be in mine eyes that she did be so dainty.\n",
      "\n",
      "Now when that the Maid had been a little while, and to be the little while; and she to have her dear and gentle with her dear face that did be in my face, and so that I should be a small while a little while; yet that she to have been, and to have no more of her dear spirit of my spirit.\n",
      "\n",
      "And truly I to be very quiet; but yet, she to have no power in the matter, as I did say.\n",
      "\n",
      "And I, as I did be there in the moment that I to have no power to her to be for her; and she to have a little while that she did be so dear as that she should be a little while; for I to have her to love her pretty dear and her dear dear and dear, so that I kist the cloak; and so to have no more; for she did be very sweet and loving with a little that I kiss her. And I did be so; and that I to be kist her very gentle upon, and with mine arm as a child and her dear dear woman, and so dainty me, and to have no heed whether that, in her heart did make her to the heart, and she with her arms, and I to have no more, but yet did I be so well as that I should come to her hand; and I to have her to kiss me; and she to be that I be so to be; and to be that she to be very quiet and loving, and to be a very while to her; and I to kiss me very dainty; and the Maid to be a very dainty tender, and with her love that I did not to go; for she to be in mine own face; for she to be in a sweet while, because that she would be so dainty to be in mine armour, that she did be like to a child; and I to have her strength that she had her head; for, indeed, as I did say that she did be very dainty unto her, and that she did not be her. And I to be in her arms with her; and she to be in that moment, and she to kiss me with a dainty gladness that I did be her.\n",
      "\n",
      "And she to her Maid in her instant; and she to be that she had a little while that she did be very quiet unto me; and she to be so dainty as a love, that doth be all her and loving with a dainty upon her. And, indeed, I made her to be; so, in a moment that I should not to be a dear way.\n",
      "\n",
      "And she then to be very husht; and yet to be very dear; and so I to know, that she did not be so utter as that she had come upon her hand; and she had not her to kiss me; and she to be very dear and loving; and to be that I did be not in her heart, that I have been to come. And I made her that I be very weak and her dear, and I to kiss me, and the Maid to be so dainty as I did. And I to be very quiet in mine arms, and to make her love and loving and tender. And she to refuse me to me very dear, and that she to be her dear and naughty; and sothat I knew that she had her to love with her pretty pretty loving and gentle as that she be so that she had been her to be. \n",
      "And she did kiss me; and yet to be her in my heart; and she to kiss me, and she to be a little of my love, and the Maid to her lips very dainty; for the heart that I should be so that, in that moment, she made her head from my hands and loving into mine arms, and so did run upon my hand; but yet to be very quiet and loving; and so that I did mean that I have her thought; and she to be in a little, as that she had come to her head, because that they did be in a little moment, and to be very quiet and loving; yet to this way that we be in this matter and of a dear and dainty maid, as that she did be so strong and to have her naughtiness; but that she she had no more to be in that; but she had been not to be a little while that, she was very dainty, and with her a little; but that I did be so that I did be so that I should be in, and so to have a little thing that her heart was not in my heart.\n",
      "\n",
      "And surely, in a little while, I to go over the cloak of her, and did be so that she did be so that I have told her.\n",
      "\n",
      "And she went up into a place, and so that I did come to her hand; and she to be very quiet and tender in the heart; and so that she to be very dainty unto her; and she to kiss me with mine arms, and to be a little way off from the, dark to the heart. And she to be in that moment where she did be so utter; for I was not in her heart; for that she to have been a little to go off from me; but yet to be in mine, and so that I did be so that she to have her to kiss her with love; and she to be in a dear and dainty gladness of my heart, that I did be in mine, and so that I did think her she.\n",
      "\n",
      "And I made her to her head that; and she had her, and I to kiss her again, so that she had her belt-knife from her head against her against the rock, and she had no power to come to her. But I had not to be gone so far into the heart; and I to be very glad to have her pretty dear and loving for, as that she had been so weak as that I had been gone by her and loving her pretty dainty. But she did nestle to me as that her heart was very dainty; and that she to be a little while that she did be a little while. And she went very swift with a little cry, that was her very quiet and gentle, and she kist; and she very very quiet.\n",
      "\n",
      "But I did be a little way; for I was come upon her to the raft, and I lookt at her; so that I did be the more to her; so that I did be very glad of her dear dear love; and so, as she do, and she did be very dainty in my breast; but she to have no more to be in her own dear.\n",
      "\n",
      "And truly, she did go as she to be so dear and sweet and loving, and so to be, so  . \n",
      "And I to have her dear and gentle; and I to be that the Maid to go forward with a great while that I did make her to make her hand from her; and she to be that she to be very quiet. And she to be very dear, and I to be her to be in her with her dear heart that I to have a little while; and she to be very dainty, and she to be very quiet, as she had her love that she did be so dainty and so.\n",
      "\n",
      "Now I put her to her, so that I should her; and she kist her and gentle, and she to be a while and her belt-knife.\n",
      "\n",
      "And surely, when she was come so upon me as she did sleep, I came to my hand; and the Master Monstruwacan, very quiet; and I to be sure of her; and she to be very quiet and loving; and she to be a little very tender with her dainty; and to her face that I was very weak and loving and loving upon her.\n",
      "\n",
      "And I went up her to the Maid. And she to be a little while that she did be in mine arms, because she was very dainty; yet, in her, that I had her to, in her, and did be very quiet. But I made no more of her, as I did be. But she was a little, very weak, as that I did be so dainty as she did be; for the Humpt Men did be very weak and dainty, so that she had her thought to be a little of her dear maid; and she to be in her face of my heart, as that she did love, and she to be a little to the breast. But she then that she did be very quiet, that I should be so that I did not her; but yet to have no power of her strength unto her. And she to have no word with me; and the Maid to be very dainty; yet I to have that her naughtiness that did be her dear naughtiness. And I to be her dear and dear, and to her dear dear and gentle and loving that the woman and so utter and her, and that she to be a little of her face.\n",
      "\n",
      "And she then then to kiss me, as I have told, and I kist her, and she to be in the end, and the Maid did be her dear and loving; and she to   and her face very dainty and tender; and that it did be her dear pretty and a pretty way;and she was very quiet for her dear dear and loving and loving unto her, and she to be so dainty.\n",
      "\n",
      "Now presently, when she to be a little way off; and she to make a little, because that she did be so weak as I did think; for that she did be so utter her and gentle as that she did be so strong to be in a moment that I to be her pretty unto the heart, as that she might say her that I did be very dainty, and so that I to have no heed for she to be.\n",
      "\n",
      "And I to be the more of Mine Own Maid, as she to have no more than I, and that she did be so well as she with her heart.\n",
      "\n",
      "Then I saw her that her face of my hand upon the breast of mine armour, and did run very quick. And she then to make a little pace.\n",
      "\n",
      "And when we were gone again again, she had come into the Maid; for, truly, she had her thought that she had her head; but she to put her hand into mine armour and so to my heart to her, as I do think; for she to be very quiet and dainty and dainty with her dainty; and yet to be a dainty and gentle in that part.\n",
      "\n",
      "And when I had come to her hand, she did be in mine arms, that I should come very more upon her, and did be very strong and dainty; and so that I was not to be in mine arms; for, truly, in that moment I did come so that I had no power of her strength; for she was very strong in her heart; and she to kiss me; and she to kiss me; and she kist me, very very dainty, and so, to be so strong and gentle with her; and she to be in the end of the little moment.\n",
      "\n",
      "And I to be very quiet as I to have her dear and love, and with her sweet dear and gentle pretty and dainty, so that she did  ; so that I did be in mine heart with her sweet naughtiness, and to make her love and with me, so that I was, and to need that she be kist; and I to have that she to be gone from her unto the heart. And she to make her that moment very pretty unto me. And she then to have the little while that; but she to put her hand very quiet in my hands; and she to have her belt-knife very and tender upon her; but she did be that she had no heed of her naughtiness, as that I did be her; and she to have her pretty dear loving and dear; for I did be so utter as that she had no more of her strength.\n",
      "\n",
      "And surely, in a moment, I to be the more to the Maid, that she to make to her hand to her face, that she to be very dainty with me; yet that I should be very well in mine arms, and I to need that she be very dainty; but I to be that she had her in love; but she to have that I should be so utter as you to have been in the same.\n",
      "\n",
      "And\n",
      "she did be in her arms very quiet; but she then to make me to be gone, and she to be very husht and loving, and so to be in her face.\n",
      "\n",
      "But she to have been to her and gentle and dainty with my heart; and she to be very dainty, and I; and she to be that I be in a while that she did be in her dear love and dainty, and so that she did be so dainty. And she to have no more in her dear; and she did be that she did be a lovely. And as she did be so dear and dainty. And she to  and that I did be her pretty pretty very quick; for, in a moment, I to know. And when she had been a little way off that her head; but the Maid had no power of my strength, and she to be very glad that she be gone; and she to kiss me very dainty, and to be very quiet, as to her face.\n",
      "\n",
      "But I to her to be very quiet; for, indeed, she to have been her with all of love that, in her heart; and truly I to be so utter a little as she thought, because that she had no power for a little thing in my heart. And truly I was a little while that she did be her dear head unto my face, and so that I was so that she to be so that I was not a more to her own; and so to be that she did not so to have a dear knowledge of the maid.\n",
      "\n",
      "And she made me very quiet; and so to have been that she did be so dainty as a child; and she to kiss me very gentle and loving with a dainty as a child; that I to be in mine armour, and so to have her dear dear and dainty upon my heart; for I to kiss her, and to be very quiet; and she to be kist the cloak against me very dainty as that she did be her dear naughtiness and that be. And she to know that she was her to me; for I to be a little of my heart, that I should be so glad of her own love; and to be very glad. And I made a little while, she to be in her arms; and yet I to be very weak and dainty, and with a little while she to go upon the cloak; but she to be kist her in mine arms with a little while; but she to kiss her head very gentle, and I to have no heed of her. But she was not to say that her own body.\n",
      "\n",
      "And I went her to run from her head into a moment, that she put up her; and she to kiss me; and I kist her, and very quiet; but I to know that she did be her pretty loving and dainty; and I to be very glad; and she to have no word to me, as you shall think.\n",
      "\n",
      "And I then to have no more to the more and of her love; and she, as I did say, that I did be a little thing, and the Maid to have a little while that she be in the moment of a little moment.\n",
      "\n",
      "And she then in the Maid and then to be that I should be in the same moment, and that I did go forward upon my head. And I lookt very, so that I had come so that we should eat and drink, and to be a little place. And she then to be in a while, and made to be a little while that she did be in that she be so that I was to her in the moment that she did be her; and I to be very glad, and so to have been a little of her dear heart; for she did be so utter a little and dainty and dainty and gentle and dainty and so dainty.\n",
      "\n",
      "And presently, when she had been a little while, and afterward I had no power to be the raft; but she to be in that moment she to be very strong and loving; and so to be very dainty and tender with a little.\n",
      "\n",
      "And presently, she did come to her toes into her, and I took her into the heart that she should be kist her in the hollow; so yet as I have told.\n",
      "\n",
      "And presently I went forward again upon the mouth, and the Maid did go back again, and so that we did be so well that I. And she to be very strong upon her, and she to be so utter a dainty; and she to have her belt-knife and to be the little of the other man, and that she to be in mine arms.\n",
      "\n",
      "And when that we came come to her, because of the Humpt Humpt Men that I was her in mine arms; for she did be the more that I should be so well to have the Maid in her own head; for she to know what she did be in mine, and so did be her to her dear head.\n",
      "\n",
      "And I to kiss her very dainty; for her to be very tender and loving in a moment.\n",
      "\n",
      "And she to have the Maid that she be nigh; and she to have the cloak of her; so that I wasand and to be her to her hand with her; and she to have no more of her; but she to have her love with me; but that she was very dainty, as I have been that it had so been that I did be in her heart with me that she did be a woman, in the face of the Humpt Men, and so that I had her so gentle as her; and afterward I to be very husht, and with her dear head of the heart as that I had been in mine armour. And I to have been in a while the Maid and then that I had her to sleep; but she to have her head, and she to be that her love did be so daintythat as I do think; and she to be a little to be in a sweet and loving fashion.\n",
      "\n",
      "And so that we did be very strong, as I to have her to be the raft and upon her; for the while that she be in the hollow and with the cloak, and so that she did make a little to be upon the cloak.\n",
      "\n",
      "And she then to go with a little while, as that she did look very quiet and to her feet; but that I did come very more of the tablets; and the Maid to be the more of mine own heart; but I knew that her heart was very quiet in her own dear and loving pain, as that she had her head of the love. And she then she had to be a little while that herdid so  ; that she had her to be gone, so that she did be very dainty upon her. And she then to be very dainty, and I to kiss the cloak about me; for she did kiss me to me; but she to be so dear and dear and gentle loving upon me, because that she would be so weak; but yet I was so utter in her.\n",
      "\n",
      "And she took me very strong and gentle; so that I did be very quiet, and I to have been in a little, and she to be very quiet with her own. And she to have no heed to me from her; for I was not to her mind that I should have no more to know of this way that I should be able to eat and drink at her dear.\n",
      "\n",
      "And I went then then with her and tablet; for she had her thought that I should have no more to be able to know, and, to have no power to be seen unto her in her face.\n",
      "\n",
      "Now I was the more of her dear Maid, and  ; her she had her belt-knife, she to be very quiet with me, that she did be so strong and dainty. And, indeed, when I had come to her her shoulders, because that she had come her unto my feet.\n",
      "\n",
      "And she then to have no more for her; but she to be a little of mine arms, that I should have no more than my love of her pretty pretty that she to be her. And she then then; and she to have no more to her dear dear way, that I did be her to her dear face of her sweet dear and loving and gentle. And so that I was very gentle and to be. And she to have no heed in her dear; but she to be in her instant.\n",
      "\n",
      "Now she then, and she did be very quiet, and she to put her arms into a little, very little; for she had been to be a little while that she did be a dainty way off from her armour; and truly she to be very dainty in my heart.\n",
      "\n",
      "Then a little while, she made a little while; but she took her hands and belt-knife, so did seem very quiet and  ; but yet to be like to be a little man of her. But she to kiss her belt-knife, and to have her and gentle, as that I did be in her arms with me, so that she had so  ; for she did be; for she did be so dainty and dainty and dainty; and she to be very dainty; and she to be that she be very dear and tender to her; and she to be in the little way of mine; but yet to be so utter as that I did be; and she to have her dear head unto her, as that she did be very dainty.\n",
      "\n",
      "And she askt her utter love; and yet to be that she did be in the heart; but yet with a little, as that I might be in her own. And truly, she to be very quiet in the heart; for she to be very dainty with her naughty and that way of her, as you do mind to her naughtiness that I did be like to be in; yet, in verity, she to be very weak and with her dear love, and to be very dear in her own love.\n",
      "\n",
      "And the Maid did be very dainty and gentle; and so to have her to be in a moment, as she to be in that I should be so utter in the heart.\n",
      "\n",
      "And she to be very quiet; and, indeed, she was very quiet; and she very gentle and loving, very quiet, and so to be a while that she to have her strength. And she to be very quiet and dainty; and she to have no heed to her in her heart; for that I did be so well as that she had gone, and to know that she was her dear naughtiness. And when I had I to eat her more; and afterward I to be that her, she to have her dear dear pain; and truly, she was not so to her, as that I had come from her to her, because that she did be her pretty dear and dear.\n",
      "\n",
      "And she then to kiss; and yet to be a little thing; and she to have her to have her; so that I was so utter a little thing; but yet, as I did think her very dear and dainty with her love, and her head to be; for she, to her belt-knife to me. And so that I did not be in her heart, that I to think she had her to kiss me; and she to have the Maid in mine arms for my neck, and to make her to be a dear and dainty hug; and afterward that I to be kist her; and she to have no more than a little.\n",
      "\n",
      "Now she then that I had a little while; for she had come very little unto her feet; and I kist her, she very quiet and loving and so utter a dainty, as that she might be in a moment, and she to have no more than a little; but she to have a dear fear of her, because she to be very strong; and she to have a little while, as she did have so; and to be very quiet in her face; and so that I to have no more to be in a natural fashion, because that she did be so; and she to be in that time with her dear and love.\n",
      "\n",
      "And when I did be so that she did, and she to have a little while that I did go to sleep; and, indeed, she did be so utter and in her dear and dainty, and she to be that she did kiss her very dainty, and so very dainty; so that I did be all that she did be in her heart; and she to be, in that moment her heart of a sweet and gladness as her to love; so, and to be that she did be a little and tender; and that I be in her dear dear and gentle loving, and that she to be in a little moment; and I to be very quiet. And I to be kist, and she to have her dear dear and dear dear woman, and she to kiss her belt-knife to her belt-knife, so  ; so that she had been to be gone over her toes; but she to be very quiet; and she to be in a moment that I be in that she had her dear and loving; yet that I she did be very dainty and gentle unto her dear head and so dainty.\n",
      "\n",
      "And I then then to have her dear and loving upon me, and that she kist me with a quick hand, and did make her to kiss me; but I made her that she did be her dear dear, and I to kiss my head, very quiet. And when she was come very husht upon mine arms; for I did be so that she did be so utter a dainty; and she to kiss me very dainty, and she to kiss me to the breast that I had no more of her dear strength. And she to be that I kist my head, because that her was love and she had her thought that she was her. And she to kiss me; and she then to make a little and loving toes to the breast. And in a little, I to have no more than my way; and she to be very strong, and I to know that I should be very quiet and dainty.\n",
      "\n",
      "And I put the Diskos to my hand; for she did be very glad of her dear breast, and did make her her head, and she to have no more more than I have gone.\n",
      "\n",
      "And I to have a little while in my breast, and the little to be very husht, and to be a while to be gone in her. And surely I did be so that I was come from the raft and upon her hand, and she to be in a while; and she to be that she had come from her to me with her feet that, and that she was her to kiss, her very gentle and loving; and she to be her head with me; and sothat that she had her to be a little of her dear love; and she to kissherher and very very tender, and so that she be so that I did be all her.\n",
      "\n",
      "And presently, I saw that she was her belt-knife from my head of the cloak; so that it was so that her heart was a dainty; and I made her to go; and she very very husht, and to kiss her and very little to be; and afterward I lookt up at me.\n",
      "\n",
      "And I was not a little to go back; and yet did run a little while; and she then to have gone very dainty into a little, so that, in that I have been a little way, that she was come from her hand; but she to have been in a little while that she should be in mine arms, and she to have a little way upon her; for the Humpt Men had no more of her dear head; and the Maid to have her head very quiet for a little, and that I should have no more of the body of her heart, and so to be so.\n",
      "\n",
      "And I to be a little while; for I was not so that I did think her; for I had been gone by her feet from her, and she to be in a moment that, in her instant; and she to be in her dear head that, and to be the Diskos in her; and so to be that she to be in the heart.\n",
      "\n",
      "And I saw that she was not a little while that she had gone from her head to her face for a little, as I did know that she did be so dainty as a child; and she to know that she had come unto her; and she to be so that she to be very quiet; for that she to be in a little moment, and that she put the head of the Humpt Man; so that I put her head into mine arms, and she had her to be in her face, that I did be so utter a; but yet to be in the same fashion that in my heart.\n",
      "\n",
      "And I to be very husht, because of the little while that I did carry my hand for her. And I kist her that the Maid did be very dainty; and she to be that I should kiss her pretty pretty to be upon the raft, and her to look upon me against her shoulders, and that I should be so that she be kist and she to her feet; and so to be a great and kiss me; and I to be in a little while, because that she would be so to have a little man, as that she did be very dainty upon her with her arms that she did be so dainty as that I did be in her dear dear and natural.\n",
      "\n",
      "And the Maid then to go back from her. And when she did be a little while that, she had been so weak and loving, as I have her. And she to have no power in her dear; yet she to be that she did love that she was her; and she to be very dear, and she did be her dainty and dainty unto me; so that, I had not to be so that she might not have been so that she did not be so dear and natural that her love that did her spirit to her naughtiness.\n",
      "\n",
      "And she did be her utter gentle from me, that she kist me, and I to have a broth upon mine; and she to be that I was her, and that she had no heed to her, as that she did be her, because that her thing did be all the maid, as she did be in; but yet to her naughtiness that she be her pretty dear dear and love for her; and she then that she be so weak and dainty; and she to know, that she to have been gone upon her; for I to have no knowing that she did be so weak as that, when the Maid had her so  , as she did think; and so a little while she to be gone, and I to be very husht and to be a dear maid and her dear, and that her maid did be so that she had her to have her her face with her dear head, and she did run; and she then   and mine arms against mine arms and gentle, and that she to be very dainty. And she to kiss me, very sweet and tender with the little that she had her head of her pretty garments that she had her so sweet as she.\n",
      "\n",
      "And she to be then, and she to have no more to the more of her. And, truly, I to be that she did be so that I did be.\n",
      "\n",
      "And presently, I to be very husht, as that she had been gone into her, as you do perceive. And she then that she had her, and she to kiss her; and she then kist me; and the Maid did be very dainty, and so to have her dear dear dear and loving unto her, and so to have her dear gentle, and that I be all her; and she to be very dainty.\n",
      "\n",
      "And when that I was come to her, I to be that I should have her to eat and drink in the heart.\n",
      "\n",
      "And I went forward that she did run, and so to my face with me, and I to have a while that she had come so to her dear and dainty.\n",
      "\n",
      "And she askt her that I did go upon her feet very gentle and so; and I to go very quiet; but she to be so utter, so that Idid surely she had been gone to her, she had been a little way, but that she had not so  ; that she had no power to have been gone.\n",
      "\n",
      "And lo! in a moment I to go forward that she did be in mine armour, and I to make that she kist her; for her to seem that she did not her so dainty;from but yet to be so dear and a little thing.\n",
      "\n",
      "And the Maid to have her belt-knife from her face of the trees. And I made the little Humpt Men, and she to refuse her to be so utter as that she had no more of Mine Own; and so to have her naughtiness, as that she did be so that I should not have to have been; and to have her fear that her naughtiness.\n",
      "\n",
      "And she then to have her dear strength, as she to be her pretty very dainty; so that I did mean that she be not in her love, and to be very strong and her in the heart that she had her and to be so utter. And she then to be very dear and loving, as that I had her so gentle, as that I did be a little; and she to have kist her dear and gentle very gentle; for her, sheto her head to be very dainty; and she had to be that she put off her head to the pillow; and, in the moment she to have gone her to her; for she was to her dear, that she be not to my spirit, that she did know that she did be in her dear love and dear unto her spirit; and yet, as I have said, I to know her to have her dear way that she to have her naughtiness; and to kiss me with her dear naughtiness and all pretty; and, in verity, she to be very quiet as she did be so utter as a little man of her love; and yet to have her naughtiness that she to know that she be all that she to know in her dear, and she to be very quiet and, because that she had so  ; her she to be in the end of her hand. And she took the Maid; but she to make her belt-knife with her face, and to kiss me, and she to be so dainty and dainty with the heart.\n",
      "\n",
      "And I to be kist her, and kist her very gentle with mine arms, as that I did lie in mine arms as she to be gone. I had no more, because that she did be in her dear heart. And the Maid to be very dainty; and yet with her to love, and with her sweet naughtiness; and to be her pretty dear and dainty; and she to refuse me to be a sweet and dainty and dainty, as that she did be all her pretty pretty and a little upon her; for she did be very dainty and tender, and with her love, and to her, and she to be that I have her to be so dainty; but yet to have her dear naughtiness; for I did be so glad, that I did be like a little thing with me; for she did be very dainty.\n",
      "\n",
      "And when that she had come so to be that she had come to the other side; and she to put the cloak, very sudden, and so that she did be a dainty and joyous in my arms and a little while, and she to be very husht, because that I to be.\n",
      "\n",
      "And I came the Maid into her; and she then to kiss me, and so that she had her belt-knife to her garments, and to her dear face with her head and loving and loving as that she had come her head of a little and tender; and she to kiss me, very sudden and dainty; so that, as her love, she was very tender and loving; so that she had come her to the Maid. And, truly, I did not so well as she to think that; but she to be so that I should be; for she to be so well as I did be in her love; for I to have her so that. And, in verity, I to be a more and tender to be; and so I to be very glad to have her to have her pretty pretty dear and her; and she then that she kist me very little with my hands and gentle to the Maid, and I to be very dear in her own love, that she to be very weak and tender with her dainty, so that she had her love that she did be a dainty and dainty.\n",
      "\n",
      "And surely, as I do think, for she to be so weak as that I have been so thatIshe to be very content; for truly there was no little to be; and I lookt, and I to be the Maid that she did be in a little moment, so that I did be in her dear and love, and that I did be so that she had her to love her with me, and to make her a little while that she did make me to her, and I to be very quiet and dainty; but yet to be very dear in her dear dear heart, and to be so utter a little of the little that of her.\n",
      "\n",
      "And she to kiss me with mine arms as her as, and she to make me very dainty; and she to be very dear and dainty; and she to have no more of me; and she then to be a dainty and loving of that she kiss. And so to be very dear unto my heart; for the Maid to be very quiet; for she did be so utter; and I to be in that moment where she did be her, and so that we did be a little while that she did be in her; and she to be very husht, that she to be so utter to be so. And I to be very quiet; for, indeed, I did be so glad as I do. And she to be in a little pace, and did be so utter a little and dainty upon her head; and so that she to be very quiet and tender; but that we put her back upon her head of a little,little that she did be in a moment that I did go to be in that she be, and she to be so utter in a little and dainty to beher that I be all that she had her to kiss me. And she did be a little thing; for she did be so that I should have no heed to her, and she to be very weak and with a little thing; for that she was her in mine arms, and so to my mind, and that she had no power. And she to be like that I have gone of a dear and loving gladness of my spirit with her naughtiness; and yet she to have no more than a man that I should come her to her feet, and she did be very strong and loving with her; but I to be very glad that she did be so dainty; but I to have no heed to be so that I should have, but not to know how that she did be so utter a little.\n",
      "\n",
      "Now, in that moment I was to have no knowledge of the Maid that did be in a moment, and to have a little to be gone from me, because that she had not so   , to her heart.\n",
      "\n",
      "And I to be the little way of her hand, and she to kiss, and she to be in a little pace that her face did be very dainty, so that I did be her dear and gentle and loving; and surely the Maid very gentle and dainty; but to be a little to be in mine arms as she.\n",
      "\n",
      "And when, she made a little, that I did be so that she did go in her hand, and she had no more to my feet, and so that she had been a little, and that I should come upon her very gentle, because that I did have her love for her; so she that I did mind her that she did love with her dear naughtiness with me that she did nestle so unto me; so that I was not so to have been her; and she to be that she be very dear and loving and dainty unto me, so that she was so that I did be like to be her, and to be in a sweet and gladness as that I did love to make her to me that she did be so strong and dainty in the heart, and so that she had not her to know, and to be so that she to be in a little moment that she did be so dear in me. And truly, she to be very dainty; and she, and that I did be her to kiss her dear dear and loving unto the pillow; for the Maid did be so strong in mine arms; for I to be that she be not so to have her; but yet to be so that she should, and she to be like a little man of her dear dear, as you to know, so that I did be very quiet and natural for her.\n",
      "\n",
      "And she to go back, and I kist her, that she did be her pretty loving; and yet I did be so utter a while.\n",
      "\n",
      "Yet, presently, I did be in a moment, and to the Maid to be a little of the Humpt Men; and yet I to be in her arms, and to be so that I might have to have her to be in her. And she then to kiss me very gentle and tender with me, and I to be that I to be in her dear dear, and to kiss me that she kist me; and she to be in mine arms and loving against me, so that I did be so wondrous as that she had been her so dear, because that she had no more of the more of the Humpt Men that did be very dainty; for I to have no more of the more that of my heart in her instant.\n",
      "\n",
      "And she to be in a while, and to be very glad that she to be a little to be her with me; but that she did be so utter and to my heart; and she to be very quiet; for, indeed, she to be very dear in her own; and she to be in that moment and a little while that she had been in my hands as a little thing, that she did be a little while, and did be very dainty and loving; and she to have her to be in a little of love, and to have a little of her; yet did I to have a little time that she be her, and did be very glad and all her; so that it did be a little time. But she did be a little way that of her face; and she to be in the little time.\n",
      "\n",
      "And she took her belt-knife into mine arms; for when I came to her feet very dainty, and lookt very close and at her; and she then to beher as she came forward very little, as I did sleep; and so that she did be very weak, and so to be that she did be in a moment; and afterward I to be in mine arms, and so that we be gone so upon my sleep. But I lookt to her, and I lookt very quiet upon her; and I to have her dear gentle very dainty, and so that she had no heed to be all that I had her to have been a little to be of her dear love; and she to be so utter and in mine arms; and yet with her dear sweet dear and tender as I. And she to be very husht unto my feet, and I lookt to her; and she did kiss her very dainty; and she to put her belt-knife to her head; and so she to be that her head did be so utter a little and loving upon her, as that she did be a little way with her, because that I was her; and I to have her dear pretty and dainty, so that I had not her to her, so that she did be so that I might be in mine heart.\n",
      "\n",
      "And in the end of the Maid came back to me; but truly I did be very strong to be her; for I was to have her to be in that I; and she to have to have been gone with a dear way.\n",
      "\n",
      "And I made the Maid to go downward upon mine arms; for I had not to be the broth of her dear and gentle to have the Maid very dainty upon mine; and she to be very quiet, as as I have told; and I to have no knowing whether this thing that should be come upon her feet and loving unto her breast with her. Yet she did be that I did be in her; and she to be kist me very quiet as that I did be in mine armour. And her in the moment that I was her to the Maid, because she was very sweet and loving, as she did her head in mine arms with me, and she had her torn back from me; and she did not be very tender upon her with me; and I did be very glad, that she had been in a little moment; for she had been a little while to her feet, very quiet, and so to have a great and a little cry; for the Maid had to her feet; and I lookt her about her feet and her; and I to kiss her belt-knife, and kist mine and knees against her, and did be very dainty and dainty, because that she was so dainty as I to know that she did be her dear love and loving unto my heart; and she to be so dainty; yet I to be very glad to  ; and she not to have a little while the broth; but she to kiss me, and to be very quiet in the little, because that she had so  .\n",
      "\n",
      "And I lookt at the little; and afterward I to be in the little hour, and did be come very sudden, she to be in a little, as I did be very dainty in her, and that she to kiss me again, and so I to have her so dear as a love; and so to have a little to be a sweet and gladness, and that was all the more of the trees; and surely she did have no more of her dear; but yet to have her; and she to be very dainty, as I did be that I be so shaken as I might have her; so she to have no power to her own body; and so to have been a little while; and I to be very quiet in mine, and so utter as that she did be.\n",
      "\n",
      "And I came her to her feet, and to her belt-knife, and to make her belt-knife to her shoulders of the little mouth ofthatthe And she did run up her head into mine arms, and I to have to be in her dear and love, so that I had her and her hands to her face that she had no love; so that she did be so utter as I did go. \n",
      "And I put her head very gentle with the ointment; and so to have that, she to have her head of the broth, because she did not be so that, and the Maid to be very strong in her heart; and yet to be all my heart with a little while.\n",
      "\n",
      "And she then that the Maid had no more than that she. And she did be very; and I to be a little in my heart, as a little thing.\n",
      "\n",
      "And presently I to know that she was her to me with mine; and so that I was not in her own dear and dainty; for I was that her voice did be very quiet; and she to have no more in her heart, and she to have her belt-knife very dainty. And so as I have told that she to be in her own, as that she had not been so to be so dainty. And I made that I have no power of her strength for her; but,to she to be very dainty; and the little to my heart was so that I was not a man to be in the same.\n",
      "\n",
      "And surely, I to go very weak and so; but that I should be so well as it might have, and the Maid to come out of mine armour, and so to be so that I should have no knowledge that I be. And she to have been a while, and to have her to go,  , with a little maid, that I did be in a moment.\n",
      "\n",
      "And she came back into the rock, and she to be very weak, and with her face and a dainty upon her head; and she put the head very dainty; so that I to be gone; for she had not been a little while that she had been her in her heart; and she was very strong and loving; but yet I was very strong in her dear dear, and to kiss me; so that I should be very weak for my love. And the Maid to be her dear, because her her dear love.\n",
      "\n",
      "And when I was gone over her, and so  ; her that she should be so utter a sweet and dainty dainty dainty; and that she kiss me; and she to be in a dear, and a little way that I did go in her; for she to have her dear hands and her head very loving, and so to her utter gentle and dainty, and I to be that I did carry her, and to be her dear and dear naughty and loving dainty and dainty, so that she did be so utter and in a moment; for she to be so that she should be a little thing that she did be like to be a little thing; and she to make that she be in her a moment; and she to be that she to be very dainty. And she to be kist her with me in mine arms, that was so dainty and loving; and that she to know me to be a dainty while, because that she had been so dear, and she did be her utter dear and dear dear and love her, and she to kiss me that she put her hand to her, so that I did her to be kist her; and she to kiss her, and to be that I have her to have a love for her with a dainty humbleness and her; for that her heart did be so dear, and she to have a little of her heart. And she did be that she to have her belt-knife, and she to make her very dainty.\n",
      "\n",
      "And I took her hands from her, and to her belt-knife very that her hair; and I was a little to her lips; for she was very quiet; and she very  , all the while and her hands of my heart and mine. And she did be so dainty and dainty upon my heart; and truly I to have been so much, that she did be in mine arms to her face; and I to be that she to be in a little moment, and she to be so dainty and a dainty and tender fashion.\n",
      "\n",
      "And so I kist her very quiet, and to have no fear; but she to have no more more than that I should;comebut indeed, I to have the Maid, because that she did be in the same moment, and the Maid to be in a moment, and so to have her to make a love and to me.\n",
      "\n",
      "And surely, I made a little to be of the Humpt Men, and that she put her hand into mine arms, because that the Maid did be so utter, as that you did know that I had no power to come through her from her garments.\n",
      "And so that I went forward to the Maid; and I lookt to her hand and her, and did be a little and gentle and dainty upon me; and she to have no more in her pretty loving; for she to be a little way, as that she did be a little way off upon her. And she she to be that I have her with a little while; and Iher I did be so that I was so utter a dainty while of her, that she had her and a little to her hand; and so that I had her so gentle and loving and loving and gentle upon her face; and so that she did be so utter; and she to know her how that she was; and I to think that I have a little way that she had her thought of a little thing; so that I had no; for I was come to the Maid that I did be so that I should be very weak, and I to have her dear and gentle and loving and pretty dear; and she to have her dear dear dear dear dear and gentle dainty, so that, and to her utter dainty and gentle. And so that I had her to the raft, and the Maid to be utter very dainty and so; so that I was her in a little and dainty upon her hand; and she to be very quiet; yet she to be very weak and tender; so that she had been so utter a little.\n",
      "\n",
      "And she made a little while that I did be very husht; yet I did be that she had come upon her, and she to be very dainty, and I to think that she had no love to be, and made her to be a little thing; and she to be like to her with me a little thing that I did be her in my, and with her dainty, that she very quiet; and she to be very dainty. But she did seem to have her to be a little unto her; and she to kiss her; so that she did have her dear love, and she to be a dainty and loving upon my head.\n",
      "\n",
      "And she to be in a moment, as I to have her her dear; and yet, I did be so weak and to the more of her spirit; but she to have her to be in mine arms, and, indeed, she to be in her arms and loving and gentle and dainty; but so very sweet and dainty and loving unto me that she be so dainty unto her with a dainty naughtiness of that dear.\n",
      "\n",
      "And truly, as I to be, and I to be the more of my heart, as that I might have no. And, indeed, I to be, the Maid to have no power to be her to her feet, so that I did be so utter as that I had come so to her naughtiness; and she lookt to be at her.\n",
      "\n",
      "And she then to make her belt-knife very and loving upon the Maid, that she did kiss me; and she to be her, as I came her to the breast of a little hug.\n",
      "\n",
      "And surely she was very gentle, and so to be; so, indeed, she was so that I was all the way of her; and she to make her a little while that did be her.\n",
      "\n",
      "And I made a little to the Maid for her dear dear and loving and dainty; and so that I was very quiet and gentle; yet, indeed, I knew that I was come in her; and I to have her head in mine arms as a little man, and then to have the Diskos very dainty upon my breast; and I to be that of my hand in the heart.\n",
      "\n",
      "And surely I did be in mine armour; and she to make that she be in mine arms; yet, as she had been,\n",
      " , I to be like that I did be so glad to my mind.\n",
      "\n",
      "And I made that the Maid to be her; for I was her to my back, and the Diskos and so that she did go down from my hands to my hand, as I did think it; for that I was come to the Maid that she did be very strong; yet that she be in a little moment; but she did be that she be not in her dear heart.\n",
      "\n",
      "And she then that she did be a sudden and loving into my breast for a little moment, as she did be, I perceived that her Own did be so utter in her arms, and did be so that I did be in her.\n",
      "\n",
      "Now, indeed, I was come very quiet and loving; for I to be very sure and her; and I kist her, and very very tender in the; and so to be very husht and dainty;and so, in a moment, she to be in her own love with me.\n",
      "\n",
      "And she to be very quiet, and she to put my head against her, and I to be that she did be so weak; and I knew that the thing did be so that I should be in the first, and so that I did not be stirred by my love; and she to be a little while in mine armour.\n",
      "\n",
      "And she then to be the Maid very gentle and; and afterward she to be very little, so I do not to be in the moment; and she did be that I did be so that I should be in her; and I to kiss herand she took her head, and very gentle. And she to have her head very dainty;and she to be very quiet and gentle with the dainty humbleness of the heart, and the cloak and so that I should be very sure; yet that I was come very glad that she had her; but yet to be so weak as I did know; but I not to be a little while, as that she did be so utter to her.\n",
      "\n",
      "And when I was gone very quiet from her, and I to be that she to have her head in her face, and to her head that she be in a little dainty; but that I to be so that I did go upon mine arms and that her love, and she to have her dear and gentle, and so that she did be in her arms as I  .\n",
      "\n",
      "And she then then to have her head from her pretty head; and she to refuse to make her belt-knife, as I did. And I saw that she had her, and she to her lips very gentle as that she did be very quiet; for her dear head that she did be so dainty in a dainty and dainty dainty; and so that her heart did be so dainty as I. And she came to her hand from her; for I to kiss me; and she to be that her heart with me for a little while that she had her torn to me in a moment.\n",
      "\n",
      "And she then to know how that I was in the heart, and she to have her belt-knife that I put her into her arms, and to be her, and to be a very tender; yet, in verity, she to have her dear and gentle pretty loving, and so to have her to her head that she to be that I should have no more; but that I have her so that I should think that I had been gone upon my hand, and she to have a little while, and she did be very strong in a moment, as that I did be in her heart and gentle with her; for, indeed, that I should have not so much as I did think, and so that she did be a little while that her body; and she then to kiss me very gentle. And she did not be a more of her feet, that she had her head to her face; and she to be a very dainty and joyous upon the lips, and to have a little while, so that I should not, for the Humpt Men be in her and love, and to have her belt-knife and she be in mine arms.\n",
      "\n",
      "And she came very husht and tender; and, indeed, I did go up her into mine arms; and so that I had come to my right to the Maid, and so that I did be in a little while, and she to make a little while that she should be in that a little man; and yet to make her dear dear and love.\n",
      "\n",
      "And surely, as I did go, and she to make her to me, because that she did mean so to have a little time as she to have her to love that she did be so dainty and dainty, as she to have  . And I to be so that I was.\n",
      "\n",
      "And I to be very glad that her be very dear and loving; so that I was so glad to be that, and she to be so that I should have no need of her naughtiness for her.\n",
      "\n",
      "But in this moment, I did be very strong, and I did be a while that she did be so that she to be a little and dainty; and so that it was her, as she did be; for I to be a little while that she did be a little while, because thatshe she to be in mine; so that it did be that she had her to love her. And I kist the Maid that she put her hair, and did seem to be a dainty, and made to that she had no heed to be all. And that she to have no heed of her; but, indeed, she to know how that I had not come from her, and she to be in a moment; so that she had no heed to the more of her dear; and she to be her, in her arms with a little loving that did go very dainty, as I to be that I should be in her; and she to be in her heart, and she to be in that time and she to be. But I to be that I should be like, for that we did be so utter in her arms as that I had her. And she to be very husht unto her and gentle; and so that I did be her to be in her dear love with me; and she to have that she to be in her.\n",
      "\n",
      "And I to be very husht, and to kiss me; and she to be very dainty, andof and to be her dear dear.\n",
      "\n",
      "And she to be very husht, and to have a while to be her to be in mine arms; and she to be in a little while, and to have her to be a dainty and dainty.\n",
      "\n",
      "And she to be that she to be in mine armour; and to have no need to have her. And so that we did come to her hand, and the Humpt Man in her; and she to kiss that, she very weak and tender with the little of her; and so that she she to be her pretty very dainty, and she to have her dear head that she be all that she did be her; and, in verity, as you do think. And I to think that she be gone unto me; but I not to be so that she did be like a dainty of the man.\n",
      "\n",
      "And truly she was a very little way. But she then to make me to go back, and she to kiss me; and she to be in mine arms, as she did sleep; and she to have her belt-knife to me, because that she did be so that she had so  . And her to have a love of her dear heart.\n",
      "\n",
      "And she to kiss her, and to run her head into mine arms and mine arms; and I to be very husht and tender to me; yet that I had no more of the Maid. But she had no little to be the while that she did be so dainty and dainty, and so that she did. And she came to me that she did kiss me very quiet and loving into my breast, and she to have gone so that she to be in a moment.\n",
      "\n",
      "And she to be very strong, and so to be so that she did not be so utter to be in mine armour.\n",
      "\n",
      "But she to be very husht and gentle with the dainty and dainty; and she to be that she did be in me that she to be kist, and she to make a little of the cloak; for her hair to be very weak; and truly I to have no more of her love. And I to be that she be very little; and yet to be in her heart.\n",
      "\n",
      "And presently, I to be in her heart, and to be that she did be in a dear, that she did be so dainty. And when that she had been a little while to be in the hollow; and she to refuse me to be very dainty; yet as I to have no heed of her; but she to know that I did be so utter as I did, and I kist her again with the cloak and her pretty pretty. And I did be very quiet; so that, as she did be, I to have no power of her dear love, and that I did have a little while; for, indeed, I to have a little while, as that she might have her love to be all in her; so that she to be in her heart as that she, and to kiss me, as that her heart did not her love, because that I was so weak; and that she be her in all her, and with me that she did be in her heart; and so that she did be.\n",
      "\n",
      "And she then that I to be very dear and dainty; for she to be that I have her in a sweet and dainty as that did be in her own and love of me; for I did think that she was so to have a little while that she be gone to the right way; and she to be very dear, as she did be all the more of the heart; and her to be in her arms, and she then to be a little of my heart; for that she to have a new joy in the heart. And I did be that her head to be very dainty unto the Maid, as that she had her belt-knife in her heart that she to be in a moment, and she kist her, that I kiss the cloak; but I did kiss her; and she to be her belt-knife, because that she was her. And I came her with the little garments where she did be so that I did be, so that she did be so utter in my love and loving and gentle that she to be all her, and to be in the heart that she did be in a moment as\n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"The thing that should not be\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words\n",
      "Tensor(\"rnn/transpose_1:0\", shape=(1, 1, 1024), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mwords_i17775_l1024.ckpt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LURKS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fc1aade675c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"THE THING THAT LURKS IN GUATEMALA CITY\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-2fa44254ff95>\u001b[0m in \u001b[0;36msample\u001b[0;34m(checkpoint, n_samples, lstm_size, vocab_size, prime, mode)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             feed = {model.inputs: x,\n\u001b[1;32m     13\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LURKS'"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"THE THING THAT LURKS IN GUATEMALA CITY\\n\\n\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"THE NIGHTMARE IN GUATEMALA CITY\\n\\n\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"ONCE UPON A CREEPY NIGHT\\n\\nAll saints eve magic was mysterious\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"I have never been so afraid in my life. The trembling of the legs is uncontrollable. I do not think I survive tonight...\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"THE THING THAT SHOULD NOT BE\\n\\n\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sample(checkpoint, 50000, lstm_size, len(vocab), prime=\"the creature of the night\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
