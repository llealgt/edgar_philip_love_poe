{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks for H.P Lovecraft text generation\n",
    "\n",
    "\"The color out of space\" is one of my favorite tales from Lovecraft, i will use it(as well as others as the call of cthulhu) to create a recurrent neural network in tensorflow that learns his style and generates new text in his style\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn) and an example from \"Deep Learning Nanodegree\" on udacity. Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. \n",
    "\n",
    "## General architecture using \"Long short term memory\" units in the recurrent layers\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime ,localtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run only the  first time nltk is used to download language\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define conf variables and hyper parameteters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = \"characters\" #characters or words\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128       # Sequences per batch\n",
    "num_steps = 75         # Number of sequence steps per batch\n",
    "lstm_size = 768         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.001  # Learning rate\n",
    "keep_prob = 1       # Dropout keep probability\n",
    "\n",
    "resume_from_checkpoint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base text\n",
    "Once trained ,the network can take base text and a sequence size and generate new text using base text as first characters in the sequence. For every element in base text wi will create a list that will store generated text as training goes, to be able to compare results between steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_to_try = [\"In the first place\",\"the night before\",\"horror\",\"creature\",\"night\",\"dream\",\"thing\",\"That night\",\"mountain\",\"Ammi\",\"Cthulhu\",\"raven\",\"bird\",\"nevermore\",\"dead\",\"The bird\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that separates text into tokens(for whitespace characters, only new line is implemented, missing tabs and others="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'u',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'e',\n",
       " 'a',\n",
       " 'l',\n",
       " '!',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'F',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'G',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'l',\n",
       " 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_by_words(text):\n",
    "    text = text.replace(\"\\n\",\" new_line_token \")\n",
    "    tokens = []\n",
    "    splitted =[[word_tokenize(w),' ']for w in text.split()]\n",
    "    splitted = list(itertools.chain(*list(itertools.chain(*splitted))))\n",
    "    \n",
    "    token_list = []\n",
    "    i = 0\n",
    "    while i < len(splitted):\n",
    "        if splitted[i] == \"new_line_token\":\n",
    "            if   token_list[-1]==\" \":\n",
    "                token_list[-1] = splitted[i]\n",
    "            else:\n",
    "                token_list.append(splitted[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            token_list.append(splitted[i])\n",
    "        i+=1\n",
    "    \n",
    "    return token_list\n",
    "\n",
    "def tokenize_by_characters(text):\n",
    "    return list(text)\n",
    "\n",
    "def tokenize_text(text,mode=\"characters\"):\n",
    "    if mode == \"characters\":\n",
    "        return tokenize_by_characters(text)\n",
    "    elif mode == \"words\":\n",
    "        return tokenize_by_words(text)\n",
    "    \n",
    "tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",mode)\n",
    "#tokenize_text(\"Hello, my name is Luis Leal!\\n\\nFrom Guatemala\",\"words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(tokenize_text(text,mode))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a little portion of text for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_text = tokenize_text(text,mode)\n",
    "encoded_dataset = np.array([vocab_to_int[c] for c in tokenized_text if c in vocab_to_int], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_size = batch_size * num_steps #create a single baty\n",
    "validation_start_index = len(encoded_dataset) - validation_size\n",
    "\n",
    "encoded = encoded_dataset[:validation_start_index]\n",
    "encoded_val = encoded_dataset[validation_start_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of \n"
     ]
    }
   ],
   "source": [
    "def encoded_to_text(encoded):\n",
    "    return \"\".join([int_to_vocab[number] for number in encoded])\n",
    "\n",
    "print(encoded_to_text(encoded_val[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_text =encoded_to_text(encoded_val)\n",
    "text = encoded_to_text(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first 100 characters of train and validation, make sure everything is peachy.  line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE COLOUR OUT OF SPACE\\n\\nWest of Arkham the hills rise wild, and there are valleys with deep woods t'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r genera of creatures are germinated) -- the spontaneous germination, I say, of five vast hordes of '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the characters encoded as integersin both train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98,  22,  91,  48,  36,   0,  15,   0,  62,  96,  48,   0,  62,\n",
       "        98,  48,   0,  88,  48,  84,   6,  41,  36,  91,   5,   5,  90,\n",
       "        55,  28,  54,  48,  38,  29,  48,  41,   3,  42,  58,  40,  45,\n",
       "        48,  54,  58,  55,  48,  58,  12,  65,  65,  28,  48,   3,  12,\n",
       "        28,  55,  48, 100,  12,  65,  19,  49,  48,  40,  93,  19,  48,\n",
       "        54,  58,  55,   3,  55,  48,  40,   3,  55,  48,  26,  40,  65,\n",
       "        65,  55,  20,  28,  48, 100,  12,  54,  58,  48,  19,  55,  55,\n",
       "        99,  48, 100,  38,  38,  19,  28,  48,  54], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,  48,  21,  55,  93,  55,   3,  40,  48,  38,  29,  48,  13,\n",
       "         3,  55,  40,  54,  81,   3,  55,  28,  48,  40,   3,  55,  48,\n",
       "        21,  55,   3,  45,  12,  93,  40,  54,  55,  19,  47,  48,  87,\n",
       "        87,  48,  54,  58,  55,  48,  28,  99,  38,  93,  54,  40,  93,\n",
       "        55,  38,  81,  28,  48,  21,  55,   3,  45,  12,  93,  40,  54,\n",
       "        12,  38,  93,  49,  48, 101,  48,  28,  40,  20,  49,  48,  38,\n",
       "        29,  48,  29,  12,  26,  55,  48,  26,  40,  28,  54,  48,  58,\n",
       "        38,   3,  19,  55,  28,  48,  38,  29,  48], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is working with individual english tokens, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training mini-batches\n",
    "\n",
    "Here is where we'll make our mini-batches for training. Remember that we want our batches to be multiple sequences of some desired number of sequence steps. Considering a simple example, our batches would look like this:\n",
    "\n",
    "<img src=\"assets/sequence_batching@1x.png\" width=500px>\n",
    "\n",
    "\n",
    "<br>\n",
    "We have our text encoded as integers as one long array in `encoded`. Let's create a function that will give us an iterator for our batches. I like using [generator functions](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/) to do this. Then we can pass `encoded` into this function and get our batch generator.\n",
    "\n",
    "The first thing we need to do is discard some of the text so we only have completely full batches. Each batch contains $N \\times M$ characters, where $N$ is the batch size (the number of sequences) and $M$ is the number of steps. Then, to get the number of batches we can make from some array `arr`, you divide the length of `arr` by the batch size. Once you know the number of batches and the batch size, you can get the total number of characters to keep.\n",
    "\n",
    "After that, we need to split `arr` into $N$ sequences. You can do this using `arr.reshape(size)` where `size` is a tuple containing the dimensions sizes of the reshaped array. We know we want $N$ sequences (`n_seqs` below), let's make that the size of the first dimension. For the second dimension, you can use `-1` as a placeholder in the size, it'll fill up the array with the appropriate data for you. After this, you should have an array that is $N \\times (M * K)$ where $K$ is the number of batches.\n",
    "\n",
    "Now that we have this array, we can iterate through it to get our batches. The idea is each batch is a $N \\times M$ window on the array. For each subsequent batch, the window moves over by `n_steps`. We also want to create both the input and target arrays. Remember that the targets are the inputs shifted over one character. You'll usually see the first input character used as the last target character, so something like this:\n",
    "```python\n",
    "y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "```\n",
    "where `x` is the input batch and `y` is the target batch.\n",
    "\n",
    "The way I like to do this window is use `range` to take steps of size `n_steps` from $0$ to `arr.shape[1]`, the total number of steps in each sequence. That way, the integers you get from `range` always point to the start of a batch, and each window is `n_steps` wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps \n",
    "    n_batches =  len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr =  arr[:n_batches*batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs,-1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros(x.shape)\n",
    "        y[:,:-1],y[:,-1] = x[:,1:] ,x[:,0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[ 98  22  91  48  36   0  15   0  62  96]\n",
      " [ 48  28  55  54  48  40  99  99  55  40]\n",
      " [ 48  13  40  26  55   3  93  38  81  28]\n",
      " [ 55  19  48  65  38  38  99  58  38  65]\n",
      " [ 54  65  20  48  54  38  48  40  65  65]\n",
      " [ 55  40   3  65  20  48  13  40  65  45]\n",
      " [ 55  28  48 100  55   3  55  48  40  21]\n",
      " [ 93  48  40  19  26  40  93  13  55  49]\n",
      " [ 40  13  55  19  48  19  38 100  93  48]\n",
      " [ 54  40  12  93  57  28  48  46  40  28]]\n",
      "\n",
      "y\n",
      " [[  22.   91.   48.   36.    0.   15.    0.   62.   96.   48.]\n",
      " [  28.   55.   54.   48.   40.   99.   99.   55.   40.   65.]\n",
      " [  13.   40.   26.   55.    3.   93.   38.   81.   28.   48.]\n",
      " [  19.   48.   65.   38.   38.   99.   58.   38.   65.   55.]\n",
      " [  65.   20.   48.   54.   38.   48.   40.   65.   65.   38.]\n",
      " [  40.    3.   65.   20.   48.   13.   40.   65.   45.   49.]\n",
      " [  28.   48.  100.   55.    3.   55.   48.   40.   21.   40.]\n",
      " [  48.   40.   19.   26.   40.   93.   13.   55.   49.   48.]\n",
      " [  13.   55.   19.   48.   19.   38.  100.   93.   48.   99.]\n",
      " [  40.   12.   93.   57.   28.   48.   46.   40.   28.   55.]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Below is where you'll build the network. We'll break it up into parts so it's easier to reason about each bit. Then we can connect them up into the whole network.\n",
    "\n",
    "<img src=\"assets/charRNN.png\" width=500px>\n",
    "\n",
    "\n",
    "### Inputs\n",
    "\n",
    "First off we'll create our input placeholders. As usual we need placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called `keep_prob`. This will be a scalar, that is a 0-D tensor. To make a scalar, you create a placeholder without giving it a size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"inputs\")\n",
    "    targets = tf.placeholder(tf.int32,[batch_size,num_steps],name=\"targets\")\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Cell\n",
    "\n",
    "Here we will create the LSTM cell we'll use in the hidden layer. We'll use this cell as a building block for the RNN. So we aren't actually defining the RNN here, just the type of cell we'll use in the hidden layer.\n",
    "\n",
    "We first create a basic LSTM cell with\n",
    "\n",
    "```python\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "where `num_units` is the number of units in the hidden layers in the cell. Then we can add dropout by wrapping it with \n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "```\n",
    "You pass in a cell and it will automatically add dropout to the inputs or outputs. Finally, we can stack up the LSTM cells into layers with [`tf.contrib.rnn.MultiRNNCell`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/rnn/MultiRNNCell). With this, you pass in a list of cells and it will send the output of one cell into the next cell. For example,\n",
    "\n",
    "```python\n",
    "tf.contrib.rnn.MultiRNNCell([cell]*num_layers)\n",
    "```\n",
    "\n",
    "This might look a little weird if you know Python well because this will create a list of the same `cell` object. However, TensorFlow will create different weight matrices for all `cell` objects. Even though this is actually multiple LSTM cells stacked on each other, you can treat the multiple layers as one cell.\n",
    "\n",
    "We also need to create an initial cell state of all zeros. This can be done like so\n",
    "\n",
    "```python\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    # Add dropout to the cell outputs\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper( tf.contrib.rnn.BasicLSTMCell(lstm_size),output_keep_prob = keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Output\n",
    "\n",
    "Here we'll create the output layer. We need to connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character, so we want this layer to have size $C$, the number of classes/characters we have in our text.\n",
    "\n",
    "If our input has batch size $N$, number of steps $M$, and the hidden layer has $L$ hidden units, then the output is a 3D tensor with size $N \\times M \\times L$. The output of each LSTM cell has size $L$, we have $M$ of them, one for each sequence step, and we have $N$ sequences. So the total size is $N \\times M \\times L$. \n",
    "\n",
    "We are using the same fully connected layer, the same weights, for each of the outputs. Then, to make things easier, we should reshape the outputs into a 2D tensor with shape $(M * N) \\times L$. That is, one row for each sequence and step, where the values of each row are the output from the LSTM cells. We get the LSTM output as a list, `lstm_output`. First we need to concatenate this whole list into one array with [`tf.concat`](https://www.tensorflow.org/api_docs/python/tf/concat). Then, reshape it (with `tf.reshape`) to size $(M * N) \\times L$.\n",
    "\n",
    "One we have the outputs reshaped, we can do the matrix multiplication with the weights. We need to wrap the weight and bias variables in a variable scope with `tf.variable_scope(scope_name)` because there are weights being created in the LSTM cells. TensorFlow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default. To avoid this, we wrap the variables in a variable scope so we can give them unique names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    seq_output = tf.concat(lstm_output,axis=1)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size),stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros([out_size]))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits =  tf.add(tf.matmul(x,softmax_w),softmax_b) \n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits,name =\"out\")\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss\n",
    "\n",
    "Next up is the training loss. We get the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, we're getting them as encoded characters. Then, reshape the one-hot targets so it's a 2D tensor with size $(M*N) \\times C$ where $C$ is the number of classes/characters we have. Remember that we reshaped the LSTM outputs and ran them through a fully connected layer with $C$ units. So our logits will also have size $(M*N) \\times C$.\n",
    "\n",
    "Then we run the logits and targets through `tf.nn.softmax_cross_entropy_with_logits` and find the mean to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped =  tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_reshaped))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Here we build the optimizer. Normal RNNs have have issues gradients exploding and disappearing. LSTMs fix the disappearance problem, but the gradients can still grow without bound. To fix this, we can clip the gradients above some threshold. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip,global_step):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        global_step: to control the total number of train steps\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars),global_step)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network\n",
    "\n",
    "Now we can put all the pieces together and build a class for the network. To actually run data through the LSTM cells, we will use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/nn/dynamic_rnn). This function will pass the hidden and cell states across LSTM cells appropriately for us. It returns the outputs for each LSTM cell at each step for each sequence in the mini-batch. It also gives us the final LSTM state. We want to save this state as `final_state` so we can pass it to the first LSTM cell in the the next mini-batch run. For `tf.nn.dynamic_rnn`, we pass in the cell and initial state we get from `build_lstm`, as well as our input sequences. Also, we need to one-hot encode the inputs before going into the RNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.global_step_tensor = tf.Variable(0,trainable=False,name = \"global_step\")\n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size,num_steps)\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,self.keep_prob)\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs,num_classes)\n",
    "        \n",
    "        self.grad_clip  = grad_clip\n",
    "        # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,x_one_hot,initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs,lstm_size,num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss =  build_loss(self.logits,self.targets,lstm_size,num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss,learning_rate,grad_clip,self.global_step_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here are the hyperparameters for the network.\n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.\n",
    "* `lstm_size` - The number of units in the hidden layers.\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy on training the network:. \n",
    "\n",
    "> ## Tips and Tricks\n",
    "\n",
    ">### Monitoring Validation Loss vs. Training Loss\n",
    ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
    "\n",
    "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
    "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "> ### Approximate number of parameters\n",
    "\n",
    "> The two most important parameters that control the model are `lstm_size` and `num_layers`. I would advise that you always use `num_layers` of either 2/3. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    "\n",
    "> - The number of parameters in your model. This is printed when you start training.\n",
    "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
    "\n",
    ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
    "\n",
    "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `lstm_size` larger.\n",
    "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
    "\n",
    "> ### Best models strategy\n",
    "\n",
    ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_of_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        \n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters*=dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters+= variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for training\n",
    "\n",
    "This is typical training code, passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I save a checkpoint.\n",
    "\n",
    "Here I'm saving checkpoints with the format\n",
    "\n",
    "`i{iteration number}_l{# hidden layer units}.ckpt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = {\"train\":[],\"validation\":[]}\n",
    "x_steps = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting at time: 2017-10-25 21:55:34\n",
      "Number of parameters: 7475814 Dataset size: 2563420\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i2670_l768.ckpt\n",
      "Epoch: 1/10...  Training Step: 2671...  Training loss: 1.3990...  Val loss: 1.5394...  0.3608 sec/batch\n",
      "Epoch: 1/10...  Training Step: 2771...  Training loss: 1.3505...  Val loss: 1.4831...  0.2723 sec/batch\n",
      "Epoch: 1/10...  Training Step: 2871...  Training loss: 1.3284...  Val loss: 1.4912...  0.2723 sec/batch\n",
      "Epoch: 2/10...  Training Step: 2971...  Training loss: 1.2620...  Val loss: 1.4818...  0.2800 sec/batch\n",
      "Epoch: 2/10...  Training Step: 3071...  Training loss: 1.2822...  Val loss: 1.4816...  0.2726 sec/batch\n",
      "Epoch: 2/10...  Training Step: 3171...  Training loss: 1.3120...  Val loss: 1.4835...  0.2728 sec/batch\n",
      "Epoch: 3/10...  Training Step: 3271...  Training loss: 1.2855...  Val loss: 1.4810...  0.2739 sec/batch\n",
      "Epoch: 3/10...  Training Step: 3371...  Training loss: 1.2524...  Val loss: 1.4784...  0.2739 sec/batch\n",
      "Epoch: 3/10...  Training Step: 3471...  Training loss: 1.3044...  Val loss: 1.4903...  0.2729 sec/batch\n",
      "Epoch: 4/10...  Training Step: 3571...  Training loss: 1.2643...  Val loss: 1.4839...  0.2744 sec/batch\n",
      "Epoch: 4/10...  Training Step: 3671...  Training loss: 1.2504...  Val loss: 1.4892...  0.2758 sec/batch\n",
      "Epoch: 5/10...  Training Step: 3771...  Training loss: 1.2516...  Val loss: 1.4810...  0.2721 sec/batch\n",
      "Epoch: 5/10...  Training Step: 3871...  Training loss: 1.2356...  Val loss: 1.4906...  0.2727 sec/batch\n",
      "Epoch: 5/10...  Training Step: 3971...  Training loss: 1.2673...  Val loss: 1.4849...  0.2734 sec/batch\n",
      "Epoch: 6/10...  Training Step: 4071...  Training loss: 1.2487...  Val loss: 1.4764...  0.2733 sec/batch\n",
      "Epoch: 6/10...  Training Step: 4171...  Training loss: 1.2453...  Val loss: 1.4751...  0.2783 sec/batch\n",
      "Epoch: 6/10...  Training Step: 4271...  Training loss: 1.2621...  Val loss: 1.4849...  0.2810 sec/batch\n",
      "Epoch: 7/10...  Training Step: 4371...  Training loss: 1.2545...  Val loss: 1.4894...  0.2732 sec/batch\n",
      "Epoch: 7/10...  Training Step: 4471...  Training loss: 1.2069...  Val loss: 1.4941...  0.2736 sec/batch\n",
      "Epoch: 8/10...  Training Step: 4571...  Training loss: 1.2266...  Val loss: 1.4913...  0.2813 sec/batch\n",
      "Epoch: 8/10...  Training Step: 4671...  Training loss: 1.2271...  Val loss: 1.4845...  0.2751 sec/batch\n",
      "Epoch: 8/10...  Training Step: 4771...  Training loss: 1.2380...  Val loss: 1.4928...  0.2749 sec/batch\n",
      "Epoch: 9/10...  Training Step: 4871...  Training loss: 1.2299...  Val loss: 1.4958...  0.2731 sec/batch\n",
      "Epoch: 9/10...  Training Step: 4971...  Training loss: 1.2231...  Val loss: 1.4984...  0.2909 sec/batch\n",
      "Epoch: 9/10...  Training Step: 5071...  Training loss: 1.2089...  Val loss: 1.5019...  0.2734 sec/batch\n",
      "Epoch: 10/10...  Training Step: 5171...  Training loss: 1.2055...  Val loss: 1.5093...  0.2742 sec/batch\n",
      "Epoch: 10/10...  Training Step: 5271...  Training loss: 1.2112...  Val loss: 1.5087...  0.2777 sec/batch\n",
      "Epoch 10/10 time:74.06262755393982...  finished at 2017-10-25 22:07:55\n",
      "Training ending at time: 2017-10-25 22:07:56\n",
      "Trainint total time: 742.0028877258301\n"
     ]
    }
   ],
   "source": [
    "#epochs = 1\n",
    "# Save every N iterations\n",
    "save_every_n = 500\n",
    "print_loss_every_n = 100\n",
    "sample_every = 500\n",
    "print_epoch_time_every = 10\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "    #print(\"after model\")\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "print(\"Training starting at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "train_start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Number of parameters:\",get_number_of_parameters(),\"Dataset size:\",len(encoded))\n",
    "    #print(\"after initializer\")\n",
    "    if resume_from_checkpoint:\n",
    "        latest_checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            \n",
    "            \n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "        \n",
    "            \n",
    "            end = time.time()\n",
    "            if counter%print_loss_every_n == 0:\n",
    "                val_batches = get_batches(encoded_val,int(len(encoded_val)/num_steps),num_steps)\n",
    "                x_val,y_val = next(val_batches)\n",
    "                \n",
    "                val_dict = {model.inputs: x_val,\n",
    "                            model.targets: y_val,\n",
    "                            model.keep_prob: 1,\n",
    "                            model.initial_state: new_state}\n",
    "                \n",
    "                val_loss,prediction = sess.run([model.loss,model.prediction],feed_dict=val_dict)\n",
    "                \n",
    "                losses[\"train\"].append(batch_loss)\n",
    "                losses[\"validation\"].append(val_loss)\n",
    "                \n",
    "                \n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                x_steps.append(global_step)\n",
    "                \n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(global_step),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      'Val loss: {:.4f}... '.format(val_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "                saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "                \n",
    "            counter += 1\n",
    "            #learning_rate*=0.75\n",
    "            #model.optimizer = build_optimizer(model.loss,learning_rate,model.grad_clip,model.global_step_tensor)\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "        \n",
    "        \n",
    "        if ((e+1) % print_epoch_time_every== 0):\n",
    "            print('Epoch {}/{} time:{}...'.format(e+1,epochs,epoch_end-epoch_start),\n",
    "                 \" finished at\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "        \n",
    "            \n",
    "    global_step = tf.train.global_step(sess,model.global_step_tensor)\n",
    "    saver.save(sess, \"checkpoints/m{}_i{}_l{}.ckpt\".format(mode,global_step, lstm_size))\n",
    "    \n",
    "print(\"Training ending at time:\",strftime(\"%Y-%m-%d %H:%M:%S\", localtime()))\n",
    "print(\"Trainint total time:\",time.time()-train_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAH0CAYAAACEkWPuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06d00a8550>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 373
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_steps,losses[\"train\"],label=\"Train loss\")\n",
    "plt.plot(x_steps,losses[\"validation\"],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved checkpoints\n",
    "\n",
    "Read up on saving and loading checkpoints here: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints = tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling final trained model\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \",mode=\"characters\"):\n",
    "    print(mode)\n",
    "    samples = tokenize_text(prime,mode)\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in tokenize_text(prime,mode):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples).replace(\"new_line_token\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/mcharacters_i5340_l768.ckpt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new text from \"base\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "\n",
    "\n",
    "samples = list()\n",
    "for text in text_to_try:\n",
    "    #print(\"------------------------\",text)\n",
    "    samples.append( sample(checkpoint, 500, lstm_size, len(vocab), prime=text,mode=mode))\n",
    "    #print(samp)\n",
    "    #print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ In the first place\n",
      "In the first place.\n",
      "\n",
      "II.\n",
      "\n",
      "A cription had accidentally reached the best, before he had befluxed those excited, and, as well as at a moment at the fear of see what we could not receive any death.\n",
      "\n",
      "    I am a sea continued to tince a lot in that fearful imploying to attend on the figure of the particum to make a marble observation. We will not met offen it, at once the street was not the frequent poise or place to the\n",
      "patient, this portray of all the place. I had no\n",
      "blood, and the problem of many surface wondered the\n",
      "------------------------\n",
      "------------------------ the night before\n",
      "the night before these apendaress off in the deceased and tormed their strength.\n",
      "\n",
      "    On their securely and convaced through which I hadned in the things with the strange conformal motered structures in the sea which were two of this thouganours. It is new last that we could seen a post of the climate and threatened to say his hold of a person to the sole character and made over the mulmils that treated a glimpsed bolts of the seconds of the case of their comments, and when a sharp contemporary sea-bill of a per\n",
      "------------------------\n",
      "------------------------ horror\n",
      "horror and a striking shared strates, of what we soon climbed me was a straight and, burning and princible than any setting southwardly with taking about, and at length the words of his mind was itself, and he woull be this thing whose day was the mind to the season. He was necessarily stupidisted on the conversation at the terror of the distracising memories. All to the facts with work a part of this time of the street and singular-hang tigarity.\n",
      "     Inname the starting was three things. His mistake,\n",
      "------------------------\n",
      "------------------------ creature\n",
      "creature and twice is all the crowd of medical, and toose on the fact wine and marvellous abysses of the core at their entering, and that they can be never trandicled by the southerly and merchants of his head.\n",
      "\n",
      "    When a lots of the strange hunter had been satisfiedly fifty-maisone course, of exposed mortality are not to forch all these significance was induced there in the primal mass against the perfect called speed takes, and their states were seen temple of means of all that he had built the blesti\n",
      "------------------------\n",
      "------------------------ night\n",
      "night in his persecusive to the case. The temporary character of the countenance were suffered in some of the placid men of his pendulum to treav window, and the primal cases, telling to the power of this planet which had been meat as a marble, which they can be nearly taking himself.\n",
      "\n",
      "    The tenant of the tenth must be im what was interruit.\n",
      "\n",
      "There windows he see only\n",
      "to be the primordial special ferge of its dark corridors;of into my\n",
      "head as the same time with me. He was to tend all the place of th\n",
      "------------------------\n",
      "------------------------ dream\n",
      "dreaming that he had no line of her direction, and at least a singular-conclose and fathomanaced breath with the clouds of the distance and dogs.\n",
      "     The contents of the trees were now transportating it as if a shrill courage abouthy found in attention with some portrait that I was able to resemble myself a few moments, and thanking in that of the parts of the starboard streams of the shadew than to the farm or three of the cargo which was anceyondering and thrilled above the bright, and of a great m\n",
      "------------------------\n",
      "------------------------ thing\n",
      "thing to me that the sturn of the shocking or first weethered toward the tempiration of the passage that widelets of the cry talked about an intimate appearance, and a faint signs of this pennilive with terror was able to be the beautiful points of their ship on the common consequenism of that sucted bearing of the drug behind my ascending shame. I had so tended to my song any power again. In a sharp time the boat was a secreciaais one of the chillate. It seems, and his fearshoud comfowness, and all t\n",
      "------------------------\n",
      "------------------------ That night\n",
      "That night and horti and tresses ofe tried to think it, where the moon had seeks of the stages and pretaining way. We seemed to believe any teeth of the place. The peauling senses were several clutched carvings our paralleless on a pointed and chief or fifteen minutes, and touched by the stories of this place; and when I had no largercalle tentacle of horrible chorus and singular powers were set to the cabin chief of any of his marvellous vasterchange.\n",
      "     It had set not for the sea with times of the cham\n",
      "------------------------\n",
      "------------------------ mountain\n",
      "mountain--about me a statter and at an anturnent, but, in the state of this terrible chief in all morting an enormal shrubs of my own. I saw that, after the choked hours, the familiarity of the breaking through teephances in their memory worked out for the body. At air of a short of his whole companion were not before that of his maskers and tremulous stench of the mists. Iffest to top or our obstruction about midnight. The chair, with a second, as although in the manner of hope of the considerable desir\n",
      "------------------------\n",
      "------------------------ Ammi\n",
      "Ammita in their sea before a singular point of days, with all along the primornial bulletins. The second had caused me in the first of his prisoners, and that terribly organisments and tented ship had been ready; and when he heard his preferction was in the first stationer and missing a party whose causes and shelves and people, in my own proportion windows in myself, the sound, or something was secured with the bearing in them and seen in a great cargo of able to trust it with the creature, been inc\n",
      "------------------------\n",
      "------------------------ Cthulhu\n",
      "Cthulhumate to their hatred, though it would not take it wide that they had been to think. And this I took the priest therefore to the careless surface of the cabin, and the sound is not to be station in the peculiar and tied apociation. The singular conversation of the seasaus on a caught contemptate houses, a cased time told me to the world after his friends at the fortune to death and special. In strength and concealing an easily coming, it was in some period with more than huge and cargo about a far\n",
      "------------------------\n",
      "------------------------ raven\n",
      "ravened to be a memory of all that with the bottom to the frequent prisoner.\n",
      "\n",
      "The faintest discuss of making the sealed channel her family apptiveness and step being ovaraely before that of the painful minds of its matter on the clothes of his parents of a cloud. I had next to do, that the compence of this things were set off a seated priests of taste was the bottle; but the shelves seemed to few the season, and that, as the sharp thing was absolutely stone; but the shocking stone was a postrite with \n",
      "------------------------\n",
      "------------------------ bird\n",
      "birdened by the first old moment at length, and succeeded by their morning to bander, and the mountain-like captive minds of the same times, and were nine of any personal beach where a powers of the bare or tales was considerable; and, for the mutine issuated as their mounds of those others and their sea-somewhere beyond that of the cold. Another hathful interests was too late to the straight and tremulous that.\n",
      "     It was a steel a discoveries, of what I can access them altogether with the box.\n",
      "\n",
      "It\n",
      "------------------------\n",
      "------------------------ nevermore\n",
      "nevermore, and the shore, though their company with which the collage, are now, too, in some of their secondation of each\n",
      "of the chamber. Althoush be to say and some dreadful times to believe\n",
      "of about to receive him and at that morbid older and firsined short, works of\n",
      "an efforts, though it is not been to be absentially perceptible. As ter signs of those who had altogether raven by the from my boding respects in their formst the course of my fruiters, as incedent wide fright. Whether it seemed to be touch\n",
      "------------------------\n",
      "------------------------ dead\n",
      "dead without things, we failed to be all merchantled them, and the short shock wished, as idea to lead the strange and telling of the planes when he spoke of the sharp cargars; and the frightened minds were obtaining to all the charnel of a canoot a people as it was never, through the stone beauty in that paper to be those on the same strange and partiture. With the second hill-crawling credible coat from the manner in the monstrous and destroyed sea of the southward and have a greater cryshicast spa\n",
      "------------------------\n",
      "------------------------ The bird\n",
      "The bird twelt brought about the strangers. Then he was some of a mere good current which the chain of their heads, were murmuring at the passage of the characterism. Then, was in the places of stone with surroundings. With the chief of the crawlings, and as we will be stopped and perilous to be to see what to make me with human and cleaking twistings to the catacombs of their process.\n",
      "     In this time was seen to my state, the first time which seemed, the chair in the captain of the topic.\n",
      "     I have \n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_to_try)):\n",
    "    text = text_to_try[i]\n",
    "    generated = samples[i]\n",
    "    print(\"------------------------\",text)\n",
    "    print(generated)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/mcharacters_i5340_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i3671_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i4171_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i4671_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i5171_l768.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/mcharacters_i5340_l768.ckpt\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "The old folk have gone away. The conversation of the samplight had seen them.\n",
      "\n",
      "    As I traved his calling of those heart was an open abyss, talked in troubled hadly a deepender and a strong peak after a single collection at the first attic of my face to be absonbed before it, and though there were two matters of a manner within the points of the clouding odour, and which were incident of a tinked profinity. This was the tale of the storms on the back of the moon. He seemed to be chiefly in the care of the caverns. As he stumped these thoroughly that he started, the main start at the think of the matter on that case was the trap-door and when the strength is to be seen; but the taverns of these must have been much as to remone more able to steam; and what had complished the boy where he say, while impression there was a great candles of material. The prisoner in the mere corrog-rank which might hav invossel all my househisth made all thinking of the contact in the cherish cities; the marvellous cinctual, which tages off on a thousand terror and and figure to the steam carrisue which many obstruck several masses of invaries with the seri and pointed and teecious truck, taking in his head to a single continually ancient points of three-horror, and why I have saw another infancy in the consect with the steady fatters and stranger. The town of a man would be the farther terrible descent to my stone--a king of different solucies of explanation in the place; and there was a farmhouse, the facto was indefined thate about a monoment. The struggles of the travelled height of a strong shaping ring of antraverncious, shape of thousand arrangements were somewhat about him. Thus it would have been securing about him in a present to the countenance of some prosecy in his careful incidents. It had been taken them in a mind, without time, I could not be neered in my own tigers and prints are still storm and the faces, we found it to a persuad to suppose for an excellent archive, and only by the stone black stone and the whole of the period. The shining almost--with mention of the state of the massage of my soul, and, in the sea was clussed as the formations of his pass of the box. It was one of the shoggoths.\n",
      "     It was able to my bosom to this party water, as in a childhood fragments of earth and the sea. I had studied them of the blow in by access, the canoes of the murmurs of the secondary stream threw\n",
      "degrees see in streets in the meteor of the mate was a strange brooding of the plusion of the same inches as if his foot of the stairs. Touchment and provisioned thing about the blight-so concrete interest of this complete remaining coloure in the proportion of the column and their province. The thought of the men and a croaked change of the dreaded secure with sea-bottom to speak. At the table and three moon-beasts, wholesome ancestry are more recognizing the powder, and their shades and the caverns his secrecisal midnights as the fright of anticipations, and sight of a presence of that contradiction of all the southern sea terrible belief. They are not a particle of pleasurable penguins. The trees throughout this mistake was all shadowed about the creatures too much as a cloud-room of mysterious a fancy; for it would of an animal with surprising metal, and which he could not be a matter of the corven and memories of tenantless and massively conceivable and dog. He spoken of story station in sight in the marvel who had carefully dreamed over the correction of the miles to the tongue. The fact the trees was any other antarctic monstrorable elder ship.\n",
      "\n",
      "The second tone of this matter had been called. He spoke how however tood an opportunity which must have they would have had travelled the traimed situation. And the first of time Innsmouth are more than a stages of their concreteing the case that he had been begun beyond the secrecy of the morningboth of mental conclusion. When I threw or to think the feeling of the precarious part of that strokes and danger, which this had begun to dispose the chimneys cracking of his characters, which had been shaking out of the boat with his creature would profess my ordinary torch is to be the sands it at the far to any person of the state of this top tried, and the terrifus at the frantic well half the town wall and tried on the path too memories; with timidly terms of that, and on a change is able to relieve the sailow although they are now forgotten, but in six mental stone process of that point of thirst to search himself with a conflection of my streets of the containing and almost about. It was one of the terrors than were the singular. Obriaging the cloud of the mind was almost to streak. It was the first of the character, bringing, and shadowed all that sounded on half-prints were the sort of tense archaic specimens of accidents on the mate of his favority and simple wind. At the police strainliar height on the tenden character, is a part of three floor in searcily to be classed only to the cargation o\n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The old folk have gone away\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mcharacters_i5340_l768.ckpt\n",
      "The thing that should not behin my part of two points, and a stream who consulted on a members about which his mistakeas which high heard, and then, with the strange world, and some of the start of the senses had contented the personality in the desig of thronging things about her the mind which was so finally; then, as I turned the carded stars, with all-currents of torch, and though the most stooped about the precipious mountain that was absolute in this side, and to the second tower source of a corpse, and the steps, were its chill of my burning and steppe about to time himself, but only the chamber of two walls if terrifies are again. The primal tine of the steps were clear or provised to say, attempting to think of the chorus of the propiding. At all these ancient sounds have becomes a clear to the country insteadous mental steady by the silent and the concern of some moments, and the first strange of the temperator could be so seen to me that a glass which there are some measure, and about as possible and aliening it to the firm that we may have been to be made one antient surface, and had that, as I hav instaited a greater secret of the breathing- if at all, to me that he would be surprised to make at this stretching, and to mydelf. I had seen only the myth head, where it, and the storeroom became a great creature. The curious stranger of the chaoner secured. They were so many of the most\n",
      "extrimate subtractible conditions and the fire. As I had better now applinated that, to the torch was in a few of the matter was\n",
      "too, in any other mountaed baterious masonry. He assiminated the seconds of a great dealing with the same above alluder, but there were not, a singular portion of my brain at a casoligh, which he did its crawling cords, and with an excessiveness immediately sent a stench and of the principal steps to their examining.\n",
      "     These\n",
      "and a man of telling our possible seven mental company was abroat. The crags of ancience, too, all over the book, and the significance was so taken, a time of the ship was soon as a black. I had not filled a strangely peringituent of the murches of the sea at at once, the thinner\n",
      "would be no\n",
      "permit of the same absence.\n",
      "\n",
      "It was abandoned in the mountain, with a powder of plainly; and the more stiffed at the prisoner of the cavole in attain that we could not bring. I said I was able to date an intent of my own in the moonlight of ancestor and membraneous terraces.\n",
      "     I declored a great bodies\n",
      "of the back of animals. He was at an aged barking of two otherwise that I had now should have been increased. I could not take to the ten million, which, a surface, it was never,hing, and\n",
      "was throow off in the person. Third of the\n",
      "countresid of the most distance, his mind into\n",
      "past were solemnass of immidotial case. Then, as if the primagical stone- I have said that it was a single suffering of my poisted, and\n",
      "a minute and sentiment\n",
      "waited at the morning, but which must have ever thinked them with three manuels; the fountain of meditations of thirth waste of his parentance were almost, and shortly\n",
      "afterward he saw through\n",
      "the first of the proffing watchers of the maise and about them; but which would be anyone with stranger whee there was something with the better attended as a fresh, or meres of the same similar motionless suggestions of the street.\n",
      "     We saw only on that peaked plain and the wind, and was in the matter is that\n",
      "of a heed, and,\n",
      "impressed,\n",
      "indeed, we had been took up at the single\n",
      "treal of the matter, been to contrive the same time, into the\n",
      "sound of my\n",
      "own\n",
      "excessive things what this walls was not only a man of their curving an infinite experiment. The passable heavy catacombs and store of\n",
      "the matter, and attempt to trade the features of the morning of the cabils and a man alone.\n",
      "\n",
      "    Of weather had a subternation of the beautiful sense of subtic trapperition, and thing, and this particular cross of my fatueaus and meant from\n",
      "me to be so strong, and then. The corrisor, it was a merinion of matters of the blasphemous membraneour in the sound, and so actually apptied, were in the\n",
      "chaos, the beginning of my business, and instantly, were strengthenished by the\n",
      "proper sides,\n",
      "and were two prevailings ofered, and terrible thirst, as we arched the struggles of a few wilbolm into the crowding. In this precise survived were\n",
      "only only weeks of more than\n",
      "fragments at\n",
      "the\n",
      "considerable perspective, but of which\n",
      "the fine way, and attempting her with statement it\n",
      "could bring it upon his presence, and it were tottering over a probable towers of the box, and it is the pardness, while the blace of the most immediate daylight shoulder as a blancht in the progress of\n",
      "the south,\n",
      "when his whip was sufficiently, as if if these casting three singned was there, although there was\n",
      "a month the witd our sound, with me without any\n",
      "tincoplagitant force or the static occasional steps in the\n",
      "couch. He was an intellect\n",
      "while the sounds of the brig the couctic above.\n",
      "\n",
      "Thus the faintest people was,\n",
      "\n",
      "\n",
      "\n",
      "\"I nobody arritately w\n"
     ]
    }
   ],
   "source": [
    "generated = sample(checkpoint, 5000, lstm_size, len(vocab), prime=\"The thing that should not be\",mode=mode)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
